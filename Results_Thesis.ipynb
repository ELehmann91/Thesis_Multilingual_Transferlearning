{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Results_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CePvYnY0y7tR"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ELehmann91/Thesis_Multilingual_Transferlearning/blob/master/Results_Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru35-Xo1kmrW",
        "colab_type": "text"
      },
      "source": [
        "# Train script\n",
        "  \n",
        "using prewritten fuctions and standardized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5sB703QrHaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "f20a9522-81bf-4971-b136-cfa02e2bb791"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive, files\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path ='/content/gdrive/My Drive/Thesis_ecb_ecoicop'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJUAJfPTnMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install eli5\n",
        "!git clone 'https://github.com/ELehmann91/Thesis_Multilingual_Transferlearning'\n",
        "\n",
        "%cd Thesis_Multilingual_Transferlearning\n",
        "import labeler_cc5\n",
        "import coicop_model\n",
        "import model_helper\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import io"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupya9-dk4m0",
        "colab_type": "text"
      },
      "source": [
        "## Import Data\n",
        "  \n",
        "data in the normalized folder are splitted between languages (currently de fr & it) and share the same columns so they can be merged easily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvxjN1mrrZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "baed43de-db37-4e5a-b8b2-dfa873737d42"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_path = '/data/'#\n",
        "#file_path = 'fra/carrfour_trans_pred.csv'\n",
        "file_path = 'normalized/norm_fr.csv'\n",
        "file_path2 = 'normalized/norm_de.csv'\n",
        "file_path3 = 'at/norm_at.csv'\n",
        "file_path4 = 'normalized/df_italiano.csv'\n",
        "#file_path = 'edeka_pred.csv'\n",
        "\n",
        "# french data\n",
        "df_fr = pd.read_csv(path+data_path+file_path,sep='|',index_col=False)\n",
        "\n",
        "# only already labeled\n",
        "df_fr = df_fr[df_fr['cc5'].isna()==False]\n",
        "df_fr = df_fr[df_fr['shop'].isin(['carrefour','auchan','banque_de_france'])]#,'banque_de_france','carrefour'])]\n",
        "df_fr['cc5'] = df_fr['cc5'].apply(lambda x: '9999_Non-Food' if int(str(x)[0])>2 else x)\n",
        "print(len(df_fr))\n",
        "\n",
        "# german data\n",
        "df_de = pd.read_csv(path+data_path+file_path2,sep='|',index_col=False)\n",
        "# only already labeled\n",
        "df_de = df_de[df_de['cc5'].isna()==False]\n",
        "print(len(df_de))\n",
        "# austrian data\n",
        "df_at = pd.read_csv(path+data_path+file_path3,sep='|',index_col=False)\n",
        "# only already labeled\n",
        "df_at = df_at[df_at['cc5'].isna()==False]\n",
        "df_de = df_de.append(df_at)\n",
        "print(len(df_de))\n",
        "\n",
        "df_it = pd.read_csv(path+data_path+file_path4,sep='|',index_col=False)\n",
        "df_it = df_it[df_it['cc5'].isna()==False]\n",
        "print(len(df_it))\n",
        "#df_fr = df_fr.sample(frac=1).reset_index(drop=True)\n",
        "#df_de = df_de.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22833\n",
            "21903\n",
            "31463\n",
            "667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-z8SWyzJE24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0e75493f-44d3-49dd-99d5-99c1ad9053e7"
      },
      "source": [
        "len(df_fr['cc5'][df_fr['shop'].isin(['banque_de_france'])].value_counts())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZH6sOjr2_no",
        "colab_type": "text"
      },
      "source": [
        "### Exclude non-food?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-40uLS9OAZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_Classes = 75\n",
        "exclude_non_food = False\n",
        "if exclude_non_food:\n",
        "    df_fr = df_fr[df_fr['cc5']!='9999_Non-Food']\n",
        "    df_de = df_de[df_de['cc5']!='9999_Non-Food']\n",
        "    df_at = df_it[df_it['cc5']!='9999_Non-Food']\n",
        "    no_Classes = 74\n",
        "    print(len(df_fr))\n",
        "    print(len(df_de))\n",
        "    print(len(df_at))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswr191ClXi1",
        "colab_type": "text"
      },
      "source": [
        "decide which columns should be used for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n55A0HV-g95g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = 'name'\n",
        "#df_fr['text'] = df_fr[var].fillna('unknown') \n",
        "#df_de['text'] = df_de[var].fillna('unknown') \n",
        "#df_at['text'] = df_at[var].fillna('unknown') \n",
        "\n",
        "var1 = 'categ'\n",
        "var2 = 'words_from_url'\n",
        "#df_fr['text'] = df_fr[var1].fillna('unknown')  + ' <sep> ' + df_fr[var2].fillna('unknown') \n",
        "#df_de['text'] = df_de[var1].fillna('unknown')  + ' <sep> ' + df_de[var2].fillna('unknown') \n",
        "#df_at['text'] = df_at[var1].fillna('unknown')  + ' <sep> ' + df_at[var2].fillna('unknown') \n",
        "\n",
        "\n",
        "var1 = 'categ'\n",
        "var2 = 'words_from_url' \n",
        "var3 = 'name'\n",
        "#var1 = 'name' \n",
        "#var2 = 'categ' \n",
        "#var3 = 'words_from_url' \n",
        "df_fr['text'] = df_fr[var1].fillna('unknown')  + ' <sep> ' + df_fr[var2].fillna('unknown')  + ' <sep> ' + df_fr[var3].fillna('unknown') \n",
        "df_de['text'] = df_de[var1].fillna('unknown')  + ' <sep> ' + df_de[var2].fillna('unknown')  + ' <sep> ' + df_de[var3].fillna('unknown') \n",
        "df_it['text'] = df_it[var1].fillna('unknown')  + ' <sep> ' + df_it[var2].fillna('unknown')  + ' <sep> ' + df_it[var3].fillna('unknown') \n",
        "\n",
        "#df_fr['text'] = df_fr[var1].fillna('unknown')  + df_fr[var2].fillna('unknown')  + df_fr[var3].fillna('unknown') \n",
        "#df_de['text'] = df_de[var1].fillna('unknown')  + df_de[var2].fillna('unknown')  + df_de[var3].fillna('unknown') \n",
        "#df_at['text'] = df_at[var1].fillna('unknown')  + df_at[var2].fillna('unknown')  + df_at[var3].fillna('unknown') \n",
        "\n",
        "#df_fr['text'] = ' <fr> ' + df_fr['name'] + ' <sep> ' + df_fr['categ'].fillna('unknown') + ' <sep> ' + df_fr['words_from_url'].fillna('unknown') + ' <sep> ' + df_fr['prod_desc'].fillna('unknown') \n",
        "#df_de['text'] = ' <de> ' + df_de['name'] + ' <sep> ' + df_de['categ'].fillna('unknown') + ' <sep> ' + df_de['words_from_url'].fillna('unknown') + ' <sep> ' + df_de['prod_desc'].fillna('unknown') \n",
        "#df_at['text'] = ' <de> ' + df_at['name'] + ' <sep> ' + df_at['categ'].fillna('unknown') + ' <sep> ' + df_at['words_from_url'].fillna('unknown') + ' <sep> ' + df_at['prod_desc'].fillna('unknown') \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScESyOiJNwoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "rep_dict = {'.':' ',\n",
        "                        ',': ' ',\n",
        "                        '&': ' ',\n",
        "                        '-': ' ',\n",
        "                        '/': ' ',\n",
        "                        'ü': 'ue',\n",
        "                        'ä': 'ae',\n",
        "                        'ö': 'oe',\n",
        "                        'ß': 'ss',\n",
        "                        'ê': 'e',\n",
        "                        'é': 'e',\n",
        "                        'è': 'e',\n",
        "                        'â': 'a',\n",
        "                        'á': 'a',\n",
        "                        'à': 'a',\n",
        "                        ' a ':' ',\n",
        "                        ' b ':' ',\n",
        "                        ' c ':' ',\n",
        "                        ' d ':' ',\n",
        "                        ' e ':' ',\n",
        "                        ' f ':' ',\n",
        "                        ' g ':' ',\n",
        "                        ' h ':' ',\n",
        "                        ' i ':' ',\n",
        "                        ' j ':' ',\n",
        "                        ' k ':' ',\n",
        "                        ' l ':' ',\n",
        "                        ' m ':' ',\n",
        "                        ' n ':' ',\n",
        "                        ' o ':' ',\n",
        "                        ' p ':' ',\n",
        "                        ' q ':' ',\n",
        "                        ' r ':' ',\n",
        "                        ' s ':' ',\n",
        "                        ' t ':' ',\n",
        "                        ' u ':' ',\n",
        "                        ' v ':' ',\n",
        "                        ' w ':' ',\n",
        "                        ' x ':' ',\n",
        "                        ' y ':' ',\n",
        "                        ' z ':' ',\n",
        "                        'ô':'o',\n",
        "                        'œ': 'ae',\n",
        "                        '%': ' percent ',\n",
        "                        '1': ' one ',\n",
        "                        '2': ' two ',\n",
        "                        '3': ' three ',\n",
        "                        '4': ' four ',\n",
        "                        '5': ' five ',\n",
        "                        '6': ' six ',\n",
        "                        '7': ' seven ',\n",
        "                        '8': ' eigth ',\n",
        "                        '9': ' nine ',\n",
        "                        '0': ' zero ',\n",
        "                        ' l ':' liter ',\n",
        "                        ' ml ':' liter ',\n",
        "                        'api':' ', 'offers':' ', 'images':' ', 'default':' ', 'msmall' :' ','jpg':' '\n",
        "                        }\n",
        "\n",
        "def prepro(line):\n",
        "    if isinstance(line,str):\n",
        "        text_str = ' '.join(str(t) for t in line.split())\n",
        "        text_str = text_str.lower()\n",
        "        for a,b in rep_dict.items():\n",
        "            text_str = text_str.replace(a,b)\n",
        "        text_str = re.sub('[^a-zäöüàáâéèêßœ<>]+', ' ', text_str)\n",
        "    else: \n",
        "        text_str = str(line)\n",
        "    return text_str"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1on_by8aNzmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fr['text'] = df_fr['text'].apply(lambda x:prepro(x))\n",
        "df_de['text'] = df_de['text'].apply(lambda x:prepro(x))\n",
        "df_it['text'] = df_it['text'].apply(lambda x:prepro(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUiw5fuU250I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "99514685-0d61-4c6d-ab2b-3c56a41ad7b7"
      },
      "source": [
        "print('50% quantile no. of words per row french',np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "print('50% quantile no. of words per row german',np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "print('50% quantile no. of words per row italian',np.quantile(df_it['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "\n",
        "print('90% quantile no. of words per row french',np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.95))\n",
        "print('90% quantile no. of words per row german',np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.95))\n",
        "print('90% quantile no. of words per row italian',np.quantile(df_it['text'].apply(lambda x: len(str(x).split())),.95))\n",
        "\n",
        "seq_len = int(max(np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.95),np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.95)))\n",
        "print('seq_len',seq_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50% quantile no. of words per row french 19.0\n",
            "50% quantile no. of words per row german 19.0\n",
            "50% quantile no. of words per row italian 11.0\n",
            "90% quantile no. of words per row french 34.0\n",
            "90% quantile no. of words per row german 27.0\n",
            "90% quantile no. of words per row italian 18.0\n",
            "seq_len 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPbed6wD3pXB",
        "colab_type": "text"
      },
      "source": [
        "### Split Train Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZmopEj259h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "14b0d0dc-b4b5-4b1e-eab1-6d2a4da94dd4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_train_abs(df):\n",
        "    X_train, X_val_test, y_train, y_val_test  = train_test_split(df['text'], df['cc5'], random_state=42, shuffle=True)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val_test , y_val_test, train_size=.5,random_state=42)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train_de, X_val_de, X_test_de, y_train_de, y_val_de, y_test_de = split_train_abs(df_de)\n",
        "X_train_fr, X_val_fr, X_test_fr, y_train_fr, y_val_fr, y_test_fr = split_train_abs(df_fr)\n",
        "\n",
        "df_it = df_it[df_it['cc5'].isna()==False]\n",
        "\n",
        "X_it = df_it['text']\n",
        "y_it = df_it['cc5']\n",
        "print('de',X_train_de.shape, X_val_de.shape, X_test_de.shape, y_train_de.shape, y_val_de.shape, y_test_de.shape )\n",
        "print('fr',X_train_fr.shape, X_val_fr.shape, X_test_fr.shape, y_train_fr.shape, y_val_fr.shape, y_test_fr.shape )\n",
        "print('it',X_it.shape, y_it.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de (23597,) (3933,) (3933,) (23597,) (3933,) (3933,)\n",
            "fr (17124,) (2854,) (2855,) (17124,) (2854,) (2855,)\n",
            "it (667,) (667,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA-OuCNFzfLP",
        "colab_type": "text"
      },
      "source": [
        "### Embed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X22q8A2r8rmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eb8afcab-218e-4552-84b1-30efb65a8a29"
      },
      "source": [
        "import pickle\n",
        "french = True\n",
        "german = True\n",
        "italian = True\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "if french:\n",
        "    fr_git_embed = pickle.load( open(path + '/embeddings/fr_slim_embed_ext.p', \"rb\" ) ) #fr_slim_embed_ext #fr_muse_align #fr_muse\n",
        "    #fr_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Thesis_ecb_ecoicop/embeddings/wiki.fr.vec')\n",
        "if german:\n",
        "    de_git_embed = pickle.load( open(path + '/embeddings/de_slim_embed_ext.p', \"rb\" ) ) #de_muse\n",
        "    #de_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Thesis_ecb_ecoicop/embeddings/wiki.de.vec')\n",
        "if italian:\n",
        "    it_git_embed = pickle.load( open(path + '/embeddings/it_slim_embed.p', \"rb\" ) ) #de_muse\n",
        "    #de_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Thesis_ecb_ecoicop/embeddings/wiki.de.vec')\n",
        "\n",
        "v = np.zeros(300)\n",
        "v[0]=0\n",
        "fr_git_embed['<sep>'] = v\n",
        "de_git_embed['<sep>'] = v\n",
        "it_git_embed['<sep>'] = v\n",
        "\n",
        "print('de_git_embed',len(de_git_embed.keys()))\n",
        "print('fr_git_embed',len(fr_git_embed.keys()))\n",
        "print('it_git_embed',len(it_git_embed.keys()))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de_git_embed 64412\n",
            "fr_git_embed 43013\n",
            "it_git_embed 1984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUHuEX0X3zq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in de_git_embed.keys():\n",
        "    if word in fr_git_embed.keys():\n",
        "        if word in it_git_embed.keys():\n",
        "            avg_vec = (de_git_embed[word] + fr_git_embed[word] + it_git_embed[word]) /3\n",
        "            de_git_embed[word] = avg_vec\n",
        "            fr_git_embed[word] = avg_vec\n",
        "            it_git_embed[word] = avg_vec\n",
        "        else:\n",
        "            avg_vec = (de_git_embed[word] + fr_git_embed[word] ) /2\n",
        "            de_git_embed[word] = avg_vec\n",
        "            fr_git_embed[word] = avg_vec\n",
        "    elif word in it_git_embed.keys():\n",
        "        avg_vec = (de_git_embed[word] + it_git_embed[word] ) /2\n",
        "        de_git_embed[word] = avg_vec\n",
        "        it_git_embed[word] = avg_vec\n",
        "\n",
        "for word in fr_git_embed.keys():\n",
        "    if word in it_git_embed.keys():\n",
        "        avg_vec = (it_git_embed[word] + fr_git_embed[word] ) /2\n",
        "        fr_git_embed[word] = avg_vec\n",
        "        it_git_embed[word] = avg_vec"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcePY6XPzwca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if False:\n",
        "    X_train_emb_de = np.array(list(model_helper.text_to_embed(X_train_de, de_git_embed,  seq_len=seq_len)))\n",
        "    X_val_emb_de = np.array(list(model_helper.text_to_embed(X_val_de,  de_git_embed,  seq_len=seq_len)))\n",
        "    X_test_emb_de = np.array(list(model_helper.text_to_embed(X_test_de, de_git_embed,  seq_len=seq_len)))\n",
        "\n",
        "    X_train_emb_fr = np.array(list(model_helper.text_to_embed(X_train_fr, fr_git_embed, seq_len=seq_len)))\n",
        "    X_val_emb_fr = np.array(list(model_helper.text_to_embed(X_val_fr, fr_git_embed, seq_len=seq_len)))\n",
        "    X_test_emb_fr = np.array(list(model_helper.text_to_embed(X_test_fr, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "    X_emb_it = np.array(list(model_helper.text_to_embed(X_it, it_git_embed,  seq_len=seq_len)))\n",
        "\n",
        "    print('de',X_train_emb_de.shape, X_val_emb_de.shape, X_test_emb_de.shape)\n",
        "    print('fr',X_train_emb_fr.shape, X_val_emb_fr.shape, X_test_emb_fr.shape)\n",
        "    print('it',X_emb_it.shape)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekCBr3pIzkf6",
        "colab_type": "text"
      },
      "source": [
        "### Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOuPZPvwzsct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f3e54bc3-a35f-4395-86fd-345df55c35d0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer_de = Tokenizer()\n",
        "tokenizer_de.fit_on_texts(X_train_de.append(X_val_de))\n",
        "vocab_size_de = len(tokenizer_de.word_index) + 1\n",
        "\n",
        "tokenizer_fr = Tokenizer()\n",
        "tokenizer_fr.fit_on_texts(X_train_fr.append(X_val_fr))\n",
        "vocab_size_fr = len(tokenizer_fr.word_index) + 1\n",
        "\n",
        "tokenizer_it = Tokenizer()\n",
        "tokenizer_it.fit_on_texts(X_it)\n",
        "vocab_size_it = len(tokenizer_it.word_index) + 1\n",
        "\n",
        "tokenizer_all = Tokenizer()\n",
        "tokenizer_all.fit_on_texts(X_train_de.append(X_val_de).append(X_train_fr).append(X_val_fr).append(X_it))\n",
        "\n",
        "vocab_size_all = len(tokenizer_all.word_index) + 1\n",
        "print(vocab_size_de,vocab_size_fr,vocab_size_it,vocab_size_all)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16837 6977 1664 22908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FePPPZvSz6rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#german\n",
        "X_train_tokens_de = tokenizer_all.texts_to_sequences(X_train_de)\n",
        "X_val_tokens_de = tokenizer_all.texts_to_sequences(X_val_de)\n",
        "X_test_tokens_de = tokenizer_all.texts_to_sequences(X_test_de)\n",
        "\n",
        "X_train_pad_de = pad_sequences(X_train_tokens_de,maxlen=seq_len, padding='post')\n",
        "X_val_pad_de = pad_sequences(X_val_tokens_de,maxlen=seq_len, padding='post')\n",
        "X_test_pad_de = pad_sequences(X_test_tokens_de,maxlen=seq_len, padding='post')\n",
        "\n",
        "#french\n",
        "X_train_tokens_fr = tokenizer_all.texts_to_sequences(X_train_fr)\n",
        "X_val_tokens_fr = tokenizer_all.texts_to_sequences(X_val_fr)\n",
        "X_test_tokens_fr = tokenizer_all.texts_to_sequences(X_test_fr)\n",
        "\n",
        "X_train_pad_fr = pad_sequences(X_train_tokens_fr,maxlen=seq_len, padding='post')\n",
        "X_val_pad_fr = pad_sequences(X_val_tokens_fr,maxlen=seq_len, padding='post')\n",
        "X_test_pad_fr = pad_sequences(X_test_tokens_fr,maxlen=seq_len, padding='post')\n",
        "\n",
        "X_tokens_it = tokenizer_all.texts_to_sequences(X_it)\n",
        "X_pad_it = pad_sequences(X_tokens_it,maxlen=seq_len, padding='post')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "087hB6Ghz-8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unknown = np.random.rand(embedding_dim)\n",
        "\n",
        "def get_embed_matrix(embed,tokenizer,vocab_size,embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word,i in tokenizer.word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embed[word]\n",
        "        except KeyError:\n",
        "            #next\n",
        "            embedding_matrix[i] = unknown #np.random.rand(embedding_dim)\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix_de = get_embed_matrix(de_git_embed,tokenizer_de,vocab_size_de,embedding_dim)\n",
        "embedding_matrix_fr = get_embed_matrix(fr_git_embed,tokenizer_fr,vocab_size_fr,embedding_dim)\n",
        "embedding_matrix_it = get_embed_matrix(it_git_embed,tokenizer_it,vocab_size_it,embedding_dim)\n",
        "\n",
        "combine_embed = de_git_embed\n",
        "combine_embed.update(fr_git_embed)\n",
        "combine_embed.update(it_git_embed)\n",
        "embedding_matrix_all = get_embed_matrix(combine_embed,tokenizer_all ,vocab_size_all ,embedding_dim)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-x_ATGL_juK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "de_fr_voc = [ w for w in list(tokenizer_de.word_index.keys()) if w in list(tokenizer_fr.word_index.keys())]\n",
        "de_it_voc = [ w for w in list(tokenizer_de.word_index.keys()) if w in list(tokenizer_it.word_index.keys())]\n",
        "fr_it_voc = [ w for w in list(tokenizer_fr.word_index.keys()) if w in list(tokenizer_it.word_index.keys())]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJh91fJt_S0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "25dc12d7-e958-404e-bbd0-003d26971997"
      },
      "source": [
        "len(de_fr_voc), len(de_it_voc), len(fr_it_voc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1881, 590, 495)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1yi4_LEz0d8",
        "colab_type": "text"
      },
      "source": [
        "### LAbel Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjZke3ew9XYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d080f8da-3a98-43ac-d2aa-69e10c00f648"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_de['cc5'])\n",
        "\n",
        "def encode_label(y_):\n",
        "    y__ = encoder.transform(y_)\n",
        "    y_enc =tf.keras.utils.to_categorical(y__, num_classes=no_Classes, dtype=\"float32\")\n",
        "    return y_enc\n",
        "\n",
        "y_train_enc_de = encode_label(y_train_de)\n",
        "y_val_enc_de = encode_label(y_val_de)\n",
        "y_test_enc_de = encode_label(y_test_de)\n",
        "\n",
        "y_train_enc_fr = encode_label(y_train_fr)\n",
        "y_val_enc_fr = encode_label(y_val_fr)\n",
        "y_test_enc_fr = encode_label(y_test_fr)\n",
        "\n",
        "y_enc_it = encode_label(y_it)\n",
        "\n",
        "print(y_train_enc_de.shape,y_val_enc_de.shape,y_test_enc_de.shape)\n",
        "print(y_train_enc_fr.shape,y_val_enc_fr.shape,y_test_enc_fr.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23597, 75) (3933, 75) (3933, 75)\n",
            "(17124, 75) (2854, 75) (2855, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOG6Bc_RVe10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weigth_dict(y_train):\n",
        "    weights_dict = dict(zip(y_train.value_counts().index.tolist(),list(len(y_train) / ( len(y_train.unique())  * y_train.value_counts()))))\n",
        "\n",
        "    class_weight_dict = {}\n",
        "    for n,lab in enumerate(encoder.classes_):\n",
        "        try:\n",
        "            class_weight_dict[n] = weights_dict[lab]\n",
        "        except:\n",
        "            class_weight_dict[n] = 1\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict_de = get_weigth_dict(y_train_de)\n",
        "class_weight_dict_fr = get_weigth_dict(y_train_fr)\n",
        "class_weight_dict_de_fr = get_weigth_dict(y_train_de.append(y_train_fr))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09DZu4q4nouv",
        "colab_type": "text"
      },
      "source": [
        "# Single Language Classifier German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM_B87GsY7Yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "ac770362-3251-4404-d10f-d3a6eff69780"
      },
      "source": [
        "df_results = pd.DataFrame(columns=['model','task','metric','0','100','250','500','1000','2000','5000','10000','15000','25000','40000'])\n",
        "df_results"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [model, task, metric, 0, 100, 250, 500, 1000, 2000, 5000, 10000, 15000, 25000, 40000]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upNTfEpdntqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1GlmRV10qas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_df_res(y,pred,no):\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(pred, y),4)\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(pred, y)*len(np.unique(pred))/no_Classes,4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2q91oJWnttV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_log_reg(X_train,y_train,X_test,y_test,no):\n",
        "  \n",
        "    idx = np.random.randint(len(X_train), size=no)\n",
        "\n",
        "    X_train = [str(x) for x in X_train.iloc[idx]] #.replace('<','').replace('>','')\n",
        "    y_train = y_train.iloc[idx]\n",
        "    X_test = [str(x) for x in X_test]\n",
        "    vectorizer  = TfidfVectorizer()\n",
        "    vectorizer.fit(X_train)\n",
        "    X_train_vec = vectorizer.transform(X_train)\n",
        "    X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "    logreg = LogisticRegression(C=1,max_iter=500, solver='newton-cg')\n",
        "    logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred_test = logreg.predict(X_test_vec)\n",
        "    fill_df_res(y_pred_test,y_test,no)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNe84VIOxHo",
        "colab_type": "text"
      },
      "source": [
        "##LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKvBr7TGDR0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'LogReg'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000,25000]):\n",
        "    tf_idf_log_reg(X_train_de,y_train_de,X_test_de,y_test_de,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTK_iRAvb3EJ",
        "colab_type": "text"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y2Lozw3b3SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_avg_pool(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.4\n",
        "    filter_sizes =  [2,3,5]\n",
        "    num_filters = 75\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    pool_layer = GlobalAveragePooling1D()(embedd_seq)   \n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzPPr-vHb3Ph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0057d28-d3fd-4133-d7f1-3e0e7aeceacc"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000,25000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_avg_pool(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 34) (100, 75)\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_18 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 4.3867 - accuracy: 0.0200 - val_loss: 4.2998 - val_accuracy: 0.0122\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 4.3709 - accuracy: 0.0400 - val_loss: 4.2911 - val_accuracy: 0.0097\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 4.3338 - accuracy: 0.1000 - val_loss: 4.2832 - val_accuracy: 0.0102\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 4.3153 - accuracy: 0.0900 - val_loss: 4.2751 - val_accuracy: 0.0135\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 4.2864 - accuracy: 0.1000 - val_loss: 4.2677 - val_accuracy: 0.0173\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 4.2656 - accuracy: 0.1000 - val_loss: 4.2606 - val_accuracy: 0.0170\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 4.2346 - accuracy: 0.1200 - val_loss: 4.2538 - val_accuracy: 0.0178\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 4.2208 - accuracy: 0.1400 - val_loss: 4.2473 - val_accuracy: 0.0234\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 4.2012 - accuracy: 0.1200 - val_loss: 4.2411 - val_accuracy: 0.0264\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 4.1673 - accuracy: 0.1200 - val_loss: 4.2350 - val_accuracy: 0.0285\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 4.1490 - accuracy: 0.1400 - val_loss: 4.2287 - val_accuracy: 0.0353\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 4.1362 - accuracy: 0.1400 - val_loss: 4.2231 - val_accuracy: 0.0417\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 4.1025 - accuracy: 0.2000 - val_loss: 4.2178 - val_accuracy: 0.0478\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 4.0808 - accuracy: 0.1800 - val_loss: 4.2129 - val_accuracy: 0.0542\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 4.0542 - accuracy: 0.2600 - val_loss: 4.2081 - val_accuracy: 0.0567\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 4.0510 - accuracy: 0.2300 - val_loss: 4.2036 - val_accuracy: 0.0582\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 4.0196 - accuracy: 0.2000 - val_loss: 4.1997 - val_accuracy: 0.0600\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 3.9872 - accuracy: 0.3000 - val_loss: 4.1961 - val_accuracy: 0.0615\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 3.9622 - accuracy: 0.2700 - val_loss: 4.1927 - val_accuracy: 0.0674\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 3.9303 - accuracy: 0.2900 - val_loss: 4.1899 - val_accuracy: 0.0686\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 3.9182 - accuracy: 0.2700 - val_loss: 4.1879 - val_accuracy: 0.0692\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 3.8757 - accuracy: 0.2700 - val_loss: 4.1862 - val_accuracy: 0.0697\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 3.8502 - accuracy: 0.2800 - val_loss: 4.1851 - val_accuracy: 0.0717\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 3.8411 - accuracy: 0.2300 - val_loss: 4.1839 - val_accuracy: 0.0722\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 3.7975 - accuracy: 0.3000 - val_loss: 4.1825 - val_accuracy: 0.0722\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 3.7709 - accuracy: 0.2900 - val_loss: 4.1817 - val_accuracy: 0.0737\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 3.7520 - accuracy: 0.3000 - val_loss: 4.1816 - val_accuracy: 0.0745\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 3.7443 - accuracy: 0.2600 - val_loss: 4.1816 - val_accuracy: 0.0735\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 3.7001 - accuracy: 0.2800 - val_loss: 4.1820 - val_accuracy: 0.0717\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 3.6792 - accuracy: 0.3100 - val_loss: 4.1835 - val_accuracy: 0.0697\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 3.6395 - accuracy: 0.2900 - val_loss: 4.1858 - val_accuracy: 0.0689\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 3.6250 - accuracy: 0.2800 - val_loss: 4.1883 - val_accuracy: 0.0694\n",
            "\n",
            "de 0.0742\n",
            "fr 0.0231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 11%|█         | 1/9 [00:14<01:52, 14.04s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0255\n",
            "(250, 34) (250, 75)\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 4.2220 - accuracy: 0.0280 - val_loss: 4.2772 - val_accuracy: 0.0064\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 4.2004 - accuracy: 0.0800 - val_loss: 4.2599 - val_accuracy: 0.0135\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 4.1690 - accuracy: 0.0920 - val_loss: 4.2419 - val_accuracy: 0.0262\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 4.1405 - accuracy: 0.1480 - val_loss: 4.2256 - val_accuracy: 0.0343\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 104ms/step - loss: 4.1018 - accuracy: 0.1800 - val_loss: 4.2099 - val_accuracy: 0.0359\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 4.0796 - accuracy: 0.1320 - val_loss: 4.1953 - val_accuracy: 0.0374\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 4.0477 - accuracy: 0.1320 - val_loss: 4.1811 - val_accuracy: 0.0381\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 4.0101 - accuracy: 0.1680 - val_loss: 4.1689 - val_accuracy: 0.0389\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 3.9841 - accuracy: 0.1440 - val_loss: 4.1586 - val_accuracy: 0.0305\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 3.9786 - accuracy: 0.1200 - val_loss: 4.1479 - val_accuracy: 0.0272\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 3.9233 - accuracy: 0.1200 - val_loss: 4.1392 - val_accuracy: 0.0239\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.9041 - accuracy: 0.1120 - val_loss: 4.1314 - val_accuracy: 0.0211\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 3.8742 - accuracy: 0.1080 - val_loss: 4.1250 - val_accuracy: 0.0145\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.8250 - accuracy: 0.1240 - val_loss: 4.1177 - val_accuracy: 0.0142\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.8116 - accuracy: 0.1080 - val_loss: 4.1138 - val_accuracy: 0.0104\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 104ms/step - loss: 3.7819 - accuracy: 0.1160 - val_loss: 4.1110 - val_accuracy: 0.0084\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 3.7423 - accuracy: 0.0920 - val_loss: 4.1082 - val_accuracy: 0.0081\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.7064 - accuracy: 0.0960 - val_loss: 4.1065 - val_accuracy: 0.0066\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.6801 - accuracy: 0.0920 - val_loss: 4.1057 - val_accuracy: 0.0066\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 3.6483 - accuracy: 0.0800 - val_loss: 4.1064 - val_accuracy: 0.0066\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 3.6150 - accuracy: 0.0920 - val_loss: 4.1063 - val_accuracy: 0.0074\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 3.5899 - accuracy: 0.0960 - val_loss: 4.1047 - val_accuracy: 0.0079\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 3.5669 - accuracy: 0.0640 - val_loss: 4.1061 - val_accuracy: 0.0086\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 3.5357 - accuracy: 0.0840 - val_loss: 4.1062 - val_accuracy: 0.0094\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 3.4999 - accuracy: 0.0960 - val_loss: 4.1048 - val_accuracy: 0.0097\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.4851 - accuracy: 0.1040 - val_loss: 4.1041 - val_accuracy: 0.0104\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.4718 - accuracy: 0.0920 - val_loss: 4.1040 - val_accuracy: 0.0120\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 3.4148 - accuracy: 0.1040 - val_loss: 4.1020 - val_accuracy: 0.0147\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.4060 - accuracy: 0.1120 - val_loss: 4.0997 - val_accuracy: 0.0168\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 3.3679 - accuracy: 0.1080 - val_loss: 4.0925 - val_accuracy: 0.0216\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 3.3461 - accuracy: 0.1280 - val_loss: 4.0899 - val_accuracy: 0.0244\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 3.3249 - accuracy: 0.1360 - val_loss: 4.0812 - val_accuracy: 0.0300\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.3006 - accuracy: 0.1360 - val_loss: 4.0723 - val_accuracy: 0.0346\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 3.2658 - accuracy: 0.1760 - val_loss: 4.0606 - val_accuracy: 0.0445\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 3.2533 - accuracy: 0.1960 - val_loss: 4.0455 - val_accuracy: 0.0552\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 3.2214 - accuracy: 0.1960 - val_loss: 4.0293 - val_accuracy: 0.0666\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 3.1977 - accuracy: 0.2600 - val_loss: 4.0120 - val_accuracy: 0.0801\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 3.1863 - accuracy: 0.2520 - val_loss: 3.9947 - val_accuracy: 0.0933\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 3.1356 - accuracy: 0.2880 - val_loss: 3.9767 - val_accuracy: 0.1060\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 3.1165 - accuracy: 0.2960 - val_loss: 3.9567 - val_accuracy: 0.1190\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 3.1025 - accuracy: 0.3240 - val_loss: 3.9345 - val_accuracy: 0.1297\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.0560 - accuracy: 0.3440 - val_loss: 3.9163 - val_accuracy: 0.1419\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 3.0227 - accuracy: 0.3720 - val_loss: 3.8980 - val_accuracy: 0.1515\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.9987 - accuracy: 0.3880 - val_loss: 3.8749 - val_accuracy: 0.1645\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.9601 - accuracy: 0.4240 - val_loss: 3.8494 - val_accuracy: 0.1820\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.9430 - accuracy: 0.4280 - val_loss: 3.8269 - val_accuracy: 0.1960\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 2.8984 - accuracy: 0.4560 - val_loss: 3.8011 - val_accuracy: 0.2077\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 2.8916 - accuracy: 0.4880 - val_loss: 3.7780 - val_accuracy: 0.2171\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 2.8397 - accuracy: 0.4880 - val_loss: 3.7523 - val_accuracy: 0.2286\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 2.7989 - accuracy: 0.5200 - val_loss: 3.7264 - val_accuracy: 0.2405\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 2.7833 - accuracy: 0.5160 - val_loss: 3.7011 - val_accuracy: 0.2466\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.7514 - accuracy: 0.5480 - val_loss: 3.6753 - val_accuracy: 0.2545\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 2.7103 - accuracy: 0.5400 - val_loss: 3.6478 - val_accuracy: 0.2644\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 2.7128 - accuracy: 0.5680 - val_loss: 3.6224 - val_accuracy: 0.2754\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 2.6388 - accuracy: 0.5920 - val_loss: 3.5972 - val_accuracy: 0.2820\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 2.5987 - accuracy: 0.5840 - val_loss: 3.5687 - val_accuracy: 0.2927\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 2.5916 - accuracy: 0.5920 - val_loss: 3.5430 - val_accuracy: 0.2972\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 2.5538 - accuracy: 0.6040 - val_loss: 3.5152 - val_accuracy: 0.3087\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 2.5053 - accuracy: 0.6200 - val_loss: 3.4904 - val_accuracy: 0.3163\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 2.4756 - accuracy: 0.6320 - val_loss: 3.4649 - val_accuracy: 0.3265\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 2.4366 - accuracy: 0.6360 - val_loss: 3.4407 - val_accuracy: 0.3341\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 2.3928 - accuracy: 0.6360 - val_loss: 3.4192 - val_accuracy: 0.3405\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.3492 - accuracy: 0.6640 - val_loss: 3.3973 - val_accuracy: 0.3471\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 2.3365 - accuracy: 0.6640 - val_loss: 3.3734 - val_accuracy: 0.3514\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 2.2934 - accuracy: 0.6760 - val_loss: 3.3514 - val_accuracy: 0.3583\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 2.2581 - accuracy: 0.6880 - val_loss: 3.3275 - val_accuracy: 0.3677\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 2.2297 - accuracy: 0.6960 - val_loss: 3.3049 - val_accuracy: 0.3722\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 2.1822 - accuracy: 0.7000 - val_loss: 3.2817 - val_accuracy: 0.3799\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.1521 - accuracy: 0.6880 - val_loss: 3.2603 - val_accuracy: 0.3855\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 2.1172 - accuracy: 0.7160 - val_loss: 3.2391 - val_accuracy: 0.3898\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 2.0787 - accuracy: 0.7400 - val_loss: 3.2159 - val_accuracy: 0.3959\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 2.0316 - accuracy: 0.7400 - val_loss: 3.1931 - val_accuracy: 0.4012\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.9999 - accuracy: 0.7360 - val_loss: 3.1735 - val_accuracy: 0.4068\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 1.9772 - accuracy: 0.7360 - val_loss: 3.1515 - val_accuracy: 0.4175\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 1.9499 - accuracy: 0.7760 - val_loss: 3.1302 - val_accuracy: 0.4238\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.8969 - accuracy: 0.7640 - val_loss: 3.1106 - val_accuracy: 0.4282\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 1.8643 - accuracy: 0.7640 - val_loss: 3.0903 - val_accuracy: 0.4327\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.8163 - accuracy: 0.7920 - val_loss: 3.0713 - val_accuracy: 0.4391\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 1.8126 - accuracy: 0.8000 - val_loss: 3.0515 - val_accuracy: 0.4439\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.7594 - accuracy: 0.7920 - val_loss: 3.0336 - val_accuracy: 0.4470\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.7021 - accuracy: 0.8200 - val_loss: 3.0152 - val_accuracy: 0.4539\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.6874 - accuracy: 0.8320 - val_loss: 2.9953 - val_accuracy: 0.4643\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 1.6881 - accuracy: 0.8160 - val_loss: 2.9777 - val_accuracy: 0.4678\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.6288 - accuracy: 0.8160 - val_loss: 2.9596 - val_accuracy: 0.4732\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.5964 - accuracy: 0.8200 - val_loss: 2.9446 - val_accuracy: 0.4780\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.5809 - accuracy: 0.8200 - val_loss: 2.9276 - val_accuracy: 0.4803\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 101ms/step - loss: 1.5567 - accuracy: 0.8360 - val_loss: 2.9109 - val_accuracy: 0.4833\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 1.5291 - accuracy: 0.8280 - val_loss: 2.8932 - val_accuracy: 0.4869\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.4876 - accuracy: 0.8440 - val_loss: 2.8766 - val_accuracy: 0.4905\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 1.4695 - accuracy: 0.8320 - val_loss: 2.8623 - val_accuracy: 0.4912\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.4383 - accuracy: 0.8600 - val_loss: 2.8467 - val_accuracy: 0.4938\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.4088 - accuracy: 0.8440 - val_loss: 2.8311 - val_accuracy: 0.4973\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 1.4109 - accuracy: 0.8480 - val_loss: 2.8158 - val_accuracy: 0.4994\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.3730 - accuracy: 0.8760 - val_loss: 2.8010 - val_accuracy: 0.5032\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.3172 - accuracy: 0.8720 - val_loss: 2.7878 - val_accuracy: 0.5075\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.3289 - accuracy: 0.8640 - val_loss: 2.7738 - val_accuracy: 0.5088\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 1.2805 - accuracy: 0.8720 - val_loss: 2.7596 - val_accuracy: 0.5121\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.2771 - accuracy: 0.8560 - val_loss: 2.7462 - val_accuracy: 0.5146\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 1.2608 - accuracy: 0.8720 - val_loss: 2.7329 - val_accuracy: 0.5151\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.2243 - accuracy: 0.8760 - val_loss: 2.7184 - val_accuracy: 0.5172\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 1.2132 - accuracy: 0.8680 - val_loss: 2.7051 - val_accuracy: 0.5187\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.2089 - accuracy: 0.8840 - val_loss: 2.6924 - val_accuracy: 0.5207\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.1660 - accuracy: 0.8880 - val_loss: 2.6800 - val_accuracy: 0.5228\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.1417 - accuracy: 0.8920 - val_loss: 2.6670 - val_accuracy: 0.5240\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.1700 - accuracy: 0.8840 - val_loss: 2.6546 - val_accuracy: 0.5286\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.0878 - accuracy: 0.8920 - val_loss: 2.6414 - val_accuracy: 0.5337\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 1.1051 - accuracy: 0.8800 - val_loss: 2.6296 - val_accuracy: 0.5352\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 1.0750 - accuracy: 0.8920 - val_loss: 2.6178 - val_accuracy: 0.5380\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.0722 - accuracy: 0.8920 - val_loss: 2.6061 - val_accuracy: 0.5388\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 1.0418 - accuracy: 0.9000 - val_loss: 2.5945 - val_accuracy: 0.5400\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.0218 - accuracy: 0.9040 - val_loss: 2.5832 - val_accuracy: 0.5418\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 1.0144 - accuracy: 0.8960 - val_loss: 2.5715 - val_accuracy: 0.5436\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 1.0041 - accuracy: 0.8960 - val_loss: 2.5603 - val_accuracy: 0.5467\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.9782 - accuracy: 0.9040 - val_loss: 2.5503 - val_accuracy: 0.5482\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.9529 - accuracy: 0.9000 - val_loss: 2.5397 - val_accuracy: 0.5495\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.9396 - accuracy: 0.9120 - val_loss: 2.5292 - val_accuracy: 0.5512\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 0.9290 - accuracy: 0.9000 - val_loss: 2.5189 - val_accuracy: 0.5523\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.9155 - accuracy: 0.9040 - val_loss: 2.5090 - val_accuracy: 0.5533\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.8948 - accuracy: 0.9120 - val_loss: 2.4987 - val_accuracy: 0.5543\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 0.8897 - accuracy: 0.9200 - val_loss: 2.4903 - val_accuracy: 0.5553\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 0.8654 - accuracy: 0.9160 - val_loss: 2.4824 - val_accuracy: 0.5563\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.8708 - accuracy: 0.9160 - val_loss: 2.4731 - val_accuracy: 0.5578\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.8661 - accuracy: 0.9120 - val_loss: 2.4648 - val_accuracy: 0.5604\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.8150 - accuracy: 0.9200 - val_loss: 2.4559 - val_accuracy: 0.5611\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.8254 - accuracy: 0.9320 - val_loss: 2.4476 - val_accuracy: 0.5647\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 0.8298 - accuracy: 0.9200 - val_loss: 2.4394 - val_accuracy: 0.5667\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 0.8142 - accuracy: 0.9280 - val_loss: 2.4308 - val_accuracy: 0.5736\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.7874 - accuracy: 0.9200 - val_loss: 2.4231 - val_accuracy: 0.5751\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 0.7683 - accuracy: 0.9240 - val_loss: 2.4148 - val_accuracy: 0.5762\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.7602 - accuracy: 0.9280 - val_loss: 2.4067 - val_accuracy: 0.5769\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.7760 - accuracy: 0.9280 - val_loss: 2.3994 - val_accuracy: 0.5784\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.7483 - accuracy: 0.9400 - val_loss: 2.3914 - val_accuracy: 0.5802\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.7415 - accuracy: 0.9320 - val_loss: 2.3838 - val_accuracy: 0.5810\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.7380 - accuracy: 0.9440 - val_loss: 2.3769 - val_accuracy: 0.5825\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.7193 - accuracy: 0.9360 - val_loss: 2.3695 - val_accuracy: 0.5830\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.7052 - accuracy: 0.9400 - val_loss: 2.3624 - val_accuracy: 0.5856\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 0.7005 - accuracy: 0.9360 - val_loss: 2.3552 - val_accuracy: 0.5858\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.6950 - accuracy: 0.9400 - val_loss: 2.3477 - val_accuracy: 0.5868\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.6694 - accuracy: 0.9480 - val_loss: 2.3407 - val_accuracy: 0.5878\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 0.6504 - accuracy: 0.9440 - val_loss: 2.3337 - val_accuracy: 0.5886\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.6630 - accuracy: 0.9400 - val_loss: 2.3271 - val_accuracy: 0.5912\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.6416 - accuracy: 0.9320 - val_loss: 2.3201 - val_accuracy: 0.5917\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.6207 - accuracy: 0.9440 - val_loss: 2.3136 - val_accuracy: 0.5927\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 100ms/step - loss: 0.6219 - accuracy: 0.9480 - val_loss: 2.3071 - val_accuracy: 0.5932\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.6402 - accuracy: 0.9400 - val_loss: 2.2999 - val_accuracy: 0.5937\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.6044 - accuracy: 0.9560 - val_loss: 2.2941 - val_accuracy: 0.5947\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.9440 - val_loss: 2.2880 - val_accuracy: 0.5975\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.5948 - accuracy: 0.9480 - val_loss: 2.2818 - val_accuracy: 0.5983\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.5854 - accuracy: 0.9520 - val_loss: 2.2763 - val_accuracy: 0.5998\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 0.5958 - accuracy: 0.9480 - val_loss: 2.2704 - val_accuracy: 0.6006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 22%|██▏       | 2/9 [01:25<03:38, 31.14s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.6102\n",
            "fr 0.0655\n",
            "it 0.0195\n",
            "(500, 34) (500, 75)\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_20 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 4.6365 - accuracy: 0.0200 - val_loss: 4.2893 - val_accuracy: 0.0331\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 4.6121 - accuracy: 0.0640 - val_loss: 4.2679 - val_accuracy: 0.0552\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 4.5657 - accuracy: 0.1120 - val_loss: 4.2494 - val_accuracy: 0.0781\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.5302 - accuracy: 0.1720 - val_loss: 4.2302 - val_accuracy: 0.0926\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 4.4771 - accuracy: 0.1680 - val_loss: 4.2112 - val_accuracy: 0.1007\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 4.4438 - accuracy: 0.1800 - val_loss: 4.1962 - val_accuracy: 0.0890\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 4.3940 - accuracy: 0.1920 - val_loss: 4.1788 - val_accuracy: 0.0826\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.3623 - accuracy: 0.1580 - val_loss: 4.1675 - val_accuracy: 0.0704\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.3186 - accuracy: 0.1760 - val_loss: 4.1534 - val_accuracy: 0.0623\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 4.2802 - accuracy: 0.1680 - val_loss: 4.1343 - val_accuracy: 0.0735\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.2290 - accuracy: 0.1820 - val_loss: 4.1213 - val_accuracy: 0.0712\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 4.1897 - accuracy: 0.1700 - val_loss: 4.1046 - val_accuracy: 0.0755\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 4.1425 - accuracy: 0.1740 - val_loss: 4.0875 - val_accuracy: 0.0768\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.1023 - accuracy: 0.1940 - val_loss: 4.0720 - val_accuracy: 0.0781\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.0742 - accuracy: 0.1760 - val_loss: 4.0518 - val_accuracy: 0.0852\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 4.0244 - accuracy: 0.2200 - val_loss: 4.0239 - val_accuracy: 0.1050\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 3.9870 - accuracy: 0.2320 - val_loss: 3.9950 - val_accuracy: 0.1348\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.9389 - accuracy: 0.2580 - val_loss: 3.9640 - val_accuracy: 0.1526\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 3.8905 - accuracy: 0.2780 - val_loss: 3.9234 - val_accuracy: 0.1803\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 3.8337 - accuracy: 0.3020 - val_loss: 3.8909 - val_accuracy: 0.1968\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 3.7975 - accuracy: 0.3300 - val_loss: 3.8449 - val_accuracy: 0.2184\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.7573 - accuracy: 0.3480 - val_loss: 3.8002 - val_accuracy: 0.2408\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 3.6933 - accuracy: 0.3800 - val_loss: 3.7540 - val_accuracy: 0.2596\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.6539 - accuracy: 0.3980 - val_loss: 3.7056 - val_accuracy: 0.2733\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 3.6070 - accuracy: 0.4100 - val_loss: 3.6540 - val_accuracy: 0.2868\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 3.5494 - accuracy: 0.4220 - val_loss: 3.5937 - val_accuracy: 0.2977\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 3.4825 - accuracy: 0.4420 - val_loss: 3.5359 - val_accuracy: 0.3089\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 3.4498 - accuracy: 0.4700 - val_loss: 3.4734 - val_accuracy: 0.3201\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.3813 - accuracy: 0.5080 - val_loss: 3.4195 - val_accuracy: 0.3262\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 3.3719 - accuracy: 0.5040 - val_loss: 3.3616 - val_accuracy: 0.3354\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 3.3079 - accuracy: 0.5300 - val_loss: 3.3077 - val_accuracy: 0.3443\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.2296 - accuracy: 0.5440 - val_loss: 3.2539 - val_accuracy: 0.3499\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 3.1623 - accuracy: 0.5600 - val_loss: 3.1997 - val_accuracy: 0.3595\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 3.1383 - accuracy: 0.5600 - val_loss: 3.1513 - val_accuracy: 0.3651\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 3.0592 - accuracy: 0.5720 - val_loss: 3.1033 - val_accuracy: 0.3735\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 3.0120 - accuracy: 0.5860 - val_loss: 3.0558 - val_accuracy: 0.3801\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 2.9436 - accuracy: 0.5900 - val_loss: 3.0112 - val_accuracy: 0.3852\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 2.8885 - accuracy: 0.6140 - val_loss: 2.9698 - val_accuracy: 0.3911\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 2.8278 - accuracy: 0.6160 - val_loss: 2.9285 - val_accuracy: 0.3994\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 2.7799 - accuracy: 0.6380 - val_loss: 2.8885 - val_accuracy: 0.4076\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 2.7072 - accuracy: 0.6540 - val_loss: 2.8500 - val_accuracy: 0.4200\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 2.6640 - accuracy: 0.6620 - val_loss: 2.8149 - val_accuracy: 0.4261\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 2.5905 - accuracy: 0.6740 - val_loss: 2.7800 - val_accuracy: 0.4333\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 2.5488 - accuracy: 0.6760 - val_loss: 2.7456 - val_accuracy: 0.4447\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 2.4814 - accuracy: 0.6840 - val_loss: 2.7093 - val_accuracy: 0.4544\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 2.4437 - accuracy: 0.6820 - val_loss: 2.6774 - val_accuracy: 0.4607\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 2.3747 - accuracy: 0.6860 - val_loss: 2.6454 - val_accuracy: 0.4681\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 2.3516 - accuracy: 0.7020 - val_loss: 2.6120 - val_accuracy: 0.4752\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 2.2418 - accuracy: 0.7240 - val_loss: 2.5780 - val_accuracy: 0.4864\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 2.1987 - accuracy: 0.7340 - val_loss: 2.5467 - val_accuracy: 0.4925\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 2.1524 - accuracy: 0.7460 - val_loss: 2.5159 - val_accuracy: 0.5014\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 2.1105 - accuracy: 0.7500 - val_loss: 2.4841 - val_accuracy: 0.5128\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 2.0510 - accuracy: 0.7540 - val_loss: 2.4551 - val_accuracy: 0.5164\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.9860 - accuracy: 0.7660 - val_loss: 2.4233 - val_accuracy: 0.5268\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.9588 - accuracy: 0.7780 - val_loss: 2.3934 - val_accuracy: 0.5365\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.9112 - accuracy: 0.7800 - val_loss: 2.3661 - val_accuracy: 0.5456\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.8557 - accuracy: 0.7840 - val_loss: 2.3394 - val_accuracy: 0.5512\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.8010 - accuracy: 0.7940 - val_loss: 2.3122 - val_accuracy: 0.5589\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7886 - accuracy: 0.8000 - val_loss: 2.2884 - val_accuracy: 0.5627\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7279 - accuracy: 0.8020 - val_loss: 2.2623 - val_accuracy: 0.5693\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6787 - accuracy: 0.8060 - val_loss: 2.2369 - val_accuracy: 0.5713\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.6626 - accuracy: 0.8100 - val_loss: 2.2122 - val_accuracy: 0.5751\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 1.6379 - accuracy: 0.8260 - val_loss: 2.1873 - val_accuracy: 0.5845\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5500 - accuracy: 0.8380 - val_loss: 2.1657 - val_accuracy: 0.5934\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5324 - accuracy: 0.8320 - val_loss: 2.1424 - val_accuracy: 0.6046\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5179 - accuracy: 0.8340 - val_loss: 2.1190 - val_accuracy: 0.6087\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.4498 - accuracy: 0.8620 - val_loss: 2.0981 - val_accuracy: 0.6138\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.4170 - accuracy: 0.8660 - val_loss: 2.0774 - val_accuracy: 0.6178\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.3935 - accuracy: 0.8540 - val_loss: 2.0580 - val_accuracy: 0.6206\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.3462 - accuracy: 0.8600 - val_loss: 2.0379 - val_accuracy: 0.6245\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.3263 - accuracy: 0.8720 - val_loss: 2.0178 - val_accuracy: 0.6290\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.3099 - accuracy: 0.8780 - val_loss: 1.9979 - val_accuracy: 0.6390\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.2592 - accuracy: 0.8840 - val_loss: 1.9785 - val_accuracy: 0.6443\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.2463 - accuracy: 0.8860 - val_loss: 1.9590 - val_accuracy: 0.6509\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.2245 - accuracy: 0.8860 - val_loss: 1.9423 - val_accuracy: 0.6552\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.1747 - accuracy: 0.8880 - val_loss: 1.9253 - val_accuracy: 0.6616\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.1568 - accuracy: 0.9040 - val_loss: 1.9082 - val_accuracy: 0.6677\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.1259 - accuracy: 0.9040 - val_loss: 1.8905 - val_accuracy: 0.6733\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.0947 - accuracy: 0.9100 - val_loss: 1.8750 - val_accuracy: 0.6801\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.0792 - accuracy: 0.9060 - val_loss: 1.8588 - val_accuracy: 0.6857\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.0603 - accuracy: 0.9200 - val_loss: 1.8437 - val_accuracy: 0.6934\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.0340 - accuracy: 0.9160 - val_loss: 1.8270 - val_accuracy: 0.6995\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.0196 - accuracy: 0.9220 - val_loss: 1.8129 - val_accuracy: 0.7025\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.9848 - accuracy: 0.9260 - val_loss: 1.7967 - val_accuracy: 0.7063\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.9730 - accuracy: 0.9300 - val_loss: 1.7822 - val_accuracy: 0.7084\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.9609 - accuracy: 0.9300 - val_loss: 1.7683 - val_accuracy: 0.7101\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.9129 - accuracy: 0.9340 - val_loss: 1.7556 - val_accuracy: 0.7135\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.9163 - accuracy: 0.9320 - val_loss: 1.7413 - val_accuracy: 0.7155\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.8830 - accuracy: 0.9400 - val_loss: 1.7279 - val_accuracy: 0.7170\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.8676 - accuracy: 0.9420 - val_loss: 1.7142 - val_accuracy: 0.7193\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.8851 - accuracy: 0.9360 - val_loss: 1.7019 - val_accuracy: 0.7231\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.8316 - accuracy: 0.9480 - val_loss: 1.6889 - val_accuracy: 0.7239\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.8034 - accuracy: 0.9460 - val_loss: 1.6774 - val_accuracy: 0.7251\n",
            "Epoch 94/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.7917 - accuracy: 0.9480 - val_loss: 1.6663 - val_accuracy: 0.7264\n",
            "Epoch 95/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.7800 - accuracy: 0.9520 - val_loss: 1.6552 - val_accuracy: 0.7264\n",
            "Epoch 96/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.7745 - accuracy: 0.9480 - val_loss: 1.6441 - val_accuracy: 0.7287\n",
            "Epoch 97/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.7604 - accuracy: 0.9520 - val_loss: 1.6322 - val_accuracy: 0.7300\n",
            "Epoch 98/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.7548 - accuracy: 0.9480 - val_loss: 1.6213 - val_accuracy: 0.7323\n",
            "Epoch 99/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.7333 - accuracy: 0.9540 - val_loss: 1.6106 - val_accuracy: 0.7335\n",
            "Epoch 100/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.7122 - accuracy: 0.9540 - val_loss: 1.5986 - val_accuracy: 0.7351\n",
            "Epoch 101/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6925 - accuracy: 0.9600 - val_loss: 1.5882 - val_accuracy: 0.7361\n",
            "Epoch 102/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6690 - accuracy: 0.9520 - val_loss: 1.5774 - val_accuracy: 0.7384\n",
            "Epoch 103/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.6840 - accuracy: 0.9520 - val_loss: 1.5679 - val_accuracy: 0.7407\n",
            "Epoch 104/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6679 - accuracy: 0.9560 - val_loss: 1.5573 - val_accuracy: 0.7414\n",
            "Epoch 105/150\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.6347 - accuracy: 0.9600 - val_loss: 1.5480 - val_accuracy: 0.7432\n",
            "Epoch 106/150\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 0.6562 - accuracy: 0.9580 - val_loss: 1.5389 - val_accuracy: 0.7457\n",
            "Epoch 107/150\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.6205 - accuracy: 0.9640 - val_loss: 1.5310 - val_accuracy: 0.7455\n",
            "Epoch 108/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.6007 - accuracy: 0.9600 - val_loss: 1.5215 - val_accuracy: 0.7473\n",
            "Epoch 109/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.5867 - accuracy: 0.9640 - val_loss: 1.5124 - val_accuracy: 0.7480\n",
            "Epoch 110/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.5812 - accuracy: 0.9660 - val_loss: 1.5029 - val_accuracy: 0.7488\n",
            "Epoch 111/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.5561 - accuracy: 0.9700 - val_loss: 1.4928 - val_accuracy: 0.7496\n",
            "Epoch 112/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.5583 - accuracy: 0.9640 - val_loss: 1.4841 - val_accuracy: 0.7485\n",
            "Epoch 113/150\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.5405 - accuracy: 0.9620 - val_loss: 1.4761 - val_accuracy: 0.7503\n",
            "Epoch 114/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.5241 - accuracy: 0.9640 - val_loss: 1.4675 - val_accuracy: 0.7508\n",
            "Epoch 115/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.5290 - accuracy: 0.9660 - val_loss: 1.4595 - val_accuracy: 0.7516\n",
            "Epoch 116/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.5315 - accuracy: 0.9700 - val_loss: 1.4508 - val_accuracy: 0.7526\n",
            "Epoch 117/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.5038 - accuracy: 0.9700 - val_loss: 1.4440 - val_accuracy: 0.7534\n",
            "Epoch 118/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.4945 - accuracy: 0.9740 - val_loss: 1.4375 - val_accuracy: 0.7536\n",
            "Epoch 119/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.4748 - accuracy: 0.9740 - val_loss: 1.4301 - val_accuracy: 0.7539\n",
            "Epoch 120/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4931 - accuracy: 0.9660 - val_loss: 1.4230 - val_accuracy: 0.7554\n",
            "Epoch 121/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4659 - accuracy: 0.9740 - val_loss: 1.4156 - val_accuracy: 0.7562\n",
            "Epoch 122/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.4559 - accuracy: 0.9740 - val_loss: 1.4086 - val_accuracy: 0.7562\n",
            "Epoch 123/150\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.4429 - accuracy: 0.9760 - val_loss: 1.4010 - val_accuracy: 0.7564\n",
            "Epoch 124/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.4367 - accuracy: 0.9720 - val_loss: 1.3940 - val_accuracy: 0.7569\n",
            "Epoch 125/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4486 - accuracy: 0.9740 - val_loss: 1.3874 - val_accuracy: 0.7577\n",
            "Epoch 126/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4261 - accuracy: 0.9700 - val_loss: 1.3798 - val_accuracy: 0.7582\n",
            "Epoch 127/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.4204 - accuracy: 0.9760 - val_loss: 1.3724 - val_accuracy: 0.7590\n",
            "Epoch 128/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4033 - accuracy: 0.9780 - val_loss: 1.3655 - val_accuracy: 0.7618\n",
            "Epoch 129/150\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.4106 - accuracy: 0.9680 - val_loss: 1.3601 - val_accuracy: 0.7607\n",
            "Epoch 130/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.4063 - accuracy: 0.9740 - val_loss: 1.3549 - val_accuracy: 0.7607\n",
            "Epoch 131/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.4004 - accuracy: 0.9760 - val_loss: 1.3486 - val_accuracy: 0.7605\n",
            "Epoch 132/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.3797 - accuracy: 0.9800 - val_loss: 1.3409 - val_accuracy: 0.7613\n",
            "Epoch 133/150\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.3813 - accuracy: 0.9780 - val_loss: 1.3343 - val_accuracy: 0.7625\n",
            "Epoch 134/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.3588 - accuracy: 0.9820 - val_loss: 1.3287 - val_accuracy: 0.7628\n",
            "Epoch 135/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.3628 - accuracy: 0.9780 - val_loss: 1.3225 - val_accuracy: 0.7630\n",
            "Epoch 136/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.3667 - accuracy: 0.9800 - val_loss: 1.3169 - val_accuracy: 0.7640\n",
            "Epoch 137/150\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 0.3556 - accuracy: 0.9740 - val_loss: 1.3121 - val_accuracy: 0.7648\n",
            "Epoch 138/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.3372 - accuracy: 0.9760 - val_loss: 1.3070 - val_accuracy: 0.7666\n",
            "Epoch 139/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.3351 - accuracy: 0.9800 - val_loss: 1.3006 - val_accuracy: 0.7704\n",
            "Epoch 140/150\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.3341 - accuracy: 0.9760 - val_loss: 1.2950 - val_accuracy: 0.7724\n",
            "Epoch 141/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.3254 - accuracy: 0.9780 - val_loss: 1.2901 - val_accuracy: 0.7714\n",
            "Epoch 142/150\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.3314 - accuracy: 0.9880 - val_loss: 1.2851 - val_accuracy: 0.7717\n",
            "Epoch 143/150\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.3233 - accuracy: 0.9820 - val_loss: 1.2799 - val_accuracy: 0.7724\n",
            "Epoch 144/150\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.3152 - accuracy: 0.9800 - val_loss: 1.2753 - val_accuracy: 0.7763\n",
            "Epoch 145/150\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.3044 - accuracy: 0.9840 - val_loss: 1.2713 - val_accuracy: 0.7785\n",
            "Epoch 146/150\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.3094 - accuracy: 0.9860 - val_loss: 1.2658 - val_accuracy: 0.7798\n",
            "Epoch 147/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.3001 - accuracy: 0.9800 - val_loss: 1.2612 - val_accuracy: 0.7816\n",
            "Epoch 148/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.2990 - accuracy: 0.9840 - val_loss: 1.2560 - val_accuracy: 0.7824\n",
            "Epoch 149/150\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.2823 - accuracy: 0.9800 - val_loss: 1.2519 - val_accuracy: 0.7816\n",
            "Epoch 150/150\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.2762 - accuracy: 0.9880 - val_loss: 1.2476 - val_accuracy: 0.7818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 33%|███▎      | 3/9 [03:22<05:41, 56.97s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.79\n",
            "fr 0.1044\n",
            "it 0.0165\n",
            "(1000, 34) (1000, 75)\n",
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_21 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 4.2435 - accuracy: 0.0310 - val_loss: 4.2555 - val_accuracy: 0.0811\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 4.1914 - accuracy: 0.1970 - val_loss: 4.1960 - val_accuracy: 0.3316\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 4.1475 - accuracy: 0.3090 - val_loss: 4.1534 - val_accuracy: 0.3209\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 4.1123 - accuracy: 0.3580 - val_loss: 4.1042 - val_accuracy: 0.3265\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 4.0625 - accuracy: 0.3590 - val_loss: 4.0749 - val_accuracy: 0.2789\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 4.0138 - accuracy: 0.3510 - val_loss: 4.0331 - val_accuracy: 0.2871\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 3.9644 - accuracy: 0.3670 - val_loss: 3.9883 - val_accuracy: 0.2896\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 3.9149 - accuracy: 0.3890 - val_loss: 3.9273 - val_accuracy: 0.3094\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 3.8686 - accuracy: 0.4220 - val_loss: 3.8610 - val_accuracy: 0.3244\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 3.7993 - accuracy: 0.4370 - val_loss: 3.7836 - val_accuracy: 0.3397\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 3.7466 - accuracy: 0.4680 - val_loss: 3.6878 - val_accuracy: 0.3644\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 3.6904 - accuracy: 0.4950 - val_loss: 3.5874 - val_accuracy: 0.3844\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 3.6062 - accuracy: 0.5170 - val_loss: 3.4817 - val_accuracy: 0.4040\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 3.5380 - accuracy: 0.5480 - val_loss: 3.3606 - val_accuracy: 0.4211\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 3.4545 - accuracy: 0.5600 - val_loss: 3.2441 - val_accuracy: 0.4340\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 3.3758 - accuracy: 0.5860 - val_loss: 3.1331 - val_accuracy: 0.4493\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 3.3029 - accuracy: 0.6090 - val_loss: 3.0226 - val_accuracy: 0.4645\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 3.2193 - accuracy: 0.6260 - val_loss: 2.9185 - val_accuracy: 0.4900\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 3.1181 - accuracy: 0.6500 - val_loss: 2.8228 - val_accuracy: 0.5057\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 3.0507 - accuracy: 0.6580 - val_loss: 2.7378 - val_accuracy: 0.5177\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 2.9325 - accuracy: 0.6770 - val_loss: 2.6501 - val_accuracy: 0.5322\n",
            "Epoch 22/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 2.8497 - accuracy: 0.6960 - val_loss: 2.5832 - val_accuracy: 0.5406\n",
            "Epoch 23/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 2.7488 - accuracy: 0.7000 - val_loss: 2.5090 - val_accuracy: 0.5474\n",
            "Epoch 24/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 2.6656 - accuracy: 0.7150 - val_loss: 2.4334 - val_accuracy: 0.5594\n",
            "Epoch 25/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 2.5625 - accuracy: 0.7300 - val_loss: 2.3684 - val_accuracy: 0.5711\n",
            "Epoch 26/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 2.4612 - accuracy: 0.7410 - val_loss: 2.2986 - val_accuracy: 0.5784\n",
            "Epoch 27/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 2.3698 - accuracy: 0.7590 - val_loss: 2.2422 - val_accuracy: 0.5825\n",
            "Epoch 28/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 2.2987 - accuracy: 0.7580 - val_loss: 2.1812 - val_accuracy: 0.5970\n",
            "Epoch 29/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 2.1964 - accuracy: 0.7790 - val_loss: 2.1247 - val_accuracy: 0.6016\n",
            "Epoch 30/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 2.1115 - accuracy: 0.7970 - val_loss: 2.0698 - val_accuracy: 0.6110\n",
            "Epoch 31/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 2.0337 - accuracy: 0.8110 - val_loss: 2.0195 - val_accuracy: 0.6265\n",
            "Epoch 32/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.9452 - accuracy: 0.8230 - val_loss: 1.9647 - val_accuracy: 0.6387\n",
            "Epoch 33/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.8497 - accuracy: 0.8310 - val_loss: 1.9184 - val_accuracy: 0.6473\n",
            "Epoch 34/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 1.7976 - accuracy: 0.8400 - val_loss: 1.8741 - val_accuracy: 0.6512\n",
            "Epoch 35/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.7210 - accuracy: 0.8480 - val_loss: 1.8288 - val_accuracy: 0.6649\n",
            "Epoch 36/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 1.6239 - accuracy: 0.8600 - val_loss: 1.7850 - val_accuracy: 0.6697\n",
            "Epoch 37/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.5764 - accuracy: 0.8680 - val_loss: 1.7471 - val_accuracy: 0.6756\n",
            "Epoch 38/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 1.5065 - accuracy: 0.8740 - val_loss: 1.7092 - val_accuracy: 0.6885\n",
            "Epoch 39/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 1.4474 - accuracy: 0.8770 - val_loss: 1.6751 - val_accuracy: 0.6946\n",
            "Epoch 40/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.3817 - accuracy: 0.8780 - val_loss: 1.6370 - val_accuracy: 0.7007\n",
            "Epoch 41/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 1.3302 - accuracy: 0.8890 - val_loss: 1.5996 - val_accuracy: 0.7079\n",
            "Epoch 42/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 1.2581 - accuracy: 0.8970 - val_loss: 1.5667 - val_accuracy: 0.7119\n",
            "Epoch 43/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 1.2297 - accuracy: 0.8990 - val_loss: 1.5365 - val_accuracy: 0.7160\n",
            "Epoch 44/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 1.1804 - accuracy: 0.9050 - val_loss: 1.5034 - val_accuracy: 0.7229\n",
            "Epoch 45/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 1.1204 - accuracy: 0.9050 - val_loss: 1.4789 - val_accuracy: 0.7226\n",
            "Epoch 46/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 1.0808 - accuracy: 0.9150 - val_loss: 1.4496 - val_accuracy: 0.7330\n",
            "Epoch 47/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 1.0544 - accuracy: 0.9210 - val_loss: 1.4247 - val_accuracy: 0.7361\n",
            "Epoch 48/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 1.0279 - accuracy: 0.9220 - val_loss: 1.3936 - val_accuracy: 0.7429\n",
            "Epoch 49/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.9775 - accuracy: 0.9230 - val_loss: 1.3714 - val_accuracy: 0.7468\n",
            "Epoch 50/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.9297 - accuracy: 0.9310 - val_loss: 1.3442 - val_accuracy: 0.7508\n",
            "Epoch 51/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.9071 - accuracy: 0.9340 - val_loss: 1.3208 - val_accuracy: 0.7564\n",
            "Epoch 52/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.8588 - accuracy: 0.9440 - val_loss: 1.2979 - val_accuracy: 0.7615\n",
            "Epoch 53/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.8348 - accuracy: 0.9480 - val_loss: 1.2774 - val_accuracy: 0.7623\n",
            "Epoch 54/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.8176 - accuracy: 0.9450 - val_loss: 1.2603 - val_accuracy: 0.7661\n",
            "Epoch 55/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.7841 - accuracy: 0.9470 - val_loss: 1.2400 - val_accuracy: 0.7696\n",
            "Epoch 56/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.7558 - accuracy: 0.9480 - val_loss: 1.2212 - val_accuracy: 0.7709\n",
            "Epoch 57/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.7402 - accuracy: 0.9500 - val_loss: 1.2002 - val_accuracy: 0.7790\n",
            "Epoch 58/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.7100 - accuracy: 0.9550 - val_loss: 1.1816 - val_accuracy: 0.7869\n",
            "Epoch 59/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.6771 - accuracy: 0.9550 - val_loss: 1.1644 - val_accuracy: 0.7902\n",
            "Epoch 60/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.6679 - accuracy: 0.9590 - val_loss: 1.1497 - val_accuracy: 0.7923\n",
            "Epoch 61/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.6495 - accuracy: 0.9590 - val_loss: 1.1331 - val_accuracy: 0.7930\n",
            "Epoch 62/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.6256 - accuracy: 0.9600 - val_loss: 1.1185 - val_accuracy: 0.7946\n",
            "Epoch 63/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.6029 - accuracy: 0.9630 - val_loss: 1.1013 - val_accuracy: 0.7999\n",
            "Epoch 64/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.5745 - accuracy: 0.9620 - val_loss: 1.0897 - val_accuracy: 0.8002\n",
            "Epoch 65/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.5695 - accuracy: 0.9590 - val_loss: 1.0766 - val_accuracy: 0.8017\n",
            "Epoch 66/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.5504 - accuracy: 0.9640 - val_loss: 1.0608 - val_accuracy: 0.8075\n",
            "Epoch 67/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.5350 - accuracy: 0.9640 - val_loss: 1.0484 - val_accuracy: 0.8103\n",
            "Epoch 68/150\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.5194 - accuracy: 0.9710 - val_loss: 1.0350 - val_accuracy: 0.8113\n",
            "Epoch 69/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.5015 - accuracy: 0.9670 - val_loss: 1.0235 - val_accuracy: 0.8124\n",
            "Epoch 70/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.4832 - accuracy: 0.9710 - val_loss: 1.0107 - val_accuracy: 0.8126\n",
            "Epoch 71/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4735 - accuracy: 0.9710 - val_loss: 0.9986 - val_accuracy: 0.8126\n",
            "Epoch 72/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.4679 - accuracy: 0.9750 - val_loss: 0.9894 - val_accuracy: 0.8136\n",
            "Epoch 73/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.4533 - accuracy: 0.9710 - val_loss: 0.9766 - val_accuracy: 0.8146\n",
            "Epoch 74/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.4485 - accuracy: 0.9680 - val_loss: 0.9691 - val_accuracy: 0.8144\n",
            "Epoch 75/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4215 - accuracy: 0.9730 - val_loss: 0.9565 - val_accuracy: 0.8162\n",
            "Epoch 76/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4121 - accuracy: 0.9760 - val_loss: 0.9492 - val_accuracy: 0.8190\n",
            "Epoch 77/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.4089 - accuracy: 0.9720 - val_loss: 0.9409 - val_accuracy: 0.8195\n",
            "Epoch 78/150\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.4031 - accuracy: 0.9740 - val_loss: 0.9320 - val_accuracy: 0.8223\n",
            "Epoch 79/150\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.3844 - accuracy: 0.9760 - val_loss: 0.9234 - val_accuracy: 0.8248\n",
            "Epoch 80/150\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.3788 - accuracy: 0.9730 - val_loss: 0.9149 - val_accuracy: 0.8253\n",
            "Epoch 81/150\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3724 - accuracy: 0.9770 - val_loss: 0.9067 - val_accuracy: 0.8256\n",
            "Epoch 82/150\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3481 - accuracy: 0.9810 - val_loss: 0.8996 - val_accuracy: 0.8266\n",
            "Epoch 83/150\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.3534 - accuracy: 0.9790 - val_loss: 0.8922 - val_accuracy: 0.8266\n",
            "Epoch 84/150\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.3463 - accuracy: 0.9790 - val_loss: 0.8842 - val_accuracy: 0.8281\n",
            "Epoch 85/150\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.3341 - accuracy: 0.9770 - val_loss: 0.8755 - val_accuracy: 0.8337\n",
            "Epoch 86/150\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.3351 - accuracy: 0.9790 - val_loss: 0.8681 - val_accuracy: 0.8352\n",
            "Epoch 87/150\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3238 - accuracy: 0.9780 - val_loss: 0.8625 - val_accuracy: 0.8368\n",
            "Epoch 88/150\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3060 - accuracy: 0.9800 - val_loss: 0.8563 - val_accuracy: 0.8370\n",
            "Epoch 89/150\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.3003 - accuracy: 0.9830 - val_loss: 0.8487 - val_accuracy: 0.8380\n",
            "Epoch 90/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2841 - accuracy: 0.9840 - val_loss: 0.8423 - val_accuracy: 0.8406\n",
            "Epoch 91/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2936 - accuracy: 0.9820 - val_loss: 0.8358 - val_accuracy: 0.8408\n",
            "Epoch 92/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.2885 - accuracy: 0.9830 - val_loss: 0.8290 - val_accuracy: 0.8411\n",
            "Epoch 93/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2814 - accuracy: 0.9820 - val_loss: 0.8245 - val_accuracy: 0.8416\n",
            "Epoch 94/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2670 - accuracy: 0.9820 - val_loss: 0.8180 - val_accuracy: 0.8406\n",
            "Epoch 95/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2672 - accuracy: 0.9820 - val_loss: 0.8127 - val_accuracy: 0.8429\n",
            "Epoch 96/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2606 - accuracy: 0.9820 - val_loss: 0.8089 - val_accuracy: 0.8429\n",
            "Epoch 97/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2518 - accuracy: 0.9830 - val_loss: 0.8043 - val_accuracy: 0.8436\n",
            "Epoch 98/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2468 - accuracy: 0.9860 - val_loss: 0.7994 - val_accuracy: 0.8439\n",
            "Epoch 99/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.2451 - accuracy: 0.9860 - val_loss: 0.7947 - val_accuracy: 0.8454\n",
            "Epoch 100/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.2317 - accuracy: 0.9870 - val_loss: 0.7899 - val_accuracy: 0.8459\n",
            "Epoch 101/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2267 - accuracy: 0.9860 - val_loss: 0.7862 - val_accuracy: 0.8482\n",
            "Epoch 102/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.2216 - accuracy: 0.9830 - val_loss: 0.7814 - val_accuracy: 0.8502\n",
            "Epoch 103/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.2168 - accuracy: 0.9860 - val_loss: 0.7757 - val_accuracy: 0.8502\n",
            "Epoch 104/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2171 - accuracy: 0.9850 - val_loss: 0.7721 - val_accuracy: 0.8513\n",
            "Epoch 105/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2140 - accuracy: 0.9850 - val_loss: 0.7698 - val_accuracy: 0.8500\n",
            "Epoch 106/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.2122 - accuracy: 0.9860 - val_loss: 0.7661 - val_accuracy: 0.8520\n",
            "Epoch 107/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2052 - accuracy: 0.9870 - val_loss: 0.7624 - val_accuracy: 0.8492\n",
            "Epoch 108/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.2038 - accuracy: 0.9860 - val_loss: 0.7554 - val_accuracy: 0.8518\n",
            "Epoch 109/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1944 - accuracy: 0.9870 - val_loss: 0.7531 - val_accuracy: 0.8525\n",
            "Epoch 110/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1899 - accuracy: 0.9880 - val_loss: 0.7502 - val_accuracy: 0.8535\n",
            "Epoch 111/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1820 - accuracy: 0.9870 - val_loss: 0.7459 - val_accuracy: 0.8546\n",
            "Epoch 112/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1829 - accuracy: 0.9890 - val_loss: 0.7424 - val_accuracy: 0.8551\n",
            "Epoch 113/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1834 - accuracy: 0.9850 - val_loss: 0.7382 - val_accuracy: 0.8561\n",
            "Epoch 114/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1759 - accuracy: 0.9870 - val_loss: 0.7355 - val_accuracy: 0.8553\n",
            "Epoch 115/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1763 - accuracy: 0.9850 - val_loss: 0.7315 - val_accuracy: 0.8538\n",
            "Epoch 116/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1692 - accuracy: 0.9860 - val_loss: 0.7277 - val_accuracy: 0.8551\n",
            "Epoch 117/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1656 - accuracy: 0.9890 - val_loss: 0.7245 - val_accuracy: 0.8586\n",
            "Epoch 118/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1558 - accuracy: 0.9910 - val_loss: 0.7216 - val_accuracy: 0.8584\n",
            "Epoch 119/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1633 - accuracy: 0.9880 - val_loss: 0.7186 - val_accuracy: 0.8589\n",
            "Epoch 120/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1623 - accuracy: 0.9880 - val_loss: 0.7159 - val_accuracy: 0.8571\n",
            "Epoch 121/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1537 - accuracy: 0.9890 - val_loss: 0.7143 - val_accuracy: 0.8602\n",
            "Epoch 122/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1502 - accuracy: 0.9890 - val_loss: 0.7109 - val_accuracy: 0.8609\n",
            "Epoch 123/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1515 - accuracy: 0.9880 - val_loss: 0.7076 - val_accuracy: 0.8609\n",
            "Epoch 124/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.1420 - accuracy: 0.9920 - val_loss: 0.7068 - val_accuracy: 0.8607\n",
            "Epoch 125/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1397 - accuracy: 0.9910 - val_loss: 0.7038 - val_accuracy: 0.8609\n",
            "Epoch 126/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1435 - accuracy: 0.9870 - val_loss: 0.7000 - val_accuracy: 0.8612\n",
            "Epoch 127/150\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1362 - accuracy: 0.9900 - val_loss: 0.6964 - val_accuracy: 0.8612\n",
            "Epoch 128/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1307 - accuracy: 0.9900 - val_loss: 0.6946 - val_accuracy: 0.8614\n",
            "Epoch 129/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1320 - accuracy: 0.9920 - val_loss: 0.6922 - val_accuracy: 0.8624\n",
            "Epoch 130/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1328 - accuracy: 0.9910 - val_loss: 0.6908 - val_accuracy: 0.8619\n",
            "Epoch 131/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1275 - accuracy: 0.9890 - val_loss: 0.6896 - val_accuracy: 0.8617\n",
            "Epoch 132/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1286 - accuracy: 0.9900 - val_loss: 0.6859 - val_accuracy: 0.8622\n",
            "Epoch 133/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1211 - accuracy: 0.9930 - val_loss: 0.6832 - val_accuracy: 0.8637\n",
            "Epoch 134/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.1263 - accuracy: 0.9910 - val_loss: 0.6811 - val_accuracy: 0.8635\n",
            "Epoch 135/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1188 - accuracy: 0.9920 - val_loss: 0.6807 - val_accuracy: 0.8624\n",
            "Epoch 136/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1227 - accuracy: 0.9930 - val_loss: 0.6776 - val_accuracy: 0.8637\n",
            "Epoch 137/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1098 - accuracy: 0.9930 - val_loss: 0.6766 - val_accuracy: 0.8635\n",
            "Epoch 138/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1149 - accuracy: 0.9910 - val_loss: 0.6750 - val_accuracy: 0.8627\n",
            "Epoch 139/150\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.1084 - accuracy: 0.9900 - val_loss: 0.6720 - val_accuracy: 0.8645\n",
            "Epoch 140/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1110 - accuracy: 0.9930 - val_loss: 0.6700 - val_accuracy: 0.8645\n",
            "Epoch 141/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1054 - accuracy: 0.9940 - val_loss: 0.6670 - val_accuracy: 0.8642\n",
            "Epoch 142/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1046 - accuracy: 0.9930 - val_loss: 0.6645 - val_accuracy: 0.8642\n",
            "Epoch 143/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1088 - accuracy: 0.9910 - val_loss: 0.6633 - val_accuracy: 0.8630\n",
            "Epoch 144/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0969 - accuracy: 0.9930 - val_loss: 0.6598 - val_accuracy: 0.8658\n",
            "Epoch 145/150\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1048 - accuracy: 0.9920 - val_loss: 0.6589 - val_accuracy: 0.8652\n",
            "Epoch 146/150\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.1000 - accuracy: 0.9960 - val_loss: 0.6571 - val_accuracy: 0.8668\n",
            "Epoch 147/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1002 - accuracy: 0.9940 - val_loss: 0.6558 - val_accuracy: 0.8655\n",
            "Epoch 148/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0937 - accuracy: 0.9960 - val_loss: 0.6538 - val_accuracy: 0.8670\n",
            "Epoch 149/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0935 - accuracy: 0.9940 - val_loss: 0.6508 - val_accuracy: 0.8683\n",
            "Epoch 150/150\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0939 - accuracy: 0.9940 - val_loss: 0.6505 - val_accuracy: 0.8683\n",
            "\n",
            "de 0.8759\n",
            "fr 0.2673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 44%|████▍     | 4/9 [06:47<08:27, 101.45s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0795\n",
            "(2000, 34) (2000, 75)\n",
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_22 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_6 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 4.2380 - accuracy: 0.0745 - val_loss: 4.2021 - val_accuracy: 0.2700\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 4.1719 - accuracy: 0.3060 - val_loss: 4.1219 - val_accuracy: 0.3511\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 4.1077 - accuracy: 0.3795 - val_loss: 4.0416 - val_accuracy: 0.3827\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 4.0367 - accuracy: 0.4645 - val_loss: 3.9306 - val_accuracy: 0.4300\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 3.9582 - accuracy: 0.4670 - val_loss: 3.7913 - val_accuracy: 0.4053\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 3.8575 - accuracy: 0.5005 - val_loss: 3.5960 - val_accuracy: 0.4348\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 3.7467 - accuracy: 0.5455 - val_loss: 3.3655 - val_accuracy: 0.4666\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 3.6188 - accuracy: 0.5930 - val_loss: 3.1129 - val_accuracy: 0.5006\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 3.4817 - accuracy: 0.6310 - val_loss: 2.8855 - val_accuracy: 0.5317\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 3s 79ms/step - loss: 3.3361 - accuracy: 0.6490 - val_loss: 2.6971 - val_accuracy: 0.5594\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 3.1725 - accuracy: 0.6740 - val_loss: 2.5279 - val_accuracy: 0.5871\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 3.0098 - accuracy: 0.7100 - val_loss: 2.3823 - val_accuracy: 0.6148\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 2.8445 - accuracy: 0.7350 - val_loss: 2.2320 - val_accuracy: 0.6481\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 2.6779 - accuracy: 0.7670 - val_loss: 2.1071 - val_accuracy: 0.6756\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 2.5106 - accuracy: 0.7830 - val_loss: 1.9833 - val_accuracy: 0.6885\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 2.3503 - accuracy: 0.8155 - val_loss: 1.8727 - val_accuracy: 0.7119\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 2.1891 - accuracy: 0.8355 - val_loss: 1.7661 - val_accuracy: 0.7366\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 2.0400 - accuracy: 0.8490 - val_loss: 1.6728 - val_accuracy: 0.7541\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.9096 - accuracy: 0.8675 - val_loss: 1.5844 - val_accuracy: 0.7717\n",
            "Epoch 20/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.7812 - accuracy: 0.8845 - val_loss: 1.5051 - val_accuracy: 0.7818\n",
            "Epoch 21/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 1.6609 - accuracy: 0.8910 - val_loss: 1.4315 - val_accuracy: 0.7913\n",
            "Epoch 22/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.5459 - accuracy: 0.9015 - val_loss: 1.3628 - val_accuracy: 0.8009\n",
            "Epoch 23/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.4430 - accuracy: 0.9060 - val_loss: 1.2994 - val_accuracy: 0.8103\n",
            "Epoch 24/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.3439 - accuracy: 0.9135 - val_loss: 1.2401 - val_accuracy: 0.8205\n",
            "Epoch 25/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.2620 - accuracy: 0.9230 - val_loss: 1.1886 - val_accuracy: 0.8271\n",
            "Epoch 26/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 1.1931 - accuracy: 0.9245 - val_loss: 1.1363 - val_accuracy: 0.8281\n",
            "Epoch 27/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 1.1128 - accuracy: 0.9285 - val_loss: 1.0914 - val_accuracy: 0.8314\n",
            "Epoch 28/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 1.0384 - accuracy: 0.9370 - val_loss: 1.0452 - val_accuracy: 0.8370\n",
            "Epoch 29/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.9793 - accuracy: 0.9400 - val_loss: 1.0097 - val_accuracy: 0.8385\n",
            "Epoch 30/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.9249 - accuracy: 0.9410 - val_loss: 0.9730 - val_accuracy: 0.8459\n",
            "Epoch 31/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.8729 - accuracy: 0.9465 - val_loss: 0.9372 - val_accuracy: 0.8472\n",
            "Epoch 32/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.8261 - accuracy: 0.9505 - val_loss: 0.9068 - val_accuracy: 0.8518\n",
            "Epoch 33/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.7750 - accuracy: 0.9515 - val_loss: 0.8780 - val_accuracy: 0.8541\n",
            "Epoch 34/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.7337 - accuracy: 0.9575 - val_loss: 0.8493 - val_accuracy: 0.8581\n",
            "Epoch 35/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.6934 - accuracy: 0.9600 - val_loss: 0.8256 - val_accuracy: 0.8614\n",
            "Epoch 36/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.6510 - accuracy: 0.9630 - val_loss: 0.8015 - val_accuracy: 0.8670\n",
            "Epoch 37/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.6180 - accuracy: 0.9635 - val_loss: 0.7806 - val_accuracy: 0.8685\n",
            "Epoch 38/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.5938 - accuracy: 0.9630 - val_loss: 0.7598 - val_accuracy: 0.8708\n",
            "Epoch 39/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.5621 - accuracy: 0.9640 - val_loss: 0.7428 - val_accuracy: 0.8708\n",
            "Epoch 40/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.5304 - accuracy: 0.9640 - val_loss: 0.7255 - val_accuracy: 0.8739\n",
            "Epoch 41/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.5105 - accuracy: 0.9700 - val_loss: 0.7077 - val_accuracy: 0.8769\n",
            "Epoch 42/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.4881 - accuracy: 0.9675 - val_loss: 0.6925 - val_accuracy: 0.8769\n",
            "Epoch 43/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.4568 - accuracy: 0.9680 - val_loss: 0.6790 - val_accuracy: 0.8774\n",
            "Epoch 44/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.4370 - accuracy: 0.9705 - val_loss: 0.6659 - val_accuracy: 0.8792\n",
            "Epoch 45/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.4144 - accuracy: 0.9695 - val_loss: 0.6560 - val_accuracy: 0.8782\n",
            "Epoch 46/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.4004 - accuracy: 0.9710 - val_loss: 0.6422 - val_accuracy: 0.8802\n",
            "Epoch 47/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.3873 - accuracy: 0.9705 - val_loss: 0.6314 - val_accuracy: 0.8838\n",
            "Epoch 48/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.3647 - accuracy: 0.9745 - val_loss: 0.6181 - val_accuracy: 0.8863\n",
            "Epoch 49/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.3519 - accuracy: 0.9730 - val_loss: 0.6112 - val_accuracy: 0.8835\n",
            "Epoch 50/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.3354 - accuracy: 0.9765 - val_loss: 0.5987 - val_accuracy: 0.8861\n",
            "Epoch 51/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.3301 - accuracy: 0.9720 - val_loss: 0.5902 - val_accuracy: 0.8851\n",
            "Epoch 52/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.3069 - accuracy: 0.9780 - val_loss: 0.5802 - val_accuracy: 0.8871\n",
            "Epoch 53/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2910 - accuracy: 0.9790 - val_loss: 0.5713 - val_accuracy: 0.8874\n",
            "Epoch 54/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.2828 - accuracy: 0.9800 - val_loss: 0.5649 - val_accuracy: 0.8876\n",
            "Epoch 55/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.2697 - accuracy: 0.9790 - val_loss: 0.5581 - val_accuracy: 0.8881\n",
            "Epoch 56/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2649 - accuracy: 0.9795 - val_loss: 0.5520 - val_accuracy: 0.8886\n",
            "Epoch 57/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.2543 - accuracy: 0.9835 - val_loss: 0.5459 - val_accuracy: 0.8909\n",
            "Epoch 58/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2479 - accuracy: 0.9820 - val_loss: 0.5403 - val_accuracy: 0.8919\n",
            "Epoch 59/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2326 - accuracy: 0.9810 - val_loss: 0.5357 - val_accuracy: 0.8922\n",
            "Epoch 60/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2241 - accuracy: 0.9850 - val_loss: 0.5269 - val_accuracy: 0.8937\n",
            "Epoch 61/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.2173 - accuracy: 0.9830 - val_loss: 0.5222 - val_accuracy: 0.8952\n",
            "Epoch 62/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.2095 - accuracy: 0.9855 - val_loss: 0.5151 - val_accuracy: 0.8993\n",
            "Epoch 63/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.2060 - accuracy: 0.9840 - val_loss: 0.5117 - val_accuracy: 0.8993\n",
            "Epoch 64/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1960 - accuracy: 0.9865 - val_loss: 0.5076 - val_accuracy: 0.9001\n",
            "Epoch 65/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1922 - accuracy: 0.9850 - val_loss: 0.5025 - val_accuracy: 0.8998\n",
            "Epoch 66/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1879 - accuracy: 0.9855 - val_loss: 0.4993 - val_accuracy: 0.8980\n",
            "Epoch 67/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1808 - accuracy: 0.9855 - val_loss: 0.4963 - val_accuracy: 0.8973\n",
            "Epoch 68/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1707 - accuracy: 0.9880 - val_loss: 0.4921 - val_accuracy: 0.8975\n",
            "Epoch 69/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1670 - accuracy: 0.9875 - val_loss: 0.4895 - val_accuracy: 0.8980\n",
            "Epoch 70/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1626 - accuracy: 0.9885 - val_loss: 0.4863 - val_accuracy: 0.8978\n",
            "Epoch 71/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1540 - accuracy: 0.9860 - val_loss: 0.4823 - val_accuracy: 0.8988\n",
            "Epoch 72/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1537 - accuracy: 0.9870 - val_loss: 0.4792 - val_accuracy: 0.8986\n",
            "Epoch 73/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.1509 - accuracy: 0.9865 - val_loss: 0.4746 - val_accuracy: 0.8991\n",
            "Epoch 74/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1457 - accuracy: 0.9845 - val_loss: 0.4714 - val_accuracy: 0.8996\n",
            "Epoch 75/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.1434 - accuracy: 0.9865 - val_loss: 0.4671 - val_accuracy: 0.9006\n",
            "Epoch 76/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1345 - accuracy: 0.9880 - val_loss: 0.4653 - val_accuracy: 0.9006\n",
            "Epoch 77/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1310 - accuracy: 0.9905 - val_loss: 0.4628 - val_accuracy: 0.8996\n",
            "Epoch 78/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.1268 - accuracy: 0.9885 - val_loss: 0.4598 - val_accuracy: 0.9003\n",
            "Epoch 79/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.1184 - accuracy: 0.9890 - val_loss: 0.4563 - val_accuracy: 0.9031\n",
            "Epoch 80/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1211 - accuracy: 0.9890 - val_loss: 0.4543 - val_accuracy: 0.9019\n",
            "Epoch 81/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1205 - accuracy: 0.9905 - val_loss: 0.4526 - val_accuracy: 0.9019\n",
            "Epoch 82/150\n",
            "32/32 [==============================] - 3s 82ms/step - loss: 0.1108 - accuracy: 0.9895 - val_loss: 0.4501 - val_accuracy: 0.9021\n",
            "Epoch 83/150\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.1144 - accuracy: 0.9910 - val_loss: 0.4475 - val_accuracy: 0.9019\n",
            "Epoch 84/150\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.1068 - accuracy: 0.9915 - val_loss: 0.4456 - val_accuracy: 0.9059\n",
            "Epoch 85/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.1047 - accuracy: 0.9900 - val_loss: 0.4431 - val_accuracy: 0.9049\n",
            "Epoch 86/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.1035 - accuracy: 0.9910 - val_loss: 0.4405 - val_accuracy: 0.9067\n",
            "Epoch 87/150\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.1000 - accuracy: 0.9905 - val_loss: 0.4380 - val_accuracy: 0.9067\n",
            "Epoch 88/150\n",
            "32/32 [==============================] - 3s 108ms/step - loss: 0.0951 - accuracy: 0.9915 - val_loss: 0.4367 - val_accuracy: 0.9085\n",
            "Epoch 89/150\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.0932 - accuracy: 0.9925 - val_loss: 0.4354 - val_accuracy: 0.9082\n",
            "Epoch 90/150\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.0935 - accuracy: 0.9925 - val_loss: 0.4331 - val_accuracy: 0.9054\n",
            "Epoch 91/150\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0917 - accuracy: 0.9900 - val_loss: 0.4315 - val_accuracy: 0.9069\n",
            "Epoch 92/150\n",
            "32/32 [==============================] - 3s 82ms/step - loss: 0.0839 - accuracy: 0.9920 - val_loss: 0.4282 - val_accuracy: 0.9092\n",
            "Epoch 93/150\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.0827 - accuracy: 0.9935 - val_loss: 0.4261 - val_accuracy: 0.9095\n",
            "Epoch 94/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0840 - accuracy: 0.9930 - val_loss: 0.4250 - val_accuracy: 0.9095\n",
            "Epoch 95/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0800 - accuracy: 0.9945 - val_loss: 0.4246 - val_accuracy: 0.9090\n",
            "Epoch 96/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0740 - accuracy: 0.9935 - val_loss: 0.4225 - val_accuracy: 0.9100\n",
            "Epoch 97/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0755 - accuracy: 0.9935 - val_loss: 0.4221 - val_accuracy: 0.9097\n",
            "Epoch 98/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0739 - accuracy: 0.9925 - val_loss: 0.4204 - val_accuracy: 0.9097\n",
            "Epoch 99/150\n",
            "32/32 [==============================] - 3s 78ms/step - loss: 0.0679 - accuracy: 0.9935 - val_loss: 0.4193 - val_accuracy: 0.9090\n",
            "Epoch 100/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0677 - accuracy: 0.9950 - val_loss: 0.4188 - val_accuracy: 0.9087\n",
            "Epoch 101/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0689 - accuracy: 0.9940 - val_loss: 0.4180 - val_accuracy: 0.9095\n",
            "Epoch 102/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0695 - accuracy: 0.9925 - val_loss: 0.4178 - val_accuracy: 0.9080\n",
            "Epoch 103/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0631 - accuracy: 0.9955 - val_loss: 0.4170 - val_accuracy: 0.9092\n",
            "Epoch 104/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0621 - accuracy: 0.9945 - val_loss: 0.4149 - val_accuracy: 0.9102\n",
            "Epoch 105/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0620 - accuracy: 0.9945 - val_loss: 0.4139 - val_accuracy: 0.9102\n",
            "Epoch 106/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0579 - accuracy: 0.9945 - val_loss: 0.4133 - val_accuracy: 0.9092\n",
            "Epoch 107/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0567 - accuracy: 0.9970 - val_loss: 0.4123 - val_accuracy: 0.9102\n",
            "Epoch 108/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0566 - accuracy: 0.9960 - val_loss: 0.4112 - val_accuracy: 0.9100\n",
            "Epoch 109/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0567 - accuracy: 0.9960 - val_loss: 0.4122 - val_accuracy: 0.9095\n",
            "Epoch 110/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0571 - accuracy: 0.9935 - val_loss: 0.4107 - val_accuracy: 0.9108\n",
            "Epoch 111/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0560 - accuracy: 0.9950 - val_loss: 0.4104 - val_accuracy: 0.9105\n",
            "Epoch 112/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0520 - accuracy: 0.9960 - val_loss: 0.4097 - val_accuracy: 0.9108\n",
            "Epoch 113/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0514 - accuracy: 0.9965 - val_loss: 0.4084 - val_accuracy: 0.9108\n",
            "Epoch 114/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0497 - accuracy: 0.9955 - val_loss: 0.4076 - val_accuracy: 0.9118\n",
            "Epoch 115/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.0482 - accuracy: 0.9955 - val_loss: 0.4059 - val_accuracy: 0.9113\n",
            "Epoch 116/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0459 - accuracy: 0.9960 - val_loss: 0.4044 - val_accuracy: 0.9110\n",
            "Epoch 117/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0467 - accuracy: 0.9975 - val_loss: 0.4044 - val_accuracy: 0.9110\n",
            "Epoch 118/150\n",
            "32/32 [==============================] - 2s 78ms/step - loss: 0.0466 - accuracy: 0.9960 - val_loss: 0.4035 - val_accuracy: 0.9115\n",
            "Epoch 119/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0450 - accuracy: 0.9965 - val_loss: 0.4029 - val_accuracy: 0.9108\n",
            "Epoch 120/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0445 - accuracy: 0.9965 - val_loss: 0.4026 - val_accuracy: 0.9118\n",
            "Epoch 121/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0425 - accuracy: 0.9975 - val_loss: 0.4019 - val_accuracy: 0.9118\n",
            "Epoch 122/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0405 - accuracy: 0.9970 - val_loss: 0.4014 - val_accuracy: 0.9115\n",
            "Epoch 123/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0410 - accuracy: 0.9960 - val_loss: 0.4005 - val_accuracy: 0.9128\n",
            "Epoch 124/150\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0372 - accuracy: 0.9970 - val_loss: 0.3995 - val_accuracy: 0.9133\n",
            "Epoch 125/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0387 - accuracy: 0.9970 - val_loss: 0.3995 - val_accuracy: 0.9118\n",
            "Epoch 126/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0404 - accuracy: 0.9975 - val_loss: 0.3984 - val_accuracy: 0.9123\n",
            "Epoch 127/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0357 - accuracy: 0.9965 - val_loss: 0.3989 - val_accuracy: 0.9118\n",
            "Epoch 128/150\n",
            "32/32 [==============================] - 3s 79ms/step - loss: 0.0340 - accuracy: 0.9980 - val_loss: 0.3985 - val_accuracy: 0.9128\n",
            "Epoch 129/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0350 - accuracy: 0.9975 - val_loss: 0.3980 - val_accuracy: 0.9125\n",
            "Epoch 130/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0345 - accuracy: 0.9990 - val_loss: 0.3975 - val_accuracy: 0.9115\n",
            "Epoch 131/150\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 0.0335 - accuracy: 0.9990 - val_loss: 0.3963 - val_accuracy: 0.9113\n",
            "Epoch 132/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0328 - accuracy: 0.9990 - val_loss: 0.3969 - val_accuracy: 0.9105\n",
            "Epoch 133/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0319 - accuracy: 0.9985 - val_loss: 0.3964 - val_accuracy: 0.9108\n",
            "Epoch 134/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0310 - accuracy: 0.9985 - val_loss: 0.3959 - val_accuracy: 0.9105\n",
            "Epoch 135/150\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 0.0298 - accuracy: 0.9990 - val_loss: 0.3957 - val_accuracy: 0.9113\n",
            "Epoch 136/150\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 0.0289 - accuracy: 0.9985 - val_loss: 0.3953 - val_accuracy: 0.9113\n",
            "Epoch 137/150\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 0.0310 - accuracy: 0.9985 - val_loss: 0.3944 - val_accuracy: 0.9110\n",
            "Epoch 138/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0292 - accuracy: 0.9985 - val_loss: 0.3950 - val_accuracy: 0.9115\n",
            "Epoch 139/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0289 - accuracy: 0.9975 - val_loss: 0.3959 - val_accuracy: 0.9118\n",
            "Epoch 140/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0280 - accuracy: 0.9995 - val_loss: 0.3958 - val_accuracy: 0.9118\n",
            "Epoch 141/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0274 - accuracy: 0.9985 - val_loss: 0.3959 - val_accuracy: 0.9113\n",
            "Epoch 142/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 0.0266 - accuracy: 0.9990 - val_loss: 0.3951 - val_accuracy: 0.9115\n",
            "\n",
            "de 0.9212\n",
            "fr 0.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 56%|█████▌    | 5/9 [12:51<12:00, 180.19s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1034\n",
            "(5000, 34) (5000, 75)\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_23 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 7s 85ms/step - loss: 4.1610 - accuracy: 0.2094 - val_loss: 4.0879 - val_accuracy: 0.3916\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 4.0266 - accuracy: 0.4412 - val_loss: 3.7681 - val_accuracy: 0.4750\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 3.8312 - accuracy: 0.5692 - val_loss: 3.2380 - val_accuracy: 0.5634\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 3.5627 - accuracy: 0.6460 - val_loss: 2.6827 - val_accuracy: 0.6278\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 3.2332 - accuracy: 0.6934 - val_loss: 2.2726 - val_accuracy: 0.6758\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 2.8572 - accuracy: 0.7658 - val_loss: 1.9331 - val_accuracy: 0.7241\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 2.4887 - accuracy: 0.8004 - val_loss: 1.6448 - val_accuracy: 0.7605\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 2.1544 - accuracy: 0.8312 - val_loss: 1.4170 - val_accuracy: 0.7846\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 1.8606 - accuracy: 0.8566 - val_loss: 1.2352 - val_accuracy: 0.8101\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 1.6254 - accuracy: 0.8782 - val_loss: 1.0919 - val_accuracy: 0.8246\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 1.4224 - accuracy: 0.8892 - val_loss: 0.9742 - val_accuracy: 0.8388\n",
            "Epoch 12/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 1.2415 - accuracy: 0.9084 - val_loss: 0.8799 - val_accuracy: 0.8558\n",
            "Epoch 13/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 1.0861 - accuracy: 0.9226 - val_loss: 0.8008 - val_accuracy: 0.8721\n",
            "Epoch 14/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.9650 - accuracy: 0.9352 - val_loss: 0.7320 - val_accuracy: 0.8830\n",
            "Epoch 15/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.8593 - accuracy: 0.9446 - val_loss: 0.6767 - val_accuracy: 0.8945\n",
            "Epoch 16/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.7631 - accuracy: 0.9508 - val_loss: 0.6285 - val_accuracy: 0.9049\n",
            "Epoch 17/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.6845 - accuracy: 0.9560 - val_loss: 0.5899 - val_accuracy: 0.9102\n",
            "Epoch 18/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.6148 - accuracy: 0.9594 - val_loss: 0.5528 - val_accuracy: 0.9138\n",
            "Epoch 19/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5577 - accuracy: 0.9630 - val_loss: 0.5204 - val_accuracy: 0.9148\n",
            "Epoch 20/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5015 - accuracy: 0.9668 - val_loss: 0.4953 - val_accuracy: 0.9151\n",
            "Epoch 21/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.4617 - accuracy: 0.9686 - val_loss: 0.4703 - val_accuracy: 0.9179\n",
            "Epoch 22/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4168 - accuracy: 0.9696 - val_loss: 0.4504 - val_accuracy: 0.9184\n",
            "Epoch 23/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.3833 - accuracy: 0.9726 - val_loss: 0.4341 - val_accuracy: 0.9207\n",
            "Epoch 24/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.3510 - accuracy: 0.9748 - val_loss: 0.4138 - val_accuracy: 0.9214\n",
            "Epoch 25/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.3280 - accuracy: 0.9762 - val_loss: 0.3991 - val_accuracy: 0.9225\n",
            "Epoch 26/150\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.2994 - accuracy: 0.9772 - val_loss: 0.3880 - val_accuracy: 0.9232\n",
            "Epoch 27/150\n",
            "79/79 [==============================] - 6s 77ms/step - loss: 0.2822 - accuracy: 0.9778 - val_loss: 0.3781 - val_accuracy: 0.9255\n",
            "Epoch 28/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.2607 - accuracy: 0.9794 - val_loss: 0.3674 - val_accuracy: 0.9255\n",
            "Epoch 29/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.2428 - accuracy: 0.9810 - val_loss: 0.3570 - val_accuracy: 0.9275\n",
            "Epoch 30/150\n",
            "79/79 [==============================] - 6s 76ms/step - loss: 0.2212 - accuracy: 0.9832 - val_loss: 0.3479 - val_accuracy: 0.9286\n",
            "Epoch 31/150\n",
            "79/79 [==============================] - 6s 82ms/step - loss: 0.2093 - accuracy: 0.9830 - val_loss: 0.3404 - val_accuracy: 0.9288\n",
            "Epoch 32/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.1983 - accuracy: 0.9854 - val_loss: 0.3338 - val_accuracy: 0.9288\n",
            "Epoch 33/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1836 - accuracy: 0.9868 - val_loss: 0.3268 - val_accuracy: 0.9301\n",
            "Epoch 34/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1730 - accuracy: 0.9850 - val_loss: 0.3212 - val_accuracy: 0.9303\n",
            "Epoch 35/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1670 - accuracy: 0.9860 - val_loss: 0.3153 - val_accuracy: 0.9311\n",
            "Epoch 36/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1553 - accuracy: 0.9862 - val_loss: 0.3116 - val_accuracy: 0.9311\n",
            "Epoch 37/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1464 - accuracy: 0.9886 - val_loss: 0.3055 - val_accuracy: 0.9329\n",
            "Epoch 38/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1364 - accuracy: 0.9894 - val_loss: 0.3021 - val_accuracy: 0.9321\n",
            "Epoch 39/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1323 - accuracy: 0.9892 - val_loss: 0.2982 - val_accuracy: 0.9334\n",
            "Epoch 40/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1271 - accuracy: 0.9900 - val_loss: 0.2951 - val_accuracy: 0.9334\n",
            "Epoch 41/150\n",
            "79/79 [==============================] - 6s 76ms/step - loss: 0.1200 - accuracy: 0.9896 - val_loss: 0.2921 - val_accuracy: 0.9352\n",
            "Epoch 42/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1136 - accuracy: 0.9906 - val_loss: 0.2887 - val_accuracy: 0.9369\n",
            "Epoch 43/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1070 - accuracy: 0.9906 - val_loss: 0.2859 - val_accuracy: 0.9367\n",
            "Epoch 44/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.1002 - accuracy: 0.9918 - val_loss: 0.2827 - val_accuracy: 0.9367\n",
            "Epoch 45/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0999 - accuracy: 0.9912 - val_loss: 0.2800 - val_accuracy: 0.9375\n",
            "Epoch 46/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.0941 - accuracy: 0.9924 - val_loss: 0.2792 - val_accuracy: 0.9375\n",
            "Epoch 47/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0872 - accuracy: 0.9932 - val_loss: 0.2759 - val_accuracy: 0.9380\n",
            "Epoch 48/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0854 - accuracy: 0.9932 - val_loss: 0.2749 - val_accuracy: 0.9382\n",
            "Epoch 49/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0806 - accuracy: 0.9932 - val_loss: 0.2723 - val_accuracy: 0.9380\n",
            "Epoch 50/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0752 - accuracy: 0.9934 - val_loss: 0.2708 - val_accuracy: 0.9385\n",
            "Epoch 51/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0727 - accuracy: 0.9934 - val_loss: 0.2687 - val_accuracy: 0.9390\n",
            "Epoch 52/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0703 - accuracy: 0.9940 - val_loss: 0.2673 - val_accuracy: 0.9395\n",
            "Epoch 53/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0679 - accuracy: 0.9948 - val_loss: 0.2669 - val_accuracy: 0.9382\n",
            "Epoch 54/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0641 - accuracy: 0.9944 - val_loss: 0.2652 - val_accuracy: 0.9392\n",
            "Epoch 55/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0627 - accuracy: 0.9950 - val_loss: 0.2641 - val_accuracy: 0.9400\n",
            "Epoch 56/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0590 - accuracy: 0.9952 - val_loss: 0.2633 - val_accuracy: 0.9385\n",
            "Epoch 57/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0552 - accuracy: 0.9962 - val_loss: 0.2626 - val_accuracy: 0.9397\n",
            "Epoch 58/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0549 - accuracy: 0.9950 - val_loss: 0.2621 - val_accuracy: 0.9400\n",
            "Epoch 59/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0496 - accuracy: 0.9960 - val_loss: 0.2598 - val_accuracy: 0.9392\n",
            "Epoch 60/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0505 - accuracy: 0.9948 - val_loss: 0.2590 - val_accuracy: 0.9397\n",
            "Epoch 61/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0486 - accuracy: 0.9956 - val_loss: 0.2592 - val_accuracy: 0.9392\n",
            "Epoch 62/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0440 - accuracy: 0.9962 - val_loss: 0.2584 - val_accuracy: 0.9390\n",
            "Epoch 63/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0457 - accuracy: 0.9952 - val_loss: 0.2580 - val_accuracy: 0.9392\n",
            "Epoch 64/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0415 - accuracy: 0.9968 - val_loss: 0.2593 - val_accuracy: 0.9397\n",
            "Epoch 65/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0414 - accuracy: 0.9960 - val_loss: 0.2589 - val_accuracy: 0.9397\n",
            "Epoch 66/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.0383 - accuracy: 0.9968 - val_loss: 0.2590 - val_accuracy: 0.9392\n",
            "Epoch 67/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0359 - accuracy: 0.9964 - val_loss: 0.2580 - val_accuracy: 0.9392\n",
            "Epoch 68/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0352 - accuracy: 0.9972 - val_loss: 0.2584 - val_accuracy: 0.9397\n",
            "\n",
            "de 0.9494\n",
            "fr 0.3814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 67%|██████▋   | 6/9 [19:37<12:23, 247.90s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1604\n",
            "(10000, 34) (10000, 75)\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_24 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 4.2561 - accuracy: 0.3123 - val_loss: 3.8222 - val_accuracy: 0.5383\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 3.8926 - accuracy: 0.6401 - val_loss: 2.7107 - val_accuracy: 0.7353\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 3.2731 - accuracy: 0.7793 - val_loss: 1.9337 - val_accuracy: 0.7984\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 2.5413 - accuracy: 0.8408 - val_loss: 1.4073 - val_accuracy: 0.8279\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 12s 75ms/step - loss: 1.9177 - accuracy: 0.8720 - val_loss: 1.0769 - val_accuracy: 0.8513\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 1.4658 - accuracy: 0.9003 - val_loss: 0.8538 - val_accuracy: 0.8724\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 1.1384 - accuracy: 0.9234 - val_loss: 0.7048 - val_accuracy: 0.8919\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 12s 76ms/step - loss: 0.9099 - accuracy: 0.9359 - val_loss: 0.5982 - val_accuracy: 0.9057\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 12s 76ms/step - loss: 0.7394 - accuracy: 0.9481 - val_loss: 0.5158 - val_accuracy: 0.9148\n",
            "Epoch 10/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.6071 - accuracy: 0.9538 - val_loss: 0.4583 - val_accuracy: 0.9199\n",
            "Epoch 11/150\n",
            "157/157 [==============================] - 12s 73ms/step - loss: 0.5173 - accuracy: 0.9587 - val_loss: 0.4111 - val_accuracy: 0.9237\n",
            "Epoch 12/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.4356 - accuracy: 0.9648 - val_loss: 0.3738 - val_accuracy: 0.9263\n",
            "Epoch 13/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.3777 - accuracy: 0.9689 - val_loss: 0.3455 - val_accuracy: 0.9326\n",
            "Epoch 14/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.3294 - accuracy: 0.9735 - val_loss: 0.3221 - val_accuracy: 0.9390\n",
            "Epoch 15/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.2899 - accuracy: 0.9762 - val_loss: 0.3045 - val_accuracy: 0.9385\n",
            "Epoch 16/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.2566 - accuracy: 0.9781 - val_loss: 0.2884 - val_accuracy: 0.9408\n",
            "Epoch 17/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.2313 - accuracy: 0.9799 - val_loss: 0.2731 - val_accuracy: 0.9466\n",
            "Epoch 18/150\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 0.2071 - accuracy: 0.9822 - val_loss: 0.2630 - val_accuracy: 0.9486\n",
            "Epoch 19/150\n",
            "157/157 [==============================] - 12s 76ms/step - loss: 0.1850 - accuracy: 0.9841 - val_loss: 0.2533 - val_accuracy: 0.9494\n",
            "Epoch 20/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1690 - accuracy: 0.9852 - val_loss: 0.2437 - val_accuracy: 0.9502\n",
            "Epoch 21/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.1523 - accuracy: 0.9870 - val_loss: 0.2370 - val_accuracy: 0.9507\n",
            "Epoch 22/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1394 - accuracy: 0.9873 - val_loss: 0.2321 - val_accuracy: 0.9522\n",
            "Epoch 23/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1264 - accuracy: 0.9897 - val_loss: 0.2274 - val_accuracy: 0.9525\n",
            "Epoch 24/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1199 - accuracy: 0.9888 - val_loss: 0.2202 - val_accuracy: 0.9535\n",
            "Epoch 25/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1080 - accuracy: 0.9911 - val_loss: 0.2159 - val_accuracy: 0.9527\n",
            "Epoch 26/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1006 - accuracy: 0.9916 - val_loss: 0.2129 - val_accuracy: 0.9530\n",
            "Epoch 27/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0915 - accuracy: 0.9930 - val_loss: 0.2087 - val_accuracy: 0.9553\n",
            "Epoch 28/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0858 - accuracy: 0.9924 - val_loss: 0.2067 - val_accuracy: 0.9550\n",
            "Epoch 29/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0808 - accuracy: 0.9928 - val_loss: 0.2023 - val_accuracy: 0.9555\n",
            "Epoch 30/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0750 - accuracy: 0.9937 - val_loss: 0.2010 - val_accuracy: 0.9530\n",
            "Epoch 31/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0691 - accuracy: 0.9943 - val_loss: 0.2002 - val_accuracy: 0.9545\n",
            "Epoch 32/150\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 0.0617 - accuracy: 0.9947 - val_loss: 0.1962 - val_accuracy: 0.9563\n",
            "Epoch 33/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0597 - accuracy: 0.9948 - val_loss: 0.1954 - val_accuracy: 0.9547\n",
            "Epoch 34/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0536 - accuracy: 0.9953 - val_loss: 0.1939 - val_accuracy: 0.9568\n",
            "Epoch 35/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0519 - accuracy: 0.9956 - val_loss: 0.1930 - val_accuracy: 0.9553\n",
            "Epoch 36/150\n",
            "157/157 [==============================] - 12s 76ms/step - loss: 0.0491 - accuracy: 0.9956 - val_loss: 0.1916 - val_accuracy: 0.9558\n",
            "Epoch 37/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0467 - accuracy: 0.9967 - val_loss: 0.1902 - val_accuracy: 0.9563\n",
            "Epoch 38/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0442 - accuracy: 0.9960 - val_loss: 0.1897 - val_accuracy: 0.9560\n",
            "Epoch 39/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0405 - accuracy: 0.9965 - val_loss: 0.1892 - val_accuracy: 0.9568\n",
            "Epoch 40/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0379 - accuracy: 0.9968 - val_loss: 0.1883 - val_accuracy: 0.9560\n",
            "Epoch 41/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0355 - accuracy: 0.9968 - val_loss: 0.1898 - val_accuracy: 0.9555\n",
            "Epoch 42/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.0329 - accuracy: 0.9972 - val_loss: 0.1889 - val_accuracy: 0.9563\n",
            "Epoch 43/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0301 - accuracy: 0.9970 - val_loss: 0.1884 - val_accuracy: 0.9573\n",
            "Epoch 44/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0300 - accuracy: 0.9971 - val_loss: 0.1886 - val_accuracy: 0.9568\n",
            "Epoch 45/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0287 - accuracy: 0.9975 - val_loss: 0.1877 - val_accuracy: 0.9570\n",
            "Epoch 46/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0265 - accuracy: 0.9977 - val_loss: 0.1897 - val_accuracy: 0.9558\n",
            "Epoch 47/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0234 - accuracy: 0.9979 - val_loss: 0.1885 - val_accuracy: 0.9575\n",
            "Epoch 48/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0231 - accuracy: 0.9980 - val_loss: 0.1887 - val_accuracy: 0.9575\n",
            "Epoch 49/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0214 - accuracy: 0.9974 - val_loss: 0.1894 - val_accuracy: 0.9575\n",
            "Epoch 50/150\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0212 - accuracy: 0.9979 - val_loss: 0.1899 - val_accuracy: 0.9575\n",
            "\n",
            "de 0.9596\n",
            "fr 0.434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 78%|███████▊  | 7/9 [29:15<11:33, 346.99s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1154\n",
            "(15000, 34) (15000, 75)\n",
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_25 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_9 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 4.2129 - accuracy: 0.4364 - val_loss: 3.3082 - val_accuracy: 0.6822\n",
            "Epoch 2/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 3.4836 - accuracy: 0.7339 - val_loss: 1.9538 - val_accuracy: 0.7679\n",
            "Epoch 3/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 2.4594 - accuracy: 0.8344 - val_loss: 1.2226 - val_accuracy: 0.8490\n",
            "Epoch 4/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 1.6651 - accuracy: 0.8882 - val_loss: 0.8537 - val_accuracy: 0.8891\n",
            "Epoch 5/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 1.1565 - accuracy: 0.9208 - val_loss: 0.6427 - val_accuracy: 0.9110\n",
            "Epoch 6/150\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.8412 - accuracy: 0.9355 - val_loss: 0.5109 - val_accuracy: 0.9235\n",
            "Epoch 7/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.6346 - accuracy: 0.9470 - val_loss: 0.4225 - val_accuracy: 0.9319\n",
            "Epoch 8/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.4940 - accuracy: 0.9566 - val_loss: 0.3643 - val_accuracy: 0.9395\n",
            "Epoch 9/150\n",
            "235/235 [==============================] - 19s 80ms/step - loss: 0.3973 - accuracy: 0.9655 - val_loss: 0.3193 - val_accuracy: 0.9413\n",
            "Epoch 10/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.3238 - accuracy: 0.9704 - val_loss: 0.2918 - val_accuracy: 0.9461\n",
            "Epoch 11/150\n",
            "235/235 [==============================] - 17s 73ms/step - loss: 0.2731 - accuracy: 0.9753 - val_loss: 0.2677 - val_accuracy: 0.9489\n",
            "Epoch 12/150\n",
            "235/235 [==============================] - 17s 73ms/step - loss: 0.2331 - accuracy: 0.9777 - val_loss: 0.2472 - val_accuracy: 0.9522\n",
            "Epoch 13/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.1955 - accuracy: 0.9819 - val_loss: 0.2313 - val_accuracy: 0.9555\n",
            "Epoch 14/150\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.1711 - accuracy: 0.9839 - val_loss: 0.2200 - val_accuracy: 0.9560\n",
            "Epoch 15/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.1480 - accuracy: 0.9860 - val_loss: 0.2110 - val_accuracy: 0.9558\n",
            "Epoch 16/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.1326 - accuracy: 0.9865 - val_loss: 0.2037 - val_accuracy: 0.9580\n",
            "Epoch 17/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.1198 - accuracy: 0.9873 - val_loss: 0.1965 - val_accuracy: 0.9570\n",
            "Epoch 18/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.1040 - accuracy: 0.9896 - val_loss: 0.1892 - val_accuracy: 0.9601\n",
            "Epoch 19/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0949 - accuracy: 0.9891 - val_loss: 0.1861 - val_accuracy: 0.9606\n",
            "Epoch 20/150\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0855 - accuracy: 0.9909 - val_loss: 0.1836 - val_accuracy: 0.9596\n",
            "Epoch 21/150\n",
            "235/235 [==============================] - 18s 76ms/step - loss: 0.0765 - accuracy: 0.9921 - val_loss: 0.1780 - val_accuracy: 0.9616\n",
            "Epoch 22/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0713 - accuracy: 0.9923 - val_loss: 0.1752 - val_accuracy: 0.9621\n",
            "Epoch 23/150\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0638 - accuracy: 0.9928 - val_loss: 0.1727 - val_accuracy: 0.9621\n",
            "Epoch 24/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0594 - accuracy: 0.9934 - val_loss: 0.1712 - val_accuracy: 0.9619\n",
            "Epoch 25/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0531 - accuracy: 0.9931 - val_loss: 0.1686 - val_accuracy: 0.9631\n",
            "Epoch 26/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.0493 - accuracy: 0.9937 - val_loss: 0.1716 - val_accuracy: 0.9619\n",
            "Epoch 27/150\n",
            "235/235 [==============================] - 19s 79ms/step - loss: 0.0460 - accuracy: 0.9941 - val_loss: 0.1675 - val_accuracy: 0.9639\n",
            "Epoch 28/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.0424 - accuracy: 0.9943 - val_loss: 0.1669 - val_accuracy: 0.9641\n",
            "Epoch 29/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.0395 - accuracy: 0.9945 - val_loss: 0.1667 - val_accuracy: 0.9636\n",
            "Epoch 30/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0360 - accuracy: 0.9954 - val_loss: 0.1649 - val_accuracy: 0.9649\n",
            "Epoch 31/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.0344 - accuracy: 0.9955 - val_loss: 0.1658 - val_accuracy: 0.9647\n",
            "Epoch 32/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0302 - accuracy: 0.9957 - val_loss: 0.1663 - val_accuracy: 0.9647\n",
            "Epoch 33/150\n",
            "235/235 [==============================] - 18s 75ms/step - loss: 0.0296 - accuracy: 0.9957 - val_loss: 0.1665 - val_accuracy: 0.9647\n",
            "Epoch 34/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0264 - accuracy: 0.9961 - val_loss: 0.1655 - val_accuracy: 0.9659\n",
            "Epoch 35/150\n",
            "235/235 [==============================] - 17s 74ms/step - loss: 0.0257 - accuracy: 0.9962 - val_loss: 0.1670 - val_accuracy: 0.9654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 89%|████████▉ | 8/9 [39:35<07:08, 428.89s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9685\n",
            "fr 0.4448\n",
            "it 0.1184\n",
            "(25000, 34) (25000, 75)\n",
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_26 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 6,897,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 3.9313 - accuracy: 0.5592 - val_loss: 2.2919 - val_accuracy: 0.7773\n",
            "Epoch 2/150\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 2.4700 - accuracy: 0.8326 - val_loss: 1.0682 - val_accuracy: 0.8599\n",
            "Epoch 3/150\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.3515 - accuracy: 0.9048 - val_loss: 0.6443 - val_accuracy: 0.9044\n",
            "Epoch 4/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.8180 - accuracy: 0.9366 - val_loss: 0.4495 - val_accuracy: 0.9191\n",
            "Epoch 5/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.5461 - accuracy: 0.9512 - val_loss: 0.3477 - val_accuracy: 0.9334\n",
            "Epoch 6/150\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.3925 - accuracy: 0.9620 - val_loss: 0.2897 - val_accuracy: 0.9415\n",
            "Epoch 7/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.2968 - accuracy: 0.9696 - val_loss: 0.2462 - val_accuracy: 0.9484\n",
            "Epoch 8/150\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2341 - accuracy: 0.9770 - val_loss: 0.2213 - val_accuracy: 0.9504\n",
            "Epoch 9/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.1878 - accuracy: 0.9807 - val_loss: 0.1990 - val_accuracy: 0.9558\n",
            "Epoch 10/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.1557 - accuracy: 0.9828 - val_loss: 0.1835 - val_accuracy: 0.9591\n",
            "Epoch 11/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.1295 - accuracy: 0.9848 - val_loss: 0.1733 - val_accuracy: 0.9606\n",
            "Epoch 12/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.1097 - accuracy: 0.9875 - val_loss: 0.1647 - val_accuracy: 0.9614\n",
            "Epoch 13/150\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.0933 - accuracy: 0.9884 - val_loss: 0.1577 - val_accuracy: 0.9621\n",
            "Epoch 14/150\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.0812 - accuracy: 0.9898 - val_loss: 0.1507 - val_accuracy: 0.9652\n",
            "Epoch 15/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.0716 - accuracy: 0.9911 - val_loss: 0.1481 - val_accuracy: 0.9667\n",
            "Epoch 16/150\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.0623 - accuracy: 0.9922 - val_loss: 0.1435 - val_accuracy: 0.9685\n",
            "Epoch 17/150\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.0549 - accuracy: 0.9932 - val_loss: 0.1407 - val_accuracy: 0.9685\n",
            "Epoch 18/150\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 0.0478 - accuracy: 0.9935 - val_loss: 0.1387 - val_accuracy: 0.9697\n",
            "Epoch 19/150\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.0420 - accuracy: 0.9940 - val_loss: 0.1349 - val_accuracy: 0.9697\n",
            "Epoch 20/150\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0384 - accuracy: 0.9949 - val_loss: 0.1353 - val_accuracy: 0.9705\n",
            "Epoch 21/150\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.0341 - accuracy: 0.9954 - val_loss: 0.1332 - val_accuracy: 0.9718\n",
            "Epoch 22/150\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.0295 - accuracy: 0.9961 - val_loss: 0.1319 - val_accuracy: 0.9723\n",
            "Epoch 23/150\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0273 - accuracy: 0.9962 - val_loss: 0.1326 - val_accuracy: 0.9713\n",
            "Epoch 24/150\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.0240 - accuracy: 0.9965 - val_loss: 0.1322 - val_accuracy: 0.9725\n",
            "Epoch 25/150\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.0212 - accuracy: 0.9970 - val_loss: 0.1313 - val_accuracy: 0.9733\n",
            "Epoch 26/150\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.0186 - accuracy: 0.9972 - val_loss: 0.1316 - val_accuracy: 0.9730\n",
            "Epoch 27/150\n",
            "391/391 [==============================] - 33s 85ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.1318 - val_accuracy: 0.9730\n",
            "Epoch 28/150\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.0163 - accuracy: 0.9978 - val_loss: 0.1349 - val_accuracy: 0.9720\n",
            "Epoch 29/150\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0153 - accuracy: 0.9977 - val_loss: 0.1338 - val_accuracy: 0.9733\n",
            "Epoch 30/150\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.1355 - val_accuracy: 0.9723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9703\n",
            "fr 0.4014\n",
            "it 0.1514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [54:48<00:00, 365.39s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.6102</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.8759</td>\n",
              "      <td>0.9212</td>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9596</td>\n",
              "      <td>0.9685</td>\n",
              "      <td>0.9703</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.3592</td>\n",
              "      <td>0.5772</td>\n",
              "      <td>0.7196</td>\n",
              "      <td>0.8061</td>\n",
              "      <td>0.8661</td>\n",
              "      <td>0.8899</td>\n",
              "      <td>0.919</td>\n",
              "      <td>0.9241</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model    task      metric    0  ...   10000   15000   25000 40000\n",
              "4  avg_pool  slc_de    accuracy  NaN  ...  0.9596  0.9685  0.9703   NaN\n",
              "5  avg_pool  slc_de  avg_recall  NaN  ...  0.8899   0.919  0.9241   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Vy_XPDozLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_avg_pool(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.1\n",
        "    filter_sizes =  [2,3,5]\n",
        "    num_filters = 75\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "    pool_layer = GlobalAveragePooling1D()(embedd_seq)   \n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test, y_test),4)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test, y_test),4)\n",
        "\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrMVv7w4uarT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5f6a32a-bcb5-44f1-9086-91908cfddedd"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'avg_pool_FE'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([15000,25000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_avg_pool(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(15000, 34) (15000, 75)\n",
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_11  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 22,575\n",
            "Non-trainable params: 6,875,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2185 - accuracy: 0.1545 - val_loss: 3.8130 - val_accuracy: 0.3616\n",
            "Epoch 2/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9726 - accuracy: 0.3755 - val_loss: 3.5488 - val_accuracy: 0.4368\n",
            "Epoch 3/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7825 - accuracy: 0.4710 - val_loss: 3.3448 - val_accuracy: 0.5123\n",
            "Epoch 4/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.6204 - accuracy: 0.5337 - val_loss: 3.0530 - val_accuracy: 0.5561\n",
            "Epoch 5/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4853 - accuracy: 0.5519 - val_loss: 2.9026 - val_accuracy: 0.6138\n",
            "Epoch 6/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3569 - accuracy: 0.6102 - val_loss: 2.7530 - val_accuracy: 0.6336\n",
            "Epoch 7/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2437 - accuracy: 0.6287 - val_loss: 2.6266 - val_accuracy: 0.6384\n",
            "Epoch 8/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1393 - accuracy: 0.6529 - val_loss: 2.5725 - val_accuracy: 0.6529\n",
            "Epoch 9/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0440 - accuracy: 0.6552 - val_loss: 2.4010 - val_accuracy: 0.6723\n",
            "Epoch 10/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9535 - accuracy: 0.6661 - val_loss: 2.3433 - val_accuracy: 0.7096\n",
            "Epoch 11/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8650 - accuracy: 0.6881 - val_loss: 2.2729 - val_accuracy: 0.7180\n",
            "Epoch 12/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7895 - accuracy: 0.6921 - val_loss: 2.1659 - val_accuracy: 0.7231\n",
            "Epoch 13/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7135 - accuracy: 0.7011 - val_loss: 2.1001 - val_accuracy: 0.7330\n",
            "Epoch 14/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6397 - accuracy: 0.7073 - val_loss: 2.0694 - val_accuracy: 0.7330\n",
            "Epoch 15/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5823 - accuracy: 0.7148 - val_loss: 2.0217 - val_accuracy: 0.7333\n",
            "Epoch 16/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5117 - accuracy: 0.7238 - val_loss: 1.9434 - val_accuracy: 0.7585\n",
            "Epoch 17/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4604 - accuracy: 0.7336 - val_loss: 1.9062 - val_accuracy: 0.7429\n",
            "Epoch 18/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4001 - accuracy: 0.7313 - val_loss: 1.8268 - val_accuracy: 0.7628\n",
            "Epoch 19/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3494 - accuracy: 0.7412 - val_loss: 1.8318 - val_accuracy: 0.7450\n",
            "Epoch 20/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3002 - accuracy: 0.7476 - val_loss: 1.7713 - val_accuracy: 0.7696\n",
            "Epoch 21/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2542 - accuracy: 0.7515 - val_loss: 1.7504 - val_accuracy: 0.7623\n",
            "Epoch 22/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2051 - accuracy: 0.7483 - val_loss: 1.7003 - val_accuracy: 0.7796\n",
            "Epoch 23/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1646 - accuracy: 0.7533 - val_loss: 1.6509 - val_accuracy: 0.7974\n",
            "Epoch 24/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1278 - accuracy: 0.7625 - val_loss: 1.6382 - val_accuracy: 0.7788\n",
            "Epoch 25/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0845 - accuracy: 0.7587 - val_loss: 1.5846 - val_accuracy: 0.7907\n",
            "Epoch 26/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0490 - accuracy: 0.7643 - val_loss: 1.5470 - val_accuracy: 0.7920\n",
            "Epoch 27/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0157 - accuracy: 0.7697 - val_loss: 1.5526 - val_accuracy: 0.7874\n",
            "Epoch 28/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9836 - accuracy: 0.7727 - val_loss: 1.5213 - val_accuracy: 0.7852\n",
            "Epoch 29/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9548 - accuracy: 0.7759 - val_loss: 1.4919 - val_accuracy: 0.7760\n",
            "Epoch 30/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9173 - accuracy: 0.7777 - val_loss: 1.5000 - val_accuracy: 0.7846\n",
            "Epoch 31/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8854 - accuracy: 0.7781 - val_loss: 1.4362 - val_accuracy: 0.8012\n",
            "Epoch 32/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8662 - accuracy: 0.7821 - val_loss: 1.4241 - val_accuracy: 0.8004\n",
            "Epoch 33/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8407 - accuracy: 0.7799 - val_loss: 1.3926 - val_accuracy: 0.8202\n",
            "Epoch 34/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8121 - accuracy: 0.7865 - val_loss: 1.3936 - val_accuracy: 0.7877\n",
            "Epoch 35/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7773 - accuracy: 0.7800 - val_loss: 1.3231 - val_accuracy: 0.8205\n",
            "Epoch 36/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7609 - accuracy: 0.7897 - val_loss: 1.3697 - val_accuracy: 0.8019\n",
            "Epoch 37/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7349 - accuracy: 0.7877 - val_loss: 1.3100 - val_accuracy: 0.8248\n",
            "Epoch 38/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7147 - accuracy: 0.7917 - val_loss: 1.3146 - val_accuracy: 0.8144\n",
            "Epoch 39/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6932 - accuracy: 0.7914 - val_loss: 1.2717 - val_accuracy: 0.8309\n",
            "Epoch 40/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6727 - accuracy: 0.7987 - val_loss: 1.2634 - val_accuracy: 0.8174\n",
            "Epoch 41/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6603 - accuracy: 0.7982 - val_loss: 1.2841 - val_accuracy: 0.8134\n",
            "Epoch 42/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6349 - accuracy: 0.7997 - val_loss: 1.2557 - val_accuracy: 0.8126\n",
            "Epoch 43/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6149 - accuracy: 0.7958 - val_loss: 1.2128 - val_accuracy: 0.8246\n",
            "Epoch 44/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5893 - accuracy: 0.8011 - val_loss: 1.2166 - val_accuracy: 0.8157\n",
            "Epoch 45/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5757 - accuracy: 0.8053 - val_loss: 1.2073 - val_accuracy: 0.8141\n",
            "Epoch 46/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5604 - accuracy: 0.7989 - val_loss: 1.1636 - val_accuracy: 0.8296\n",
            "Epoch 47/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5510 - accuracy: 0.8024 - val_loss: 1.1646 - val_accuracy: 0.8152\n",
            "Epoch 48/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5263 - accuracy: 0.8050 - val_loss: 1.1622 - val_accuracy: 0.8324\n",
            "Epoch 49/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5172 - accuracy: 0.8065 - val_loss: 1.1837 - val_accuracy: 0.8101\n",
            "Epoch 50/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4985 - accuracy: 0.8089 - val_loss: 1.1678 - val_accuracy: 0.8197\n",
            "Epoch 51/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4798 - accuracy: 0.8054 - val_loss: 1.1472 - val_accuracy: 0.8281\n",
            "Epoch 52/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4755 - accuracy: 0.8066 - val_loss: 1.1169 - val_accuracy: 0.8342\n",
            "Epoch 53/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4650 - accuracy: 0.8073 - val_loss: 1.1062 - val_accuracy: 0.8223\n",
            "Epoch 54/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4416 - accuracy: 0.8117 - val_loss: 1.0966 - val_accuracy: 0.8299\n",
            "Epoch 55/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4318 - accuracy: 0.8102 - val_loss: 1.1019 - val_accuracy: 0.8380\n",
            "Epoch 56/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4200 - accuracy: 0.8113 - val_loss: 1.0712 - val_accuracy: 0.8373\n",
            "Epoch 57/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4092 - accuracy: 0.8111 - val_loss: 1.0798 - val_accuracy: 0.8335\n",
            "Epoch 58/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4035 - accuracy: 0.8122 - val_loss: 1.0442 - val_accuracy: 0.8446\n",
            "Epoch 59/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3849 - accuracy: 0.8171 - val_loss: 1.0445 - val_accuracy: 0.8446\n",
            "Epoch 60/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3811 - accuracy: 0.8123 - val_loss: 1.0427 - val_accuracy: 0.8457\n",
            "Epoch 61/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3675 - accuracy: 0.8201 - val_loss: 1.0545 - val_accuracy: 0.8337\n",
            "Epoch 62/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3556 - accuracy: 0.8128 - val_loss: 1.0462 - val_accuracy: 0.8383\n",
            "Epoch 63/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3479 - accuracy: 0.8147 - val_loss: 1.0228 - val_accuracy: 0.8258\n",
            "Epoch 64/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3306 - accuracy: 0.8155 - val_loss: 1.0207 - val_accuracy: 0.8330\n",
            "Epoch 65/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3205 - accuracy: 0.8194 - val_loss: 1.0042 - val_accuracy: 0.8459\n",
            "Epoch 66/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3076 - accuracy: 0.8232 - val_loss: 0.9868 - val_accuracy: 0.8383\n",
            "Epoch 67/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3047 - accuracy: 0.8167 - val_loss: 0.9890 - val_accuracy: 0.8319\n",
            "Epoch 68/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2958 - accuracy: 0.8195 - val_loss: 0.9764 - val_accuracy: 0.8508\n",
            "Epoch 69/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2957 - accuracy: 0.8209 - val_loss: 0.9649 - val_accuracy: 0.8505\n",
            "Epoch 70/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2760 - accuracy: 0.8215 - val_loss: 0.9759 - val_accuracy: 0.8403\n",
            "Epoch 71/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2721 - accuracy: 0.8196 - val_loss: 0.9882 - val_accuracy: 0.8357\n",
            "Epoch 72/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2586 - accuracy: 0.8249 - val_loss: 0.9586 - val_accuracy: 0.8505\n",
            "Epoch 73/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2564 - accuracy: 0.8265 - val_loss: 0.9527 - val_accuracy: 0.8502\n",
            "Epoch 74/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2389 - accuracy: 0.8253 - val_loss: 0.9512 - val_accuracy: 0.8383\n",
            "Epoch 75/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2399 - accuracy: 0.8253 - val_loss: 0.9563 - val_accuracy: 0.8464\n",
            "Epoch 76/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2296 - accuracy: 0.8267 - val_loss: 0.9333 - val_accuracy: 0.8541\n",
            "Epoch 77/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2170 - accuracy: 0.8308 - val_loss: 0.9212 - val_accuracy: 0.8574\n",
            "Epoch 78/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2217 - accuracy: 0.8239 - val_loss: 0.9349 - val_accuracy: 0.8543\n",
            "Epoch 79/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2095 - accuracy: 0.8267 - val_loss: 0.9242 - val_accuracy: 0.8482\n",
            "Epoch 80/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2054 - accuracy: 0.8283 - val_loss: 0.9077 - val_accuracy: 0.8574\n",
            "Epoch 81/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1922 - accuracy: 0.8321 - val_loss: 0.9132 - val_accuracy: 0.8444\n",
            "Epoch 82/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1929 - accuracy: 0.8233 - val_loss: 0.8915 - val_accuracy: 0.8617\n",
            "Epoch 83/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1845 - accuracy: 0.8290 - val_loss: 0.9044 - val_accuracy: 0.8520\n",
            "Epoch 84/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1790 - accuracy: 0.8305 - val_loss: 0.8826 - val_accuracy: 0.8558\n",
            "Epoch 85/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1709 - accuracy: 0.8297 - val_loss: 0.8955 - val_accuracy: 0.8497\n",
            "Epoch 86/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1545 - accuracy: 0.8313 - val_loss: 0.8847 - val_accuracy: 0.8528\n",
            "Epoch 87/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1606 - accuracy: 0.8316 - val_loss: 0.8800 - val_accuracy: 0.8561\n",
            "Epoch 88/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1483 - accuracy: 0.8291 - val_loss: 0.8568 - val_accuracy: 0.8591\n",
            "Epoch 89/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1482 - accuracy: 0.8324 - val_loss: 0.8673 - val_accuracy: 0.8538\n",
            "Epoch 90/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1334 - accuracy: 0.8316 - val_loss: 0.8747 - val_accuracy: 0.8563\n",
            "Epoch 91/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1351 - accuracy: 0.8329 - val_loss: 0.8640 - val_accuracy: 0.8535\n",
            "Epoch 92/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1267 - accuracy: 0.8356 - val_loss: 0.8521 - val_accuracy: 0.8630\n",
            "Epoch 93/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1202 - accuracy: 0.8368 - val_loss: 0.8534 - val_accuracy: 0.8579\n",
            "Epoch 94/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1136 - accuracy: 0.8325 - val_loss: 0.8282 - val_accuracy: 0.8647\n",
            "Epoch 95/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1109 - accuracy: 0.8381 - val_loss: 0.8352 - val_accuracy: 0.8632\n",
            "Epoch 96/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.1133 - accuracy: 0.8323 - val_loss: 0.8474 - val_accuracy: 0.8528\n",
            "Epoch 97/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1081 - accuracy: 0.8342 - val_loss: 0.8367 - val_accuracy: 0.8630\n",
            "Epoch 98/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1026 - accuracy: 0.8331 - val_loss: 0.8302 - val_accuracy: 0.8561\n",
            "Epoch 99/150\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0917 - accuracy: 0.8367 - val_loss: 0.8308 - val_accuracy: 0.8741\n",
            "\n",
            "de 0.8843\n",
            "fr 0.4025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 50%|█████     | 1/2 [01:38<01:38, 98.72s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2024\n",
            "(25000, 34) (25000, 75)\n",
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_28 (Embedding)     (None, 34, 300)           6875100   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_12  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,897,675\n",
            "Trainable params: 22,575\n",
            "Non-trainable params: 6,875,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 4.1814 - accuracy: 0.2065 - val_loss: 3.6706 - val_accuracy: 0.4193\n",
            "Epoch 2/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.8292 - accuracy: 0.4951 - val_loss: 3.2047 - val_accuracy: 0.5525\n",
            "Epoch 3/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.5711 - accuracy: 0.5743 - val_loss: 2.8566 - val_accuracy: 0.5812\n",
            "Epoch 4/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3552 - accuracy: 0.6186 - val_loss: 2.6615 - val_accuracy: 0.6659\n",
            "Epoch 5/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.1707 - accuracy: 0.6461 - val_loss: 2.4706 - val_accuracy: 0.6804\n",
            "Epoch 6/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.0065 - accuracy: 0.6648 - val_loss: 2.2910 - val_accuracy: 0.7231\n",
            "Epoch 7/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 2.8650 - accuracy: 0.6924 - val_loss: 2.2380 - val_accuracy: 0.6964\n",
            "Epoch 8/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.7339 - accuracy: 0.7109 - val_loss: 2.0740 - val_accuracy: 0.7216\n",
            "Epoch 9/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.6152 - accuracy: 0.7213 - val_loss: 1.9569 - val_accuracy: 0.7684\n",
            "Epoch 10/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.5140 - accuracy: 0.7362 - val_loss: 1.8941 - val_accuracy: 0.7452\n",
            "Epoch 11/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.4208 - accuracy: 0.7407 - val_loss: 1.8230 - val_accuracy: 0.7531\n",
            "Epoch 12/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.3355 - accuracy: 0.7541 - val_loss: 1.7509 - val_accuracy: 0.7689\n",
            "Epoch 13/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.2593 - accuracy: 0.7604 - val_loss: 1.6947 - val_accuracy: 0.7623\n",
            "Epoch 14/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 2.1808 - accuracy: 0.7605 - val_loss: 1.6343 - val_accuracy: 0.7661\n",
            "Epoch 15/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.1185 - accuracy: 0.7708 - val_loss: 1.5752 - val_accuracy: 0.7719\n",
            "Epoch 16/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.0495 - accuracy: 0.7738 - val_loss: 1.5461 - val_accuracy: 0.7930\n",
            "Epoch 17/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.9964 - accuracy: 0.7793 - val_loss: 1.4773 - val_accuracy: 0.8118\n",
            "Epoch 18/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.9450 - accuracy: 0.7823 - val_loss: 1.4598 - val_accuracy: 0.7788\n",
            "Epoch 19/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.8931 - accuracy: 0.7875 - val_loss: 1.3905 - val_accuracy: 0.8146\n",
            "Epoch 20/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.8505 - accuracy: 0.7882 - val_loss: 1.3884 - val_accuracy: 0.8029\n",
            "Epoch 21/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.8051 - accuracy: 0.7912 - val_loss: 1.3273 - val_accuracy: 0.8180\n",
            "Epoch 22/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.7668 - accuracy: 0.7973 - val_loss: 1.2953 - val_accuracy: 0.8146\n",
            "Epoch 23/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.7262 - accuracy: 0.8000 - val_loss: 1.2800 - val_accuracy: 0.8195\n",
            "Epoch 24/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.6965 - accuracy: 0.7992 - val_loss: 1.2375 - val_accuracy: 0.8195\n",
            "Epoch 25/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.6648 - accuracy: 0.8030 - val_loss: 1.2287 - val_accuracy: 0.8075\n",
            "Epoch 26/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.6279 - accuracy: 0.8058 - val_loss: 1.2193 - val_accuracy: 0.8029\n",
            "Epoch 27/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.6074 - accuracy: 0.8067 - val_loss: 1.1779 - val_accuracy: 0.8286\n",
            "Epoch 28/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.5671 - accuracy: 0.8077 - val_loss: 1.1451 - val_accuracy: 0.8266\n",
            "Epoch 29/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.5504 - accuracy: 0.8094 - val_loss: 1.1575 - val_accuracy: 0.8205\n",
            "Epoch 30/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.5229 - accuracy: 0.8134 - val_loss: 1.1088 - val_accuracy: 0.8319\n",
            "Epoch 31/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.4974 - accuracy: 0.8132 - val_loss: 1.0892 - val_accuracy: 0.8302\n",
            "Epoch 32/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.4705 - accuracy: 0.8148 - val_loss: 1.0964 - val_accuracy: 0.8286\n",
            "Epoch 33/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.4504 - accuracy: 0.8160 - val_loss: 1.0464 - val_accuracy: 0.8393\n",
            "Epoch 34/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.4290 - accuracy: 0.8152 - val_loss: 1.0556 - val_accuracy: 0.8345\n",
            "Epoch 35/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.4164 - accuracy: 0.8173 - val_loss: 1.0410 - val_accuracy: 0.8299\n",
            "Epoch 36/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3993 - accuracy: 0.8196 - val_loss: 1.0302 - val_accuracy: 0.8276\n",
            "Epoch 37/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3726 - accuracy: 0.8223 - val_loss: 1.0042 - val_accuracy: 0.8401\n",
            "Epoch 38/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3631 - accuracy: 0.8227 - val_loss: 1.0258 - val_accuracy: 0.8360\n",
            "Epoch 39/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3445 - accuracy: 0.8212 - val_loss: 1.0038 - val_accuracy: 0.8296\n",
            "Epoch 40/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3317 - accuracy: 0.8237 - val_loss: 0.9636 - val_accuracy: 0.8467\n",
            "Epoch 41/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3102 - accuracy: 0.8250 - val_loss: 0.9702 - val_accuracy: 0.8355\n",
            "Epoch 42/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2975 - accuracy: 0.8280 - val_loss: 0.9692 - val_accuracy: 0.8370\n",
            "Epoch 43/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2805 - accuracy: 0.8285 - val_loss: 0.9453 - val_accuracy: 0.8324\n",
            "Epoch 44/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2719 - accuracy: 0.8288 - val_loss: 0.9307 - val_accuracy: 0.8474\n",
            "Epoch 45/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2610 - accuracy: 0.8252 - val_loss: 0.9431 - val_accuracy: 0.8416\n",
            "Epoch 46/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2452 - accuracy: 0.8274 - val_loss: 0.9085 - val_accuracy: 0.8472\n",
            "Epoch 47/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2312 - accuracy: 0.8323 - val_loss: 0.9009 - val_accuracy: 0.8477\n",
            "Epoch 48/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2199 - accuracy: 0.8300 - val_loss: 0.8884 - val_accuracy: 0.8569\n",
            "Epoch 49/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2076 - accuracy: 0.8346 - val_loss: 0.8758 - val_accuracy: 0.8596\n",
            "Epoch 50/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2020 - accuracy: 0.8340 - val_loss: 0.8836 - val_accuracy: 0.8446\n",
            "Epoch 51/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1928 - accuracy: 0.8314 - val_loss: 0.8708 - val_accuracy: 0.8508\n",
            "Epoch 52/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1780 - accuracy: 0.8333 - val_loss: 0.8672 - val_accuracy: 0.8508\n",
            "Epoch 53/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1629 - accuracy: 0.8348 - val_loss: 0.8603 - val_accuracy: 0.8495\n",
            "Epoch 54/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1626 - accuracy: 0.8396 - val_loss: 0.8500 - val_accuracy: 0.8510\n",
            "Epoch 55/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1488 - accuracy: 0.8356 - val_loss: 0.8431 - val_accuracy: 0.8675\n",
            "Epoch 56/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1453 - accuracy: 0.8351 - val_loss: 0.8496 - val_accuracy: 0.8624\n",
            "Epoch 57/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1356 - accuracy: 0.8360 - val_loss: 0.8245 - val_accuracy: 0.8581\n",
            "Epoch 58/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1300 - accuracy: 0.8395 - val_loss: 0.8354 - val_accuracy: 0.8454\n",
            "Epoch 59/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1191 - accuracy: 0.8368 - val_loss: 0.8197 - val_accuracy: 0.8589\n",
            "Epoch 60/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1095 - accuracy: 0.8381 - val_loss: 0.8248 - val_accuracy: 0.8658\n",
            "Epoch 61/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1068 - accuracy: 0.8380 - val_loss: 0.8084 - val_accuracy: 0.8528\n",
            "Epoch 62/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0930 - accuracy: 0.8418 - val_loss: 0.8052 - val_accuracy: 0.8505\n",
            "Epoch 63/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0898 - accuracy: 0.8420 - val_loss: 0.7965 - val_accuracy: 0.8630\n",
            "Epoch 64/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0726 - accuracy: 0.8436 - val_loss: 0.8006 - val_accuracy: 0.8579\n",
            "Epoch 65/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0728 - accuracy: 0.8420 - val_loss: 0.7925 - val_accuracy: 0.8614\n",
            "Epoch 66/150\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0671 - accuracy: 0.8419 - val_loss: 0.7783 - val_accuracy: 0.8673\n",
            "Epoch 67/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0618 - accuracy: 0.8424 - val_loss: 0.7852 - val_accuracy: 0.8660\n",
            "Epoch 68/150\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0593 - accuracy: 0.8441 - val_loss: 0.7673 - val_accuracy: 0.8630\n",
            "Epoch 69/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0458 - accuracy: 0.8408 - val_loss: 0.7762 - val_accuracy: 0.8609\n",
            "Epoch 70/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0382 - accuracy: 0.8443 - val_loss: 0.7658 - val_accuracy: 0.8726\n",
            "Epoch 71/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0428 - accuracy: 0.8450 - val_loss: 0.7807 - val_accuracy: 0.8538\n",
            "Epoch 72/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0333 - accuracy: 0.8446 - val_loss: 0.7658 - val_accuracy: 0.8510\n",
            "Epoch 73/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0275 - accuracy: 0.8449 - val_loss: 0.7421 - val_accuracy: 0.8658\n",
            "Epoch 74/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0253 - accuracy: 0.8466 - val_loss: 0.7509 - val_accuracy: 0.8650\n",
            "Epoch 75/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0166 - accuracy: 0.8479 - val_loss: 0.7408 - val_accuracy: 0.8658\n",
            "Epoch 76/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.0073 - accuracy: 0.8474 - val_loss: 0.7360 - val_accuracy: 0.8652\n",
            "Epoch 77/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.8489 - val_loss: 0.7441 - val_accuracy: 0.8673\n",
            "Epoch 78/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.9973 - accuracy: 0.8483 - val_loss: 0.7327 - val_accuracy: 0.8685\n",
            "Epoch 79/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9952 - accuracy: 0.8488 - val_loss: 0.7202 - val_accuracy: 0.8678\n",
            "Epoch 80/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.9936 - accuracy: 0.8482 - val_loss: 0.7483 - val_accuracy: 0.8553\n",
            "Epoch 81/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9878 - accuracy: 0.8455 - val_loss: 0.7389 - val_accuracy: 0.8589\n",
            "Epoch 82/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9806 - accuracy: 0.8476 - val_loss: 0.7362 - val_accuracy: 0.8607\n",
            "Epoch 83/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9761 - accuracy: 0.8508 - val_loss: 0.7191 - val_accuracy: 0.8670\n",
            "Epoch 84/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9712 - accuracy: 0.8504 - val_loss: 0.7115 - val_accuracy: 0.8719\n",
            "Epoch 85/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9681 - accuracy: 0.8496 - val_loss: 0.7065 - val_accuracy: 0.8688\n",
            "Epoch 86/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9658 - accuracy: 0.8521 - val_loss: 0.7147 - val_accuracy: 0.8675\n",
            "Epoch 87/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9539 - accuracy: 0.8533 - val_loss: 0.7148 - val_accuracy: 0.8734\n",
            "Epoch 88/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9556 - accuracy: 0.8490 - val_loss: 0.7024 - val_accuracy: 0.8698\n",
            "Epoch 89/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9541 - accuracy: 0.8480 - val_loss: 0.6991 - val_accuracy: 0.8805\n",
            "Epoch 90/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9453 - accuracy: 0.8508 - val_loss: 0.6907 - val_accuracy: 0.8708\n",
            "Epoch 91/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9485 - accuracy: 0.8512 - val_loss: 0.6839 - val_accuracy: 0.8752\n",
            "Epoch 92/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9414 - accuracy: 0.8515 - val_loss: 0.6918 - val_accuracy: 0.8744\n",
            "Epoch 93/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9349 - accuracy: 0.8530 - val_loss: 0.6873 - val_accuracy: 0.8772\n",
            "Epoch 94/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9286 - accuracy: 0.8559 - val_loss: 0.6790 - val_accuracy: 0.8780\n",
            "Epoch 95/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9297 - accuracy: 0.8516 - val_loss: 0.6794 - val_accuracy: 0.8685\n",
            "Epoch 96/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9264 - accuracy: 0.8545 - val_loss: 0.6797 - val_accuracy: 0.8754\n",
            "Epoch 97/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9299 - accuracy: 0.8495 - val_loss: 0.6774 - val_accuracy: 0.8754\n",
            "Epoch 98/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9272 - accuracy: 0.8525 - val_loss: 0.6837 - val_accuracy: 0.8734\n",
            "Epoch 99/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.9205 - accuracy: 0.8503 - val_loss: 0.6734 - val_accuracy: 0.8772\n",
            "Epoch 100/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9171 - accuracy: 0.8567 - val_loss: 0.6712 - val_accuracy: 0.8785\n",
            "Epoch 101/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.9091 - accuracy: 0.8540 - val_loss: 0.6660 - val_accuracy: 0.8769\n",
            "Epoch 102/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9138 - accuracy: 0.8540 - val_loss: 0.6626 - val_accuracy: 0.8805\n",
            "Epoch 103/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9069 - accuracy: 0.8537 - val_loss: 0.6676 - val_accuracy: 0.8759\n",
            "Epoch 104/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9094 - accuracy: 0.8547 - val_loss: 0.6640 - val_accuracy: 0.8739\n",
            "Epoch 105/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8943 - accuracy: 0.8579 - val_loss: 0.6649 - val_accuracy: 0.8719\n",
            "Epoch 106/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8950 - accuracy: 0.8542 - val_loss: 0.6535 - val_accuracy: 0.8764\n",
            "Epoch 107/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8915 - accuracy: 0.8582 - val_loss: 0.6540 - val_accuracy: 0.8762\n",
            "Epoch 108/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8982 - accuracy: 0.8530 - val_loss: 0.6467 - val_accuracy: 0.8787\n",
            "Epoch 109/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8940 - accuracy: 0.8562 - val_loss: 0.6554 - val_accuracy: 0.8772\n",
            "Epoch 110/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8909 - accuracy: 0.8546 - val_loss: 0.6462 - val_accuracy: 0.8800\n",
            "Epoch 111/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8895 - accuracy: 0.8565 - val_loss: 0.6441 - val_accuracy: 0.8863\n",
            "Epoch 112/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8775 - accuracy: 0.8564 - val_loss: 0.6508 - val_accuracy: 0.8813\n",
            "Epoch 113/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8739 - accuracy: 0.8572 - val_loss: 0.6411 - val_accuracy: 0.8780\n",
            "Epoch 114/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8811 - accuracy: 0.8546 - val_loss: 0.6372 - val_accuracy: 0.8769\n",
            "Epoch 115/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8759 - accuracy: 0.8571 - val_loss: 0.6432 - val_accuracy: 0.8795\n",
            "Epoch 116/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8787 - accuracy: 0.8596 - val_loss: 0.6405 - val_accuracy: 0.8790\n",
            "Epoch 117/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8801 - accuracy: 0.8570 - val_loss: 0.6368 - val_accuracy: 0.8853\n",
            "Epoch 118/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8647 - accuracy: 0.8597 - val_loss: 0.6285 - val_accuracy: 0.8813\n",
            "Epoch 119/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8654 - accuracy: 0.8573 - val_loss: 0.6422 - val_accuracy: 0.8739\n",
            "Epoch 120/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8628 - accuracy: 0.8596 - val_loss: 0.6340 - val_accuracy: 0.8818\n",
            "Epoch 121/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8645 - accuracy: 0.8587 - val_loss: 0.6401 - val_accuracy: 0.8772\n",
            "Epoch 122/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.8632 - accuracy: 0.8578 - val_loss: 0.6320 - val_accuracy: 0.8838\n",
            "Epoch 123/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.8467 - accuracy: 0.8603 - val_loss: 0.6210 - val_accuracy: 0.8856\n",
            "Epoch 124/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8532 - accuracy: 0.8600 - val_loss: 0.6297 - val_accuracy: 0.8769\n",
            "Epoch 125/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8499 - accuracy: 0.8595 - val_loss: 0.6261 - val_accuracy: 0.8838\n",
            "Epoch 126/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8481 - accuracy: 0.8590 - val_loss: 0.6274 - val_accuracy: 0.8774\n",
            "Epoch 127/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8511 - accuracy: 0.8573 - val_loss: 0.6252 - val_accuracy: 0.8800\n",
            "Epoch 128/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8420 - accuracy: 0.8595 - val_loss: 0.6197 - val_accuracy: 0.8902\n",
            "Epoch 129/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8411 - accuracy: 0.8570 - val_loss: 0.6202 - val_accuracy: 0.8815\n",
            "Epoch 130/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8373 - accuracy: 0.8600 - val_loss: 0.6086 - val_accuracy: 0.8879\n",
            "Epoch 131/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8384 - accuracy: 0.8617 - val_loss: 0.6104 - val_accuracy: 0.8889\n",
            "Epoch 132/150\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.8318 - accuracy: 0.8630 - val_loss: 0.6113 - val_accuracy: 0.8902\n",
            "Epoch 133/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8326 - accuracy: 0.8599 - val_loss: 0.6101 - val_accuracy: 0.8881\n",
            "Epoch 134/150\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.8380 - accuracy: 0.8580 - val_loss: 0.6201 - val_accuracy: 0.8843\n",
            "Epoch 135/150\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8372 - accuracy: 0.8598 - val_loss: 0.6101 - val_accuracy: 0.8785\n",
            "\n",
            "de 0.895\n",
            "fr 0.4007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 2/2 [05:00<00:00, 150.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg_pool_FE</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8843</td>\n",
              "      <td>0.895</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>avg_pool_FE</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8044</td>\n",
              "      <td>0.8104</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         model    task      metric    0  100  ... 5000 10000   15000   25000 40000\n",
              "6  avg_pool_FE  slc_de    accuracy  NaN  NaN  ...  NaN   NaN  0.8843   0.895   NaN\n",
              "7  avg_pool_FE  slc_de  avg_recall  NaN  NaN  ...  NaN   NaN  0.8044  0.8104   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrLOT6sMueEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_max_pool(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.4\n",
        "    filter_sizes =  [2,3,5]\n",
        "    num_filters = 75\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    pool_layer = GlobalMaxPooling1D()(embedd_seq)   \n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVwDSCxuVK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'max_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([15000,25000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_max_pool(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FiZZp6OvSB",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP1eMhccQBtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, MaxPooling1D,AvgPool1D,Dropout,AveragePooling1D, Dense,Embedding, Flatten,Reshape, GlobalAveragePooling1D,MaxPool2D, Concatenate,\\\n",
        "Conv1D,Conv2D,BatchNormalization,Add,Masking,GlobalMaxPooling1D,LayerNormalization,Bidirectional,LSTM,GlobalAveragePooling2D,GlobalMaxPooling2D,GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.regularizers import l1,l2\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t46Nch2Kbk1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,balanced_accuracy_score\n",
        "\n",
        "def pred_encode(model,X_test):\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    return y_pred_test\n",
        "\n",
        "def all_tests(model,de,fr,it,y_it):\n",
        "    y_pred_test = pred_encode(model,de)\n",
        "    print()\n",
        "    print('de',round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "    y_pred_test = pred_encode(model,fr)\n",
        "    print('fr',round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "    y_pred_test = pred_encode(model,it)\n",
        "    print('it',round(accuracy_score(y_pred_test, y_it),4))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHyxPHPN6ENM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_CNN(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.6\n",
        "    filter_sizes =  [3,4,5]\n",
        "    num_filters = 100\n",
        "    lr = .0005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "        maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    #dense_layer = Dense(150,activation='relu')(falt_layer)\n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:], class_weight = class_weight_dict,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 32, shuffle = True,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test, y_test),4)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test, y_test),4)\n",
        "\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCV0XpG6NCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cafd24fb-cf5d-4251-83a0-b6a0f7ef6356"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'CNN1D_max'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000,25000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 34) (100, 75)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 32, 100)      90100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 31, 100)      120100      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 30, 100)      150100      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 100)       0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 1, 100)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 1, 100)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 100)       0           max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "                                                                 max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,255,275\n",
            "Trainable params: 7,255,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 5.1327 - accuracy: 0.0000e+00 - val_loss: 4.4455 - val_accuracy: 0.0069\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 4.9504 - accuracy: 0.0400 - val_loss: 4.4485 - val_accuracy: 0.0046\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 4.4907 - accuracy: 0.0500 - val_loss: 4.5199 - val_accuracy: 0.0053\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 2s 507ms/step - loss: 3.9411 - accuracy: 0.0600 - val_loss: 4.6007 - val_accuracy: 0.0018\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 3.6719 - accuracy: 0.0400 - val_loss: 4.6538 - val_accuracy: 0.0013\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 2s 501ms/step - loss: 4.1597 - accuracy: 0.0200 - val_loss: 4.6598 - val_accuracy: 0.0023\n",
            "\n",
            "de 0.0046\n",
            "fr 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 11%|█         | 1/9 [00:18<02:27, 18.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0\n",
            "(250, 34) (250, 75)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 32, 100)      90100       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 31, 100)      120100      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 30, 100)      150100      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 1, 100)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 1, 100)       0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 1, 100)       0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 100)       0           max_pooling1d_6[0][0]            \n",
            "                                                                 max_pooling1d_7[0][0]            \n",
            "                                                                 max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,255,275\n",
            "Trainable params: 7,255,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 3s 357ms/step - loss: 4.6325 - accuracy: 0.0320 - val_loss: 4.1328 - val_accuracy: 0.0147\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 4.1407 - accuracy: 0.0360 - val_loss: 4.2329 - val_accuracy: 0.0074\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 3.8667 - accuracy: 0.0440 - val_loss: 4.2454 - val_accuracy: 0.0145\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 3.9324 - accuracy: 0.0520 - val_loss: 4.1745 - val_accuracy: 0.0010\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 3s 324ms/step - loss: 3.8406 - accuracy: 0.0320 - val_loss: 4.1408 - val_accuracy: 0.0036\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 3s 324ms/step - loss: 3.7454 - accuracy: 0.0240 - val_loss: 4.1345 - val_accuracy: 0.0089\n",
            "\n",
            "de 0.0107\n",
            "fr 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 22%|██▏       | 2/9 [00:40<02:16, 19.51s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0015\n",
            "(500, 34) (500, 75)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 32, 100)      90100       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 31, 100)      120100      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 30, 100)      150100      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 1, 100)       0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 1, 100)       0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 1, 100)       0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 100)       0           max_pooling1d_9[0][0]            \n",
            "                                                                 max_pooling1d_10[0][0]           \n",
            "                                                                 max_pooling1d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,255,275\n",
            "Trainable params: 7,255,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 4s 236ms/step - loss: 5.7404 - accuracy: 0.0180 - val_loss: 4.2926 - val_accuracy: 0.0064\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 4.8037 - accuracy: 0.0300 - val_loss: 4.1645 - val_accuracy: 0.0010\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 4.4663 - accuracy: 0.0240 - val_loss: 4.3551 - val_accuracy: 5.0852e-04\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 4s 232ms/step - loss: 4.3149 - accuracy: 0.0100 - val_loss: 4.2907 - val_accuracy: 5.0852e-04\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 4s 234ms/step - loss: 3.9949 - accuracy: 0.0200 - val_loss: 4.2073 - val_accuracy: 0.0066\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 4.0861 - accuracy: 0.0220 - val_loss: 4.1739 - val_accuracy: 0.0061\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 3.9729 - accuracy: 0.0320 - val_loss: 4.0673 - val_accuracy: 0.0066\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 3.5853 - accuracy: 0.0400 - val_loss: 4.1075 - val_accuracy: 0.0058\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 3.5347 - accuracy: 0.0480 - val_loss: 3.9702 - val_accuracy: 0.0086\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 3.4767 - accuracy: 0.0740 - val_loss: 3.9252 - val_accuracy: 0.0216\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 3.2311 - accuracy: 0.1160 - val_loss: 3.7751 - val_accuracy: 0.0712\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 3.0753 - accuracy: 0.1360 - val_loss: 3.7582 - val_accuracy: 0.0567\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 2.8654 - accuracy: 0.1960 - val_loss: 3.6622 - val_accuracy: 0.1274\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 2.8900 - accuracy: 0.2320 - val_loss: 3.5757 - val_accuracy: 0.1704\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 2.7528 - accuracy: 0.3300 - val_loss: 3.4348 - val_accuracy: 0.2476\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 2.5549 - accuracy: 0.4000 - val_loss: 3.3579 - val_accuracy: 0.3478\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 2.3841 - accuracy: 0.4700 - val_loss: 3.2741 - val_accuracy: 0.3755\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 2.2302 - accuracy: 0.4960 - val_loss: 3.1463 - val_accuracy: 0.4594\n",
            "Epoch 19/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5f7d6178571a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0;31m#run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m      \u001b[0mrun_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight_dict_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-7fe882cb6a17>\u001b[0m in \u001b[0;36mrun_CNN\u001b[0;34m(X_train_emb, y_train_enc, X_val_emb, y_val_enc, X_test_emb, y_test, class_weight_dict, no)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_cnn1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mde_cnn1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight_dict\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m#verbose =0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R160K2m68gyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_CNN(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.6\n",
        "    filter_sizes =  [3,4,5]\n",
        "    num_filters = 100\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "        maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    #dense_layer = Dense(150,activation='relu')(falt_layer)\n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "\n",
        "\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmdY_xWO8jY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65515099-6113-4f37-cd12-27d9a21946f8"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'CNN1D_WOET'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000,25000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 31) (100, 75)\n",
            "Model: \"model_91\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_52 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_144 (Conv1D)             (None, 29, 100)      90100       embedding_52[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_145 (Conv1D)             (None, 28, 100)      120100      embedding_52[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_146 (Conv1D)             (None, 27, 100)      150100      embedding_52[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_138 (MaxPooling1D (None, 1, 100)       0           conv1d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_139 (MaxPooling1D (None, 1, 100)       0           conv1d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_140 (MaxPooling1D (None, 1, 100)       0           conv1d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 3, 100)       0           max_pooling1d_138[0][0]          \n",
            "                                                                 max_pooling1d_139[0][0]          \n",
            "                                                                 max_pooling1d_140[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 7.0222 - accuracy: 0.0100 - val_loss: 4.3010 - val_accuracy: 0.0064\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 6.3130 - accuracy: 0.0100 - val_loss: 4.3355 - val_accuracy: 0.0097\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 4.6465 - accuracy: 0.0100 - val_loss: 4.5342 - val_accuracy: 5.0852e-04\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 5.0910 - accuracy: 0.0100 - val_loss: 4.7724 - val_accuracy: 5.0852e-04\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 4.3314 - accuracy: 0.0300 - val_loss: 5.1245 - val_accuracy: 5.0852e-04\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 3.8867 - accuracy: 0.0100 - val_loss: 5.2797 - val_accuracy: 5.0852e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 1/9 [00:02<00:22,  2.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.0\n",
            "fr 0.0021\n",
            "it 0.0\n",
            "(250, 31) (250, 75)\n",
            "Model: \"model_92\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_53 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_147 (Conv1D)             (None, 29, 100)      90100       embedding_53[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_148 (Conv1D)             (None, 28, 100)      120100      embedding_53[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_149 (Conv1D)             (None, 27, 100)      150100      embedding_53[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_141 (MaxPooling1D (None, 1, 100)       0           conv1d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_142 (MaxPooling1D (None, 1, 100)       0           conv1d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_143 (MaxPooling1D (None, 1, 100)       0           conv1d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 3, 100)       0           max_pooling1d_141[0][0]          \n",
            "                                                                 max_pooling1d_142[0][0]          \n",
            "                                                                 max_pooling1d_143[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 4.3977 - accuracy: 0.0040 - val_loss: 4.3416 - val_accuracy: 0.0020\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.9515 - accuracy: 0.0160 - val_loss: 4.2008 - val_accuracy: 0.0064\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.4483 - accuracy: 0.0360 - val_loss: 4.1428 - val_accuracy: 0.0120\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.3314 - accuracy: 0.0320 - val_loss: 4.1183 - val_accuracy: 0.0127\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 3.2750 - accuracy: 0.0400 - val_loss: 4.1561 - val_accuracy: 0.0036\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 3.3106 - accuracy: 0.0200 - val_loss: 4.1287 - val_accuracy: 0.0048\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.2047 - accuracy: 0.0440 - val_loss: 4.1049 - val_accuracy: 0.0165\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 3.1354 - accuracy: 0.0720 - val_loss: 4.0943 - val_accuracy: 0.0191\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.9361 - accuracy: 0.0680 - val_loss: 4.0765 - val_accuracy: 0.0186\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.9294 - accuracy: 0.0800 - val_loss: 4.0482 - val_accuracy: 0.0158\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.9016 - accuracy: 0.0640 - val_loss: 4.0523 - val_accuracy: 0.0188\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.8411 - accuracy: 0.1160 - val_loss: 4.0310 - val_accuracy: 0.0191\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.5777 - accuracy: 0.0840 - val_loss: 4.0219 - val_accuracy: 0.0193\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.6776 - accuracy: 0.0680 - val_loss: 3.9762 - val_accuracy: 0.0198\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.6947 - accuracy: 0.0960 - val_loss: 3.9330 - val_accuracy: 0.0257\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.5853 - accuracy: 0.0840 - val_loss: 3.8449 - val_accuracy: 0.0509\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.5989 - accuracy: 0.1160 - val_loss: 3.8260 - val_accuracy: 0.0740\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.5026 - accuracy: 0.1400 - val_loss: 3.8384 - val_accuracy: 0.0417\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.4237 - accuracy: 0.1320 - val_loss: 3.8049 - val_accuracy: 0.0450\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.2936 - accuracy: 0.1480 - val_loss: 3.7717 - val_accuracy: 0.0481\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.4587 - accuracy: 0.1640 - val_loss: 3.7659 - val_accuracy: 0.0536\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.3123 - accuracy: 0.1400 - val_loss: 3.7564 - val_accuracy: 0.0608\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.2711 - accuracy: 0.1800 - val_loss: 3.7467 - val_accuracy: 0.0763\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.2056 - accuracy: 0.2000 - val_loss: 3.7100 - val_accuracy: 0.0880\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.1433 - accuracy: 0.1880 - val_loss: 3.6731 - val_accuracy: 0.0908\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.1515 - accuracy: 0.2360 - val_loss: 3.6109 - val_accuracy: 0.1022\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.9946 - accuracy: 0.2800 - val_loss: 3.5494 - val_accuracy: 0.2771\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.9417 - accuracy: 0.2880 - val_loss: 3.5113 - val_accuracy: 0.3707\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.9479 - accuracy: 0.2880 - val_loss: 3.5183 - val_accuracy: 0.3521\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.9019 - accuracy: 0.2640 - val_loss: 3.5621 - val_accuracy: 0.1299\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.8015 - accuracy: 0.2480 - val_loss: 3.5614 - val_accuracy: 0.1149\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.7214 - accuracy: 0.2920 - val_loss: 3.5578 - val_accuracy: 0.1165\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.7148 - accuracy: 0.2840 - val_loss: 3.4929 - val_accuracy: 0.1617\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.7091 - accuracy: 0.3040 - val_loss: 3.3767 - val_accuracy: 0.2700\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.5805 - accuracy: 0.3760 - val_loss: 3.2850 - val_accuracy: 0.3877\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.6702 - accuracy: 0.3680 - val_loss: 3.2480 - val_accuracy: 0.4404\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.6133 - accuracy: 0.3920 - val_loss: 3.2486 - val_accuracy: 0.4317\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.4810 - accuracy: 0.4880 - val_loss: 3.2456 - val_accuracy: 0.4315\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.5029 - accuracy: 0.4720 - val_loss: 3.2458 - val_accuracy: 0.4254\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.4607 - accuracy: 0.4920 - val_loss: 3.2461 - val_accuracy: 0.4394\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.4405 - accuracy: 0.4680 - val_loss: 3.2089 - val_accuracy: 0.4640\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.3292 - accuracy: 0.4880 - val_loss: 3.1453 - val_accuracy: 0.4739\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.3666 - accuracy: 0.5080 - val_loss: 3.0868 - val_accuracy: 0.4897\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.2957 - accuracy: 0.5640 - val_loss: 3.0583 - val_accuracy: 0.4961\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.2858 - accuracy: 0.5360 - val_loss: 3.0593 - val_accuracy: 0.4833\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.1885 - accuracy: 0.5320 - val_loss: 3.0443 - val_accuracy: 0.4856\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.2588 - accuracy: 0.4960 - val_loss: 2.9933 - val_accuracy: 0.4968\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.0969 - accuracy: 0.6200 - val_loss: 2.9607 - val_accuracy: 0.5080\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1522 - accuracy: 0.6120 - val_loss: 2.9482 - val_accuracy: 0.5103\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.0772 - accuracy: 0.6280 - val_loss: 2.9032 - val_accuracy: 0.5212\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0632 - accuracy: 0.6560 - val_loss: 2.8415 - val_accuracy: 0.5278\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0616 - accuracy: 0.6840 - val_loss: 2.8095 - val_accuracy: 0.5240\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9805 - accuracy: 0.6600 - val_loss: 2.8063 - val_accuracy: 0.5240\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0158 - accuracy: 0.6800 - val_loss: 2.7813 - val_accuracy: 0.5324\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.9858 - accuracy: 0.6800 - val_loss: 2.7769 - val_accuracy: 0.5365\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9096 - accuracy: 0.7080 - val_loss: 2.7582 - val_accuracy: 0.5543\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9164 - accuracy: 0.7240 - val_loss: 2.7211 - val_accuracy: 0.5606\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.9533 - accuracy: 0.7040 - val_loss: 2.6785 - val_accuracy: 0.5611\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8463 - accuracy: 0.7400 - val_loss: 2.6534 - val_accuracy: 0.5586\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.8435 - accuracy: 0.8000 - val_loss: 2.6109 - val_accuracy: 0.5581\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.8147 - accuracy: 0.7320 - val_loss: 2.5742 - val_accuracy: 0.5584\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.7514 - accuracy: 0.8120 - val_loss: 2.5559 - val_accuracy: 0.5604\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.8468 - accuracy: 0.7880 - val_loss: 2.5621 - val_accuracy: 0.5708\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.6878 - accuracy: 0.8160 - val_loss: 2.5738 - val_accuracy: 0.5751\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.7250 - accuracy: 0.7600 - val_loss: 2.5649 - val_accuracy: 0.5805\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.7216 - accuracy: 0.7720 - val_loss: 2.5253 - val_accuracy: 0.5845\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.6657 - accuracy: 0.8200 - val_loss: 2.4782 - val_accuracy: 0.5835\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.6550 - accuracy: 0.8120 - val_loss: 2.4337 - val_accuracy: 0.5795\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.6601 - accuracy: 0.8560 - val_loss: 2.4240 - val_accuracy: 0.5840\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.6481 - accuracy: 0.8360 - val_loss: 2.4297 - val_accuracy: 0.5835\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.5533 - accuracy: 0.8360 - val_loss: 2.4462 - val_accuracy: 0.5853\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5929 - accuracy: 0.8520 - val_loss: 2.4376 - val_accuracy: 0.5901\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.5579 - accuracy: 0.8440 - val_loss: 2.4222 - val_accuracy: 0.5889\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.5788 - accuracy: 0.8600 - val_loss: 2.3996 - val_accuracy: 0.5934\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.5668 - accuracy: 0.8480 - val_loss: 2.3822 - val_accuracy: 0.5942\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.5310 - accuracy: 0.8800 - val_loss: 2.3473 - val_accuracy: 0.5962\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.5130 - accuracy: 0.8760 - val_loss: 2.3171 - val_accuracy: 0.5993\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4799 - accuracy: 0.8920 - val_loss: 2.2995 - val_accuracy: 0.6003\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4746 - accuracy: 0.9040 - val_loss: 2.2902 - val_accuracy: 0.6062\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4622 - accuracy: 0.8680 - val_loss: 2.2847 - val_accuracy: 0.6120\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.4907 - accuracy: 0.8840 - val_loss: 2.2824 - val_accuracy: 0.6125\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4484 - accuracy: 0.8880 - val_loss: 2.2751 - val_accuracy: 0.6097\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4135 - accuracy: 0.9320 - val_loss: 2.2692 - val_accuracy: 0.6097\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.4662 - accuracy: 0.9160 - val_loss: 2.2647 - val_accuracy: 0.6105\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4218 - accuracy: 0.9160 - val_loss: 2.2640 - val_accuracy: 0.6062\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4215 - accuracy: 0.9160 - val_loss: 2.2619 - val_accuracy: 0.6074\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3621 - accuracy: 0.9280 - val_loss: 2.2473 - val_accuracy: 0.6135\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4172 - accuracy: 0.9040 - val_loss: 2.2449 - val_accuracy: 0.6166\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3630 - accuracy: 0.9320 - val_loss: 2.2379 - val_accuracy: 0.6153\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3483 - accuracy: 0.9240 - val_loss: 2.2281 - val_accuracy: 0.6168\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4119 - accuracy: 0.9400 - val_loss: 2.2176 - val_accuracy: 0.6156\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.3734 - accuracy: 0.9040 - val_loss: 2.2132 - val_accuracy: 0.6171\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3363 - accuracy: 0.9320 - val_loss: 2.1959 - val_accuracy: 0.6191\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3268 - accuracy: 0.9520 - val_loss: 2.1791 - val_accuracy: 0.6156\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3192 - accuracy: 0.9520 - val_loss: 2.1728 - val_accuracy: 0.6186\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3384 - accuracy: 0.9320 - val_loss: 2.1650 - val_accuracy: 0.6224\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3166 - accuracy: 0.9320 - val_loss: 2.1534 - val_accuracy: 0.6275\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2830 - accuracy: 0.9320 - val_loss: 2.1512 - val_accuracy: 0.6331\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.2808 - accuracy: 0.9760 - val_loss: 2.1576 - val_accuracy: 0.6339\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.3242 - accuracy: 0.9200 - val_loss: 2.1549 - val_accuracy: 0.6336\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3246 - accuracy: 0.9280 - val_loss: 2.1534 - val_accuracy: 0.6341\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2717 - accuracy: 0.9560 - val_loss: 2.1568 - val_accuracy: 0.6349\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.2731 - accuracy: 0.9360 - val_loss: 2.1420 - val_accuracy: 0.6334\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.3182 - accuracy: 0.9440 - val_loss: 2.1330 - val_accuracy: 0.6346\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.2796 - accuracy: 0.9360 - val_loss: 2.1280 - val_accuracy: 0.6313\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2592 - accuracy: 0.9320 - val_loss: 2.1207 - val_accuracy: 0.6321\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.2621 - accuracy: 0.9680 - val_loss: 2.1154 - val_accuracy: 0.6334\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2772 - accuracy: 0.9400 - val_loss: 2.1155 - val_accuracy: 0.6392\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2494 - accuracy: 0.9480 - val_loss: 2.1060 - val_accuracy: 0.6438\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.1969 - accuracy: 0.9560 - val_loss: 2.0968 - val_accuracy: 0.6466\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2280 - accuracy: 0.9800 - val_loss: 2.0946 - val_accuracy: 0.6491\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.2247 - accuracy: 0.9680 - val_loss: 2.0964 - val_accuracy: 0.6509\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2466 - accuracy: 0.9520 - val_loss: 2.0961 - val_accuracy: 0.6481\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.2181 - accuracy: 0.9560 - val_loss: 2.0902 - val_accuracy: 0.6479\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.2050 - accuracy: 0.9640 - val_loss: 2.0868 - val_accuracy: 0.6486\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.2215 - accuracy: 0.9400 - val_loss: 2.0913 - val_accuracy: 0.6471\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.1836 - accuracy: 0.9760 - val_loss: 2.0937 - val_accuracy: 0.6463\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.1829 - accuracy: 0.9720 - val_loss: 2.0934 - val_accuracy: 0.6484\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.1740 - accuracy: 0.9480 - val_loss: 2.0879 - val_accuracy: 0.6491\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.1637 - accuracy: 0.9760 - val_loss: 2.0830 - val_accuracy: 0.6494\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.1916 - accuracy: 0.9680 - val_loss: 2.0810 - val_accuracy: 0.6540\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2403 - accuracy: 0.9600 - val_loss: 2.0770 - val_accuracy: 0.6552\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.1875 - accuracy: 0.9520 - val_loss: 2.0753 - val_accuracy: 0.6573\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.1721 - accuracy: 0.9680 - val_loss: 2.0730 - val_accuracy: 0.6593\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.1912 - accuracy: 0.9800 - val_loss: 2.0732 - val_accuracy: 0.6578\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.2072 - accuracy: 0.9680 - val_loss: 2.0770 - val_accuracy: 0.6565\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.1856 - accuracy: 0.9440 - val_loss: 2.0828 - val_accuracy: 0.6534\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.1689 - accuracy: 0.9680 - val_loss: 2.0847 - val_accuracy: 0.6506\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.1763 - accuracy: 0.9520 - val_loss: 2.0791 - val_accuracy: 0.6496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 2/9 [00:33<01:18, 11.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.6481\n",
            "fr 0.1723\n",
            "it 0.2417\n",
            "(500, 31) (500, 75)\n",
            "Model: \"model_93\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_54 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_150 (Conv1D)             (None, 29, 100)      90100       embedding_54[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_151 (Conv1D)             (None, 28, 100)      120100      embedding_54[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_152 (Conv1D)             (None, 27, 100)      150100      embedding_54[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_144 (MaxPooling1D (None, 1, 100)       0           conv1d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_145 (MaxPooling1D (None, 1, 100)       0           conv1d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_146 (MaxPooling1D (None, 1, 100)       0           conv1d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 3, 100)       0           max_pooling1d_144[0][0]          \n",
            "                                                                 max_pooling1d_145[0][0]          \n",
            "                                                                 max_pooling1d_146[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 4.4337 - accuracy: 0.0160 - val_loss: 4.1032 - val_accuracy: 0.0163\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.9629 - accuracy: 0.0320 - val_loss: 4.1319 - val_accuracy: 0.0112\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.9415 - accuracy: 0.0340 - val_loss: 4.0616 - val_accuracy: 0.0371\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.7798 - accuracy: 0.0280 - val_loss: 4.0444 - val_accuracy: 0.0033\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.7183 - accuracy: 0.0360 - val_loss: 3.9674 - val_accuracy: 0.0221\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.5663 - accuracy: 0.0480 - val_loss: 4.0303 - val_accuracy: 0.0445\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.4750 - accuracy: 0.0520 - val_loss: 3.9980 - val_accuracy: 0.0402\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.3452 - accuracy: 0.0640 - val_loss: 3.9740 - val_accuracy: 0.0557\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.2725 - accuracy: 0.0720 - val_loss: 3.9120 - val_accuracy: 0.0557\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.1791 - accuracy: 0.0920 - val_loss: 3.8457 - val_accuracy: 0.0631\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.1432 - accuracy: 0.0880 - val_loss: 3.7651 - val_accuracy: 0.1070\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.0499 - accuracy: 0.1180 - val_loss: 3.6797 - val_accuracy: 0.2932\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.8578 - accuracy: 0.2040 - val_loss: 3.6151 - val_accuracy: 0.3453\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.8878 - accuracy: 0.1980 - val_loss: 3.5872 - val_accuracy: 0.3041\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.7276 - accuracy: 0.2060 - val_loss: 3.5966 - val_accuracy: 0.1882\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.6992 - accuracy: 0.1900 - val_loss: 3.5401 - val_accuracy: 0.1925\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.5430 - accuracy: 0.2020 - val_loss: 3.4807 - val_accuracy: 0.3064\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.4228 - accuracy: 0.2580 - val_loss: 3.3788 - val_accuracy: 0.3852\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.3646 - accuracy: 0.3140 - val_loss: 3.2692 - val_accuracy: 0.4633\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.2946 - accuracy: 0.3340 - val_loss: 3.2332 - val_accuracy: 0.4887\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.1343 - accuracy: 0.3420 - val_loss: 3.1741 - val_accuracy: 0.5050\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.1201 - accuracy: 0.3800 - val_loss: 3.0858 - val_accuracy: 0.5161\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.0664 - accuracy: 0.4060 - val_loss: 3.0634 - val_accuracy: 0.5375\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.9117 - accuracy: 0.4060 - val_loss: 3.0098 - val_accuracy: 0.5444\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.8539 - accuracy: 0.4440 - val_loss: 2.9340 - val_accuracy: 0.5634\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.7633 - accuracy: 0.4780 - val_loss: 2.8315 - val_accuracy: 0.5779\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.6960 - accuracy: 0.5320 - val_loss: 2.7494 - val_accuracy: 0.5950\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6527 - accuracy: 0.5540 - val_loss: 2.6813 - val_accuracy: 0.5990\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.5781 - accuracy: 0.5940 - val_loss: 2.6186 - val_accuracy: 0.6095\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.5734 - accuracy: 0.5800 - val_loss: 2.6138 - val_accuracy: 0.6171\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4111 - accuracy: 0.5680 - val_loss: 2.6137 - val_accuracy: 0.6212\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.4402 - accuracy: 0.6160 - val_loss: 2.4763 - val_accuracy: 0.6326\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3529 - accuracy: 0.6400 - val_loss: 2.4038 - val_accuracy: 0.6303\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3593 - accuracy: 0.6540 - val_loss: 2.3422 - val_accuracy: 0.6438\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2506 - accuracy: 0.6920 - val_loss: 2.2906 - val_accuracy: 0.6445\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.2452 - accuracy: 0.6980 - val_loss: 2.2268 - val_accuracy: 0.6570\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1522 - accuracy: 0.7060 - val_loss: 2.2481 - val_accuracy: 0.6451\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1636 - accuracy: 0.6840 - val_loss: 2.1895 - val_accuracy: 0.6598\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0652 - accuracy: 0.7100 - val_loss: 2.1575 - val_accuracy: 0.6791\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0443 - accuracy: 0.7280 - val_loss: 2.1253 - val_accuracy: 0.6766\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0271 - accuracy: 0.7580 - val_loss: 2.0740 - val_accuracy: 0.6845\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9914 - accuracy: 0.7400 - val_loss: 1.9829 - val_accuracy: 0.6817\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9242 - accuracy: 0.7860 - val_loss: 1.9396 - val_accuracy: 0.6776\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8934 - accuracy: 0.8080 - val_loss: 1.9485 - val_accuracy: 0.6936\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8366 - accuracy: 0.8060 - val_loss: 1.9120 - val_accuracy: 0.6860\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8676 - accuracy: 0.8260 - val_loss: 1.8813 - val_accuracy: 0.6901\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8219 - accuracy: 0.7880 - val_loss: 1.8764 - val_accuracy: 0.7033\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7917 - accuracy: 0.8180 - val_loss: 1.8471 - val_accuracy: 0.7048\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7361 - accuracy: 0.8260 - val_loss: 1.7969 - val_accuracy: 0.7071\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7155 - accuracy: 0.8320 - val_loss: 1.7524 - val_accuracy: 0.7155\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6644 - accuracy: 0.8700 - val_loss: 1.7258 - val_accuracy: 0.7162\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7077 - accuracy: 0.8240 - val_loss: 1.7402 - val_accuracy: 0.7173\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6936 - accuracy: 0.8420 - val_loss: 1.6837 - val_accuracy: 0.7206\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7034 - accuracy: 0.8300 - val_loss: 1.6578 - val_accuracy: 0.7223\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6336 - accuracy: 0.8620 - val_loss: 1.6429 - val_accuracy: 0.7262\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6013 - accuracy: 0.8880 - val_loss: 1.6505 - val_accuracy: 0.7173\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5332 - accuracy: 0.8720 - val_loss: 1.6300 - val_accuracy: 0.7249\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5483 - accuracy: 0.8700 - val_loss: 1.5870 - val_accuracy: 0.7282\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5556 - accuracy: 0.8680 - val_loss: 1.5932 - val_accuracy: 0.7305\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5160 - accuracy: 0.8660 - val_loss: 1.6073 - val_accuracy: 0.7346\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4752 - accuracy: 0.9040 - val_loss: 1.5835 - val_accuracy: 0.7391\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4904 - accuracy: 0.8740 - val_loss: 1.5589 - val_accuracy: 0.7368\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4734 - accuracy: 0.8840 - val_loss: 1.5473 - val_accuracy: 0.7401\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4762 - accuracy: 0.8860 - val_loss: 1.5255 - val_accuracy: 0.7394\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4370 - accuracy: 0.9040 - val_loss: 1.5074 - val_accuracy: 0.7391\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4652 - accuracy: 0.8920 - val_loss: 1.5261 - val_accuracy: 0.7429\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3999 - accuracy: 0.9200 - val_loss: 1.5323 - val_accuracy: 0.7445\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4102 - accuracy: 0.9240 - val_loss: 1.5085 - val_accuracy: 0.7493\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4221 - accuracy: 0.9120 - val_loss: 1.4886 - val_accuracy: 0.7480\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3919 - accuracy: 0.9100 - val_loss: 1.4982 - val_accuracy: 0.7427\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3999 - accuracy: 0.9000 - val_loss: 1.4966 - val_accuracy: 0.7419\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3713 - accuracy: 0.9260 - val_loss: 1.4563 - val_accuracy: 0.7551\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3331 - accuracy: 0.9460 - val_loss: 1.4315 - val_accuracy: 0.7577\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3546 - accuracy: 0.9040 - val_loss: 1.4307 - val_accuracy: 0.7590\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3307 - accuracy: 0.9440 - val_loss: 1.4468 - val_accuracy: 0.7551\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3104 - accuracy: 0.9360 - val_loss: 1.4539 - val_accuracy: 0.7521\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3105 - accuracy: 0.9460 - val_loss: 1.4369 - val_accuracy: 0.7574\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3151 - accuracy: 0.9140 - val_loss: 1.4126 - val_accuracy: 0.7587\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3033 - accuracy: 0.9340 - val_loss: 1.4043 - val_accuracy: 0.7577\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3205 - accuracy: 0.9380 - val_loss: 1.4087 - val_accuracy: 0.7572\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2865 - accuracy: 0.9220 - val_loss: 1.4150 - val_accuracy: 0.7595\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3060 - accuracy: 0.9220 - val_loss: 1.4067 - val_accuracy: 0.7625\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2719 - accuracy: 0.9440 - val_loss: 1.3740 - val_accuracy: 0.7635\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.2547 - accuracy: 0.9560 - val_loss: 1.3555 - val_accuracy: 0.7605\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.2495 - accuracy: 0.9540 - val_loss: 1.3581 - val_accuracy: 0.7638\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2599 - accuracy: 0.9400 - val_loss: 1.3561 - val_accuracy: 0.7704\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2537 - accuracy: 0.9560 - val_loss: 1.3617 - val_accuracy: 0.7707\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2415 - accuracy: 0.9600 - val_loss: 1.3627 - val_accuracy: 0.7679\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2500 - accuracy: 0.9620 - val_loss: 1.3714 - val_accuracy: 0.7707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 3/9 [00:57<01:29, 14.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.7714\n",
            "fr 0.235\n",
            "it 0.3128\n",
            "(1000, 31) (1000, 75)\n",
            "Model: \"model_94\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_55 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_153 (Conv1D)             (None, 29, 100)      90100       embedding_55[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_154 (Conv1D)             (None, 28, 100)      120100      embedding_55[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 27, 100)      150100      embedding_55[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_147 (MaxPooling1D (None, 1, 100)       0           conv1d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_148 (MaxPooling1D (None, 1, 100)       0           conv1d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_149 (MaxPooling1D (None, 1, 100)       0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 100)       0           max_pooling1d_147[0][0]          \n",
            "                                                                 max_pooling1d_148[0][0]          \n",
            "                                                                 max_pooling1d_149[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 4.7309 - accuracy: 0.0190 - val_loss: 4.3429 - val_accuracy: 0.0186\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 4.3094 - accuracy: 0.0270 - val_loss: 4.0807 - val_accuracy: 0.0165\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 4.0039 - accuracy: 0.0420 - val_loss: 4.0103 - val_accuracy: 0.0183\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.9856 - accuracy: 0.0390 - val_loss: 3.9950 - val_accuracy: 0.0572\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.8815 - accuracy: 0.0430 - val_loss: 3.9285 - val_accuracy: 0.0585\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.6990 - accuracy: 0.0500 - val_loss: 3.8745 - val_accuracy: 0.0534\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.6134 - accuracy: 0.0850 - val_loss: 3.8367 - val_accuracy: 0.0669\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.4401 - accuracy: 0.0790 - val_loss: 3.8021 - val_accuracy: 0.0941\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.3404 - accuracy: 0.1060 - val_loss: 3.5967 - val_accuracy: 0.1159\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.1955 - accuracy: 0.1860 - val_loss: 3.5099 - val_accuracy: 0.1447\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.1077 - accuracy: 0.1700 - val_loss: 3.4429 - val_accuracy: 0.1345\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.8791 - accuracy: 0.1880 - val_loss: 3.3683 - val_accuracy: 0.1973\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.9012 - accuracy: 0.2120 - val_loss: 3.2500 - val_accuracy: 0.2258\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.7317 - accuracy: 0.2770 - val_loss: 3.0746 - val_accuracy: 0.5044\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.5965 - accuracy: 0.2840 - val_loss: 3.0821 - val_accuracy: 0.4068\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.4222 - accuracy: 0.3340 - val_loss: 2.8625 - val_accuracy: 0.5428\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.3588 - accuracy: 0.3860 - val_loss: 2.8425 - val_accuracy: 0.5258\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 2.2154 - accuracy: 0.3810 - val_loss: 2.7412 - val_accuracy: 0.5482\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 2.1140 - accuracy: 0.4840 - val_loss: 2.5452 - val_accuracy: 0.5955\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.9331 - accuracy: 0.4780 - val_loss: 2.5319 - val_accuracy: 0.6036\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.8832 - accuracy: 0.5090 - val_loss: 2.2983 - val_accuracy: 0.6364\n",
            "Epoch 22/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.8158 - accuracy: 0.5510 - val_loss: 2.3628 - val_accuracy: 0.6242\n",
            "Epoch 23/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.6717 - accuracy: 0.5630 - val_loss: 2.1804 - val_accuracy: 0.6473\n",
            "Epoch 24/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.5757 - accuracy: 0.6240 - val_loss: 2.0628 - val_accuracy: 0.6445\n",
            "Epoch 25/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.5345 - accuracy: 0.6010 - val_loss: 2.0231 - val_accuracy: 0.6621\n",
            "Epoch 26/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.4484 - accuracy: 0.6310 - val_loss: 1.9204 - val_accuracy: 0.6804\n",
            "Epoch 27/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.3579 - accuracy: 0.6610 - val_loss: 1.8035 - val_accuracy: 0.6916\n",
            "Epoch 28/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.3428 - accuracy: 0.6830 - val_loss: 1.7776 - val_accuracy: 0.7068\n",
            "Epoch 29/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.2320 - accuracy: 0.6800 - val_loss: 1.6506 - val_accuracy: 0.7262\n",
            "Epoch 30/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.2094 - accuracy: 0.7130 - val_loss: 1.6791 - val_accuracy: 0.7269\n",
            "Epoch 31/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.1416 - accuracy: 0.7220 - val_loss: 1.5658 - val_accuracy: 0.7343\n",
            "Epoch 32/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.0822 - accuracy: 0.7550 - val_loss: 1.4824 - val_accuracy: 0.7399\n",
            "Epoch 33/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.0966 - accuracy: 0.7450 - val_loss: 1.5217 - val_accuracy: 0.7551\n",
            "Epoch 34/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.0292 - accuracy: 0.7560 - val_loss: 1.4700 - val_accuracy: 0.7595\n",
            "Epoch 35/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.9701 - accuracy: 0.7670 - val_loss: 1.3692 - val_accuracy: 0.7638\n",
            "Epoch 36/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.8899 - accuracy: 0.7810 - val_loss: 1.3146 - val_accuracy: 0.7681\n",
            "Epoch 37/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.9172 - accuracy: 0.7900 - val_loss: 1.2891 - val_accuracy: 0.7717\n",
            "Epoch 38/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.8460 - accuracy: 0.8020 - val_loss: 1.2820 - val_accuracy: 0.7811\n",
            "Epoch 39/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.8308 - accuracy: 0.8010 - val_loss: 1.2368 - val_accuracy: 0.7859\n",
            "Epoch 40/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.7724 - accuracy: 0.8160 - val_loss: 1.1681 - val_accuracy: 0.7979\n",
            "Epoch 41/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.7709 - accuracy: 0.8200 - val_loss: 1.1668 - val_accuracy: 0.7933\n",
            "Epoch 42/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.7033 - accuracy: 0.8350 - val_loss: 1.1643 - val_accuracy: 0.8004\n",
            "Epoch 43/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.6782 - accuracy: 0.8380 - val_loss: 1.1505 - val_accuracy: 0.8040\n",
            "Epoch 44/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.7186 - accuracy: 0.8350 - val_loss: 1.1044 - val_accuracy: 0.8035\n",
            "Epoch 45/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.6349 - accuracy: 0.8670 - val_loss: 1.0619 - val_accuracy: 0.8098\n",
            "Epoch 46/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.6102 - accuracy: 0.8740 - val_loss: 1.0233 - val_accuracy: 0.8230\n",
            "Epoch 47/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5898 - accuracy: 0.8790 - val_loss: 1.0213 - val_accuracy: 0.8225\n",
            "Epoch 48/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5799 - accuracy: 0.8720 - val_loss: 1.0035 - val_accuracy: 0.8233\n",
            "Epoch 49/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5776 - accuracy: 0.8750 - val_loss: 0.9857 - val_accuracy: 0.8228\n",
            "Epoch 50/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.5487 - accuracy: 0.8800 - val_loss: 0.9709 - val_accuracy: 0.8258\n",
            "Epoch 51/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5342 - accuracy: 0.8940 - val_loss: 0.9686 - val_accuracy: 0.8225\n",
            "Epoch 52/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5272 - accuracy: 0.8830 - val_loss: 0.9784 - val_accuracy: 0.8271\n",
            "Epoch 53/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5018 - accuracy: 0.8870 - val_loss: 0.9477 - val_accuracy: 0.8322\n",
            "Epoch 54/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4940 - accuracy: 0.8950 - val_loss: 0.9111 - val_accuracy: 0.8383\n",
            "Epoch 55/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4792 - accuracy: 0.8950 - val_loss: 0.9008 - val_accuracy: 0.8424\n",
            "Epoch 56/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4620 - accuracy: 0.9000 - val_loss: 0.8931 - val_accuracy: 0.8357\n",
            "Epoch 57/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4613 - accuracy: 0.9020 - val_loss: 0.8835 - val_accuracy: 0.8355\n",
            "Epoch 58/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4498 - accuracy: 0.9060 - val_loss: 0.8780 - val_accuracy: 0.8363\n",
            "Epoch 59/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3881 - accuracy: 0.9160 - val_loss: 0.8709 - val_accuracy: 0.8474\n",
            "Epoch 60/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4400 - accuracy: 0.9020 - val_loss: 0.8891 - val_accuracy: 0.8355\n",
            "Epoch 61/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4010 - accuracy: 0.8900 - val_loss: 0.8505 - val_accuracy: 0.8434\n",
            "Epoch 62/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3848 - accuracy: 0.9150 - val_loss: 0.8413 - val_accuracy: 0.8431\n",
            "Epoch 63/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3673 - accuracy: 0.9190 - val_loss: 0.8372 - val_accuracy: 0.8474\n",
            "Epoch 64/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3056 - accuracy: 0.9280 - val_loss: 0.8098 - val_accuracy: 0.8454\n",
            "Epoch 65/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3351 - accuracy: 0.9320 - val_loss: 0.8016 - val_accuracy: 0.8495\n",
            "Epoch 66/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3229 - accuracy: 0.9290 - val_loss: 0.8155 - val_accuracy: 0.8515\n",
            "Epoch 67/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3086 - accuracy: 0.9320 - val_loss: 0.7978 - val_accuracy: 0.8510\n",
            "Epoch 68/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2951 - accuracy: 0.9360 - val_loss: 0.7904 - val_accuracy: 0.8569\n",
            "Epoch 69/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3044 - accuracy: 0.9350 - val_loss: 0.7890 - val_accuracy: 0.8520\n",
            "Epoch 70/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2780 - accuracy: 0.9420 - val_loss: 0.7759 - val_accuracy: 0.8502\n",
            "Epoch 71/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2950 - accuracy: 0.9330 - val_loss: 0.7782 - val_accuracy: 0.8551\n",
            "Epoch 72/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2668 - accuracy: 0.9430 - val_loss: 0.7704 - val_accuracy: 0.8535\n",
            "Epoch 73/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2732 - accuracy: 0.9410 - val_loss: 0.7632 - val_accuracy: 0.8556\n",
            "Epoch 74/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2543 - accuracy: 0.9430 - val_loss: 0.7687 - val_accuracy: 0.8546\n",
            "Epoch 75/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2622 - accuracy: 0.9480 - val_loss: 0.7569 - val_accuracy: 0.8546\n",
            "Epoch 76/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2511 - accuracy: 0.9470 - val_loss: 0.7491 - val_accuracy: 0.8546\n",
            "Epoch 77/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2510 - accuracy: 0.9430 - val_loss: 0.7497 - val_accuracy: 0.8586\n",
            "Epoch 78/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2682 - accuracy: 0.9440 - val_loss: 0.7398 - val_accuracy: 0.8563\n",
            "Epoch 79/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2323 - accuracy: 0.9580 - val_loss: 0.7352 - val_accuracy: 0.8607\n",
            "Epoch 80/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2220 - accuracy: 0.9420 - val_loss: 0.7300 - val_accuracy: 0.8586\n",
            "Epoch 81/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2229 - accuracy: 0.9590 - val_loss: 0.7358 - val_accuracy: 0.8581\n",
            "Epoch 82/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2129 - accuracy: 0.9500 - val_loss: 0.7263 - val_accuracy: 0.8614\n",
            "Epoch 83/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.2267 - accuracy: 0.9490 - val_loss: 0.7180 - val_accuracy: 0.8640\n",
            "Epoch 84/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2038 - accuracy: 0.9650 - val_loss: 0.7267 - val_accuracy: 0.8599\n",
            "Epoch 85/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2081 - accuracy: 0.9490 - val_loss: 0.7243 - val_accuracy: 0.8612\n",
            "Epoch 86/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1967 - accuracy: 0.9480 - val_loss: 0.7270 - val_accuracy: 0.8596\n",
            "Epoch 87/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1900 - accuracy: 0.9470 - val_loss: 0.7125 - val_accuracy: 0.8607\n",
            "Epoch 88/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9550 - val_loss: 0.7109 - val_accuracy: 0.8632\n",
            "Epoch 89/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1706 - accuracy: 0.9610 - val_loss: 0.7066 - val_accuracy: 0.8622\n",
            "Epoch 90/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1842 - accuracy: 0.9700 - val_loss: 0.7146 - val_accuracy: 0.8614\n",
            "Epoch 91/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1839 - accuracy: 0.9540 - val_loss: 0.7085 - val_accuracy: 0.8635\n",
            "Epoch 92/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9630 - val_loss: 0.7099 - val_accuracy: 0.8627\n",
            "Epoch 93/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1670 - accuracy: 0.9640 - val_loss: 0.7014 - val_accuracy: 0.8670\n",
            "Epoch 94/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1698 - accuracy: 0.9670 - val_loss: 0.7041 - val_accuracy: 0.8658\n",
            "Epoch 95/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1720 - accuracy: 0.9630 - val_loss: 0.7005 - val_accuracy: 0.8658\n",
            "Epoch 96/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1643 - accuracy: 0.9670 - val_loss: 0.7007 - val_accuracy: 0.8670\n",
            "Epoch 97/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1537 - accuracy: 0.9740 - val_loss: 0.7022 - val_accuracy: 0.8683\n",
            "Epoch 98/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1767 - accuracy: 0.9590 - val_loss: 0.6978 - val_accuracy: 0.8691\n",
            "Epoch 99/150\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1551 - accuracy: 0.9630 - val_loss: 0.6986 - val_accuracy: 0.8619\n",
            "Epoch 100/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1620 - accuracy: 0.9660 - val_loss: 0.6955 - val_accuracy: 0.8635\n",
            "Epoch 101/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1365 - accuracy: 0.9690 - val_loss: 0.6923 - val_accuracy: 0.8632\n",
            "Epoch 102/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1366 - accuracy: 0.9700 - val_loss: 0.6907 - val_accuracy: 0.8663\n",
            "Epoch 103/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1299 - accuracy: 0.9720 - val_loss: 0.6950 - val_accuracy: 0.8663\n",
            "Epoch 104/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1488 - accuracy: 0.9620 - val_loss: 0.6906 - val_accuracy: 0.8632\n",
            "Epoch 105/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1469 - accuracy: 0.9650 - val_loss: 0.6858 - val_accuracy: 0.8688\n",
            "Epoch 106/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1326 - accuracy: 0.9730 - val_loss: 0.6868 - val_accuracy: 0.8701\n",
            "Epoch 107/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1304 - accuracy: 0.9740 - val_loss: 0.6847 - val_accuracy: 0.8701\n",
            "Epoch 108/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1193 - accuracy: 0.9760 - val_loss: 0.6776 - val_accuracy: 0.8691\n",
            "Epoch 109/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1344 - accuracy: 0.9800 - val_loss: 0.6778 - val_accuracy: 0.8658\n",
            "Epoch 110/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1367 - accuracy: 0.9710 - val_loss: 0.6728 - val_accuracy: 0.8713\n",
            "Epoch 111/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1107 - accuracy: 0.9760 - val_loss: 0.6784 - val_accuracy: 0.8703\n",
            "Epoch 112/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1162 - accuracy: 0.9790 - val_loss: 0.6854 - val_accuracy: 0.8658\n",
            "Epoch 113/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1154 - accuracy: 0.9690 - val_loss: 0.6660 - val_accuracy: 0.8696\n",
            "Epoch 114/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1128 - accuracy: 0.9750 - val_loss: 0.6628 - val_accuracy: 0.8703\n",
            "Epoch 115/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1126 - accuracy: 0.9730 - val_loss: 0.6721 - val_accuracy: 0.8701\n",
            "Epoch 116/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0996 - accuracy: 0.9830 - val_loss: 0.6749 - val_accuracy: 0.8703\n",
            "Epoch 117/150\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1084 - accuracy: 0.9730 - val_loss: 0.6707 - val_accuracy: 0.8670\n",
            "Epoch 118/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0984 - accuracy: 0.9840 - val_loss: 0.6676 - val_accuracy: 0.8701\n",
            "Epoch 119/150\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9820 - val_loss: 0.6673 - val_accuracy: 0.8716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 4/9 [01:31<01:44, 20.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.8708\n",
            "fr 0.29\n",
            "it 0.3175\n",
            "(2000, 31) (2000, 75)\n",
            "Model: \"model_95\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_56 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 29, 100)      90100       embedding_56[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 28, 100)      120100      embedding_56[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_158 (Conv1D)             (None, 27, 100)      150100      embedding_56[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_150 (MaxPooling1D (None, 1, 100)       0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_151 (MaxPooling1D (None, 1, 100)       0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_152 (MaxPooling1D (None, 1, 100)       0           conv1d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 3, 100)       0           max_pooling1d_150[0][0]          \n",
            "                                                                 max_pooling1d_151[0][0]          \n",
            "                                                                 max_pooling1d_152[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 4.5141 - accuracy: 0.0195 - val_loss: 4.0296 - val_accuracy: 0.0249\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.0949 - accuracy: 0.0410 - val_loss: 4.0304 - val_accuracy: 0.0580\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.9306 - accuracy: 0.0680 - val_loss: 3.8376 - val_accuracy: 0.1101\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.7000 - accuracy: 0.1070 - val_loss: 3.7839 - val_accuracy: 0.1782\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.4757 - accuracy: 0.1660 - val_loss: 3.4670 - val_accuracy: 0.3806\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.1548 - accuracy: 0.2065 - val_loss: 3.1816 - val_accuracy: 0.5573\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.9234 - accuracy: 0.2960 - val_loss: 3.0122 - val_accuracy: 0.5736\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.7173 - accuracy: 0.3460 - val_loss: 2.8884 - val_accuracy: 0.5406\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.4476 - accuracy: 0.3975 - val_loss: 2.4943 - val_accuracy: 0.6354\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.2358 - accuracy: 0.4880 - val_loss: 2.3432 - val_accuracy: 0.6728\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.0210 - accuracy: 0.5520 - val_loss: 2.1422 - val_accuracy: 0.6936\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.8583 - accuracy: 0.5960 - val_loss: 1.9288 - val_accuracy: 0.7010\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.7145 - accuracy: 0.6310 - val_loss: 1.8103 - val_accuracy: 0.7361\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.6307 - accuracy: 0.6670 - val_loss: 1.6918 - val_accuracy: 0.7516\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.4733 - accuracy: 0.6850 - val_loss: 1.5476 - val_accuracy: 0.7518\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.3695 - accuracy: 0.7010 - val_loss: 1.4392 - val_accuracy: 0.7554\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2668 - accuracy: 0.7275 - val_loss: 1.3214 - val_accuracy: 0.7824\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1500 - accuracy: 0.7540 - val_loss: 1.2156 - val_accuracy: 0.7867\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1234 - accuracy: 0.7700 - val_loss: 1.1475 - val_accuracy: 0.7951\n",
            "Epoch 20/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1037 - accuracy: 0.7415 - val_loss: 1.1048 - val_accuracy: 0.8040\n",
            "Epoch 21/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.9687 - accuracy: 0.7770 - val_loss: 1.0588 - val_accuracy: 0.8248\n",
            "Epoch 22/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9405 - accuracy: 0.7850 - val_loss: 0.9961 - val_accuracy: 0.8235\n",
            "Epoch 23/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.8675 - accuracy: 0.8135 - val_loss: 0.9506 - val_accuracy: 0.8197\n",
            "Epoch 24/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.8431 - accuracy: 0.8185 - val_loss: 0.9552 - val_accuracy: 0.8286\n",
            "Epoch 25/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7907 - accuracy: 0.8150 - val_loss: 0.8868 - val_accuracy: 0.8345\n",
            "Epoch 26/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7685 - accuracy: 0.8310 - val_loss: 0.8370 - val_accuracy: 0.8398\n",
            "Epoch 27/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7137 - accuracy: 0.8430 - val_loss: 0.8292 - val_accuracy: 0.8462\n",
            "Epoch 28/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6540 - accuracy: 0.8485 - val_loss: 0.7894 - val_accuracy: 0.8528\n",
            "Epoch 29/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6314 - accuracy: 0.8625 - val_loss: 0.7668 - val_accuracy: 0.8551\n",
            "Epoch 30/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6063 - accuracy: 0.8660 - val_loss: 0.7340 - val_accuracy: 0.8571\n",
            "Epoch 31/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.8660 - val_loss: 0.7287 - val_accuracy: 0.8650\n",
            "Epoch 32/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5721 - accuracy: 0.8785 - val_loss: 0.7293 - val_accuracy: 0.8642\n",
            "Epoch 33/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5305 - accuracy: 0.8745 - val_loss: 0.6930 - val_accuracy: 0.8703\n",
            "Epoch 34/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5254 - accuracy: 0.8755 - val_loss: 0.6955 - val_accuracy: 0.8752\n",
            "Epoch 35/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4850 - accuracy: 0.8845 - val_loss: 0.6562 - val_accuracy: 0.8790\n",
            "Epoch 36/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4544 - accuracy: 0.8930 - val_loss: 0.6436 - val_accuracy: 0.8780\n",
            "Epoch 37/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4475 - accuracy: 0.8965 - val_loss: 0.6410 - val_accuracy: 0.8818\n",
            "Epoch 38/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4422 - accuracy: 0.9065 - val_loss: 0.6269 - val_accuracy: 0.8805\n",
            "Epoch 39/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4042 - accuracy: 0.8965 - val_loss: 0.6130 - val_accuracy: 0.8825\n",
            "Epoch 40/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9205 - val_loss: 0.6059 - val_accuracy: 0.8869\n",
            "Epoch 41/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.9090 - val_loss: 0.5985 - val_accuracy: 0.8886\n",
            "Epoch 42/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.9115 - val_loss: 0.5856 - val_accuracy: 0.8879\n",
            "Epoch 43/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3266 - accuracy: 0.9210 - val_loss: 0.5705 - val_accuracy: 0.8886\n",
            "Epoch 44/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3496 - accuracy: 0.9145 - val_loss: 0.5891 - val_accuracy: 0.8889\n",
            "Epoch 45/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3108 - accuracy: 0.9305 - val_loss: 0.5569 - val_accuracy: 0.8904\n",
            "Epoch 46/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3095 - accuracy: 0.9270 - val_loss: 0.5580 - val_accuracy: 0.8917\n",
            "Epoch 47/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3024 - accuracy: 0.9255 - val_loss: 0.5596 - val_accuracy: 0.8881\n",
            "Epoch 48/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2821 - accuracy: 0.9330 - val_loss: 0.5482 - val_accuracy: 0.8866\n",
            "Epoch 49/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2600 - accuracy: 0.9485 - val_loss: 0.5288 - val_accuracy: 0.8937\n",
            "Epoch 50/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2804 - accuracy: 0.9325 - val_loss: 0.5247 - val_accuracy: 0.8942\n",
            "Epoch 51/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2692 - accuracy: 0.9360 - val_loss: 0.5247 - val_accuracy: 0.8945\n",
            "Epoch 52/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2443 - accuracy: 0.9460 - val_loss: 0.5242 - val_accuracy: 0.8930\n",
            "Epoch 53/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2364 - accuracy: 0.9475 - val_loss: 0.5315 - val_accuracy: 0.8991\n",
            "Epoch 54/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2341 - accuracy: 0.9445 - val_loss: 0.5238 - val_accuracy: 0.8968\n",
            "Epoch 55/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2387 - accuracy: 0.9420 - val_loss: 0.5103 - val_accuracy: 0.8998\n",
            "Epoch 56/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2242 - accuracy: 0.9465 - val_loss: 0.5036 - val_accuracy: 0.8983\n",
            "Epoch 57/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2108 - accuracy: 0.9505 - val_loss: 0.5014 - val_accuracy: 0.8983\n",
            "Epoch 58/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2110 - accuracy: 0.9530 - val_loss: 0.5068 - val_accuracy: 0.8996\n",
            "Epoch 59/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1931 - accuracy: 0.9600 - val_loss: 0.5053 - val_accuracy: 0.8968\n",
            "Epoch 60/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1910 - accuracy: 0.9590 - val_loss: 0.4940 - val_accuracy: 0.9006\n",
            "Epoch 61/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1733 - accuracy: 0.9580 - val_loss: 0.4994 - val_accuracy: 0.8996\n",
            "Epoch 62/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1879 - accuracy: 0.9560 - val_loss: 0.4972 - val_accuracy: 0.8991\n",
            "Epoch 63/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1643 - accuracy: 0.9610 - val_loss: 0.4932 - val_accuracy: 0.9003\n",
            "Epoch 64/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1704 - accuracy: 0.9625 - val_loss: 0.4799 - val_accuracy: 0.9036\n",
            "Epoch 65/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1634 - accuracy: 0.9605 - val_loss: 0.4808 - val_accuracy: 0.9047\n",
            "Epoch 66/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1610 - accuracy: 0.9615 - val_loss: 0.4840 - val_accuracy: 0.9031\n",
            "Epoch 67/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1593 - accuracy: 0.9625 - val_loss: 0.4793 - val_accuracy: 0.9041\n",
            "Epoch 68/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1586 - accuracy: 0.9620 - val_loss: 0.4816 - val_accuracy: 0.9057\n",
            "Epoch 69/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1421 - accuracy: 0.9700 - val_loss: 0.4698 - val_accuracy: 0.9059\n",
            "Epoch 70/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1462 - accuracy: 0.9645 - val_loss: 0.4756 - val_accuracy: 0.9054\n",
            "Epoch 71/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1324 - accuracy: 0.9655 - val_loss: 0.4657 - val_accuracy: 0.9092\n",
            "Epoch 72/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1223 - accuracy: 0.9670 - val_loss: 0.4661 - val_accuracy: 0.9097\n",
            "Epoch 73/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1313 - accuracy: 0.9665 - val_loss: 0.4618 - val_accuracy: 0.9090\n",
            "Epoch 74/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1227 - accuracy: 0.9710 - val_loss: 0.4644 - val_accuracy: 0.9077\n",
            "Epoch 75/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1276 - accuracy: 0.9680 - val_loss: 0.4635 - val_accuracy: 0.9100\n",
            "Epoch 76/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1110 - accuracy: 0.9775 - val_loss: 0.4652 - val_accuracy: 0.9077\n",
            "Epoch 77/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1248 - accuracy: 0.9680 - val_loss: 0.4611 - val_accuracy: 0.9102\n",
            "Epoch 78/150\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1082 - accuracy: 0.9750 - val_loss: 0.4548 - val_accuracy: 0.9080\n",
            "Epoch 79/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1139 - accuracy: 0.9720 - val_loss: 0.4688 - val_accuracy: 0.9105\n",
            "Epoch 80/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1058 - accuracy: 0.9745 - val_loss: 0.4618 - val_accuracy: 0.9113\n",
            "Epoch 81/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9795 - val_loss: 0.4595 - val_accuracy: 0.9077\n",
            "Epoch 82/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0961 - accuracy: 0.9785 - val_loss: 0.4552 - val_accuracy: 0.9105\n",
            "Epoch 83/150\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0946 - accuracy: 0.9715 - val_loss: 0.4570 - val_accuracy: 0.9082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 5/9 [02:01<01:34, 23.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9108\n",
            "fr 0.2795\n",
            "it 0.2986\n",
            "(5000, 31) (5000, 75)\n",
            "Model: \"model_96\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_57 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_159 (Conv1D)             (None, 29, 100)      90100       embedding_57[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_160 (Conv1D)             (None, 28, 100)      120100      embedding_57[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_161 (Conv1D)             (None, 27, 100)      150100      embedding_57[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_153 (MaxPooling1D (None, 1, 100)       0           conv1d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_154 (MaxPooling1D (None, 1, 100)       0           conv1d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_155 (MaxPooling1D (None, 1, 100)       0           conv1d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 3, 100)       0           max_pooling1d_153[0][0]          \n",
            "                                                                 max_pooling1d_154[0][0]          \n",
            "                                                                 max_pooling1d_155[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 4.3540 - accuracy: 0.0382 - val_loss: 3.9127 - val_accuracy: 0.0918\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 3.8137 - accuracy: 0.1266 - val_loss: 3.5182 - val_accuracy: 0.3501\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 3.2294 - accuracy: 0.2998 - val_loss: 2.9466 - val_accuracy: 0.5932\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 2.6839 - accuracy: 0.4452 - val_loss: 2.3362 - val_accuracy: 0.6718\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 2.2081 - accuracy: 0.5546 - val_loss: 1.8893 - val_accuracy: 0.7419\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.8904 - accuracy: 0.6342 - val_loss: 1.5780 - val_accuracy: 0.7640\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.5966 - accuracy: 0.6784 - val_loss: 1.2304 - val_accuracy: 0.7963\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.3979 - accuracy: 0.7102 - val_loss: 1.1076 - val_accuracy: 0.8131\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.2434 - accuracy: 0.7574 - val_loss: 0.9982 - val_accuracy: 0.8286\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.1032 - accuracy: 0.7732 - val_loss: 0.9060 - val_accuracy: 0.8446\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.0116 - accuracy: 0.7910 - val_loss: 0.8343 - val_accuracy: 0.8599\n",
            "Epoch 12/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.8784 - accuracy: 0.8084 - val_loss: 0.7481 - val_accuracy: 0.8619\n",
            "Epoch 13/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.8217 - accuracy: 0.8212 - val_loss: 0.6777 - val_accuracy: 0.8749\n",
            "Epoch 14/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.7266 - accuracy: 0.8510 - val_loss: 0.6279 - val_accuracy: 0.8846\n",
            "Epoch 15/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6941 - accuracy: 0.8514 - val_loss: 0.6000 - val_accuracy: 0.8881\n",
            "Epoch 16/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6661 - accuracy: 0.8544 - val_loss: 0.5506 - val_accuracy: 0.8924\n",
            "Epoch 17/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6002 - accuracy: 0.8664 - val_loss: 0.5361 - val_accuracy: 0.8917\n",
            "Epoch 18/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5485 - accuracy: 0.8758 - val_loss: 0.5009 - val_accuracy: 0.9006\n",
            "Epoch 19/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4977 - accuracy: 0.8888 - val_loss: 0.4828 - val_accuracy: 0.9031\n",
            "Epoch 20/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.8946 - val_loss: 0.4598 - val_accuracy: 0.9102\n",
            "Epoch 21/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.8956 - val_loss: 0.4333 - val_accuracy: 0.9176\n",
            "Epoch 22/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.9004 - val_loss: 0.4360 - val_accuracy: 0.9161\n",
            "Epoch 23/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3889 - accuracy: 0.9132 - val_loss: 0.4198 - val_accuracy: 0.9133\n",
            "Epoch 24/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3644 - accuracy: 0.9132 - val_loss: 0.3994 - val_accuracy: 0.9197\n",
            "Epoch 25/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3569 - accuracy: 0.9204 - val_loss: 0.3962 - val_accuracy: 0.9148\n",
            "Epoch 26/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3353 - accuracy: 0.9222 - val_loss: 0.3821 - val_accuracy: 0.9199\n",
            "Epoch 27/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3189 - accuracy: 0.9274 - val_loss: 0.3657 - val_accuracy: 0.9242\n",
            "Epoch 28/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2862 - accuracy: 0.9348 - val_loss: 0.3558 - val_accuracy: 0.9273\n",
            "Epoch 29/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2818 - accuracy: 0.9360 - val_loss: 0.3546 - val_accuracy: 0.9258\n",
            "Epoch 30/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2623 - accuracy: 0.9410 - val_loss: 0.3519 - val_accuracy: 0.9270\n",
            "Epoch 31/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2577 - accuracy: 0.9424 - val_loss: 0.3366 - val_accuracy: 0.9314\n",
            "Epoch 32/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2301 - accuracy: 0.9418 - val_loss: 0.3378 - val_accuracy: 0.9280\n",
            "Epoch 33/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2237 - accuracy: 0.9462 - val_loss: 0.3308 - val_accuracy: 0.9296\n",
            "Epoch 34/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2180 - accuracy: 0.9466 - val_loss: 0.3168 - val_accuracy: 0.9336\n",
            "Epoch 35/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2027 - accuracy: 0.9496 - val_loss: 0.3163 - val_accuracy: 0.9331\n",
            "Epoch 36/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.9514 - val_loss: 0.3134 - val_accuracy: 0.9336\n",
            "Epoch 37/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1874 - accuracy: 0.9494 - val_loss: 0.3159 - val_accuracy: 0.9308\n",
            "Epoch 38/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1793 - accuracy: 0.9508 - val_loss: 0.3068 - val_accuracy: 0.9344\n",
            "Epoch 39/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1752 - accuracy: 0.9546 - val_loss: 0.3048 - val_accuracy: 0.9324\n",
            "Epoch 40/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1720 - accuracy: 0.9568 - val_loss: 0.3020 - val_accuracy: 0.9347\n",
            "Epoch 41/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1554 - accuracy: 0.9626 - val_loss: 0.2971 - val_accuracy: 0.9372\n",
            "Epoch 42/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.9622 - val_loss: 0.2973 - val_accuracy: 0.9369\n",
            "Epoch 43/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1450 - accuracy: 0.9656 - val_loss: 0.2939 - val_accuracy: 0.9359\n",
            "Epoch 44/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.9662 - val_loss: 0.2953 - val_accuracy: 0.9397\n",
            "Epoch 45/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1368 - accuracy: 0.9630 - val_loss: 0.2881 - val_accuracy: 0.9382\n",
            "Epoch 46/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1429 - accuracy: 0.9618 - val_loss: 0.2978 - val_accuracy: 0.9354\n",
            "Epoch 47/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1232 - accuracy: 0.9654 - val_loss: 0.2848 - val_accuracy: 0.9397\n",
            "Epoch 48/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1203 - accuracy: 0.9720 - val_loss: 0.2868 - val_accuracy: 0.9380\n",
            "Epoch 49/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1238 - accuracy: 0.9658 - val_loss: 0.2848 - val_accuracy: 0.9413\n",
            "Epoch 50/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9734 - val_loss: 0.2869 - val_accuracy: 0.9385\n",
            "Epoch 51/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1131 - accuracy: 0.9712 - val_loss: 0.2831 - val_accuracy: 0.9405\n",
            "Epoch 52/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1020 - accuracy: 0.9692 - val_loss: 0.2849 - val_accuracy: 0.9387\n",
            "Epoch 53/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1076 - accuracy: 0.9728 - val_loss: 0.2797 - val_accuracy: 0.9395\n",
            "Epoch 54/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9740 - val_loss: 0.2747 - val_accuracy: 0.9423\n",
            "Epoch 55/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0944 - accuracy: 0.9724 - val_loss: 0.2811 - val_accuracy: 0.9390\n",
            "Epoch 56/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0909 - accuracy: 0.9746 - val_loss: 0.2789 - val_accuracy: 0.9413\n",
            "Epoch 57/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0854 - accuracy: 0.9760 - val_loss: 0.2798 - val_accuracy: 0.9423\n",
            "Epoch 58/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0892 - accuracy: 0.9752 - val_loss: 0.2767 - val_accuracy: 0.9438\n",
            "Epoch 59/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0883 - accuracy: 0.9798 - val_loss: 0.2776 - val_accuracy: 0.9402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 6/9 [02:36<01:20, 26.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9413\n",
            "fr 0.2977\n",
            "it 0.3152\n",
            "(10000, 31) (10000, 75)\n",
            "Model: \"model_97\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_58 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_162 (Conv1D)             (None, 29, 100)      90100       embedding_58[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_163 (Conv1D)             (None, 28, 100)      120100      embedding_58[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_164 (Conv1D)             (None, 27, 100)      150100      embedding_58[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_156 (MaxPooling1D (None, 1, 100)       0           conv1d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_157 (MaxPooling1D (None, 1, 100)       0           conv1d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_158 (MaxPooling1D (None, 1, 100)       0           conv1d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 3, 100)       0           max_pooling1d_156[0][0]          \n",
            "                                                                 max_pooling1d_157[0][0]          \n",
            "                                                                 max_pooling1d_158[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 4.2847 - accuracy: 0.0631 - val_loss: 3.6924 - val_accuracy: 0.2014\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 3.2955 - accuracy: 0.3023 - val_loss: 2.5829 - val_accuracy: 0.6260\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 2.3895 - accuracy: 0.5499 - val_loss: 1.7622 - val_accuracy: 0.7396\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 1.8081 - accuracy: 0.6502 - val_loss: 1.2810 - val_accuracy: 0.7879\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 1.4468 - accuracy: 0.7058 - val_loss: 1.0024 - val_accuracy: 0.8220\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 1.1730 - accuracy: 0.7598 - val_loss: 0.8272 - val_accuracy: 0.8416\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.9577 - accuracy: 0.7989 - val_loss: 0.7166 - val_accuracy: 0.8566\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.8569 - accuracy: 0.8254 - val_loss: 0.6358 - val_accuracy: 0.8759\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.7237 - accuracy: 0.8450 - val_loss: 0.5694 - val_accuracy: 0.8853\n",
            "Epoch 10/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.6617 - accuracy: 0.8572 - val_loss: 0.5530 - val_accuracy: 0.8950\n",
            "Epoch 11/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.5903 - accuracy: 0.8714 - val_loss: 0.4551 - val_accuracy: 0.9062\n",
            "Epoch 12/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.5195 - accuracy: 0.8879 - val_loss: 0.4283 - val_accuracy: 0.9102\n",
            "Epoch 13/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4723 - accuracy: 0.8963 - val_loss: 0.4018 - val_accuracy: 0.9156\n",
            "Epoch 14/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4433 - accuracy: 0.8993 - val_loss: 0.3967 - val_accuracy: 0.9161\n",
            "Epoch 15/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4073 - accuracy: 0.9067 - val_loss: 0.3731 - val_accuracy: 0.9156\n",
            "Epoch 16/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3748 - accuracy: 0.9130 - val_loss: 0.3628 - val_accuracy: 0.9232\n",
            "Epoch 17/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3389 - accuracy: 0.9210 - val_loss: 0.3289 - val_accuracy: 0.9286\n",
            "Epoch 18/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3358 - accuracy: 0.9236 - val_loss: 0.3228 - val_accuracy: 0.9298\n",
            "Epoch 19/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3006 - accuracy: 0.9262 - val_loss: 0.3151 - val_accuracy: 0.9293\n",
            "Epoch 20/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.2714 - accuracy: 0.9378 - val_loss: 0.2932 - val_accuracy: 0.9352\n",
            "Epoch 21/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.2507 - accuracy: 0.9431 - val_loss: 0.2912 - val_accuracy: 0.9354\n",
            "Epoch 22/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9427 - val_loss: 0.2821 - val_accuracy: 0.9364\n",
            "Epoch 23/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.2209 - accuracy: 0.9442 - val_loss: 0.2800 - val_accuracy: 0.9380\n",
            "Epoch 24/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.2080 - accuracy: 0.9475 - val_loss: 0.2636 - val_accuracy: 0.9418\n",
            "Epoch 25/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1913 - accuracy: 0.9513 - val_loss: 0.2614 - val_accuracy: 0.9428\n",
            "Epoch 26/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1714 - accuracy: 0.9547 - val_loss: 0.2758 - val_accuracy: 0.9369\n",
            "Epoch 27/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.9551 - val_loss: 0.2543 - val_accuracy: 0.9428\n",
            "Epoch 28/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9608 - val_loss: 0.2522 - val_accuracy: 0.9428\n",
            "Epoch 29/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1593 - accuracy: 0.9584 - val_loss: 0.2485 - val_accuracy: 0.9420\n",
            "Epoch 30/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1508 - accuracy: 0.9616 - val_loss: 0.2434 - val_accuracy: 0.9461\n",
            "Epoch 31/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9631 - val_loss: 0.2410 - val_accuracy: 0.9464\n",
            "Epoch 32/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1304 - accuracy: 0.9653 - val_loss: 0.2398 - val_accuracy: 0.9441\n",
            "Epoch 33/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1222 - accuracy: 0.9652 - val_loss: 0.2321 - val_accuracy: 0.9486\n",
            "Epoch 34/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9699 - val_loss: 0.2301 - val_accuracy: 0.9486\n",
            "Epoch 35/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1147 - accuracy: 0.9698 - val_loss: 0.2268 - val_accuracy: 0.9502\n",
            "Epoch 36/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9753 - val_loss: 0.2244 - val_accuracy: 0.9471\n",
            "Epoch 37/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1044 - accuracy: 0.9735 - val_loss: 0.2259 - val_accuracy: 0.9471\n",
            "Epoch 38/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.1049 - accuracy: 0.9731 - val_loss: 0.2246 - val_accuracy: 0.9494\n",
            "Epoch 39/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0989 - accuracy: 0.9749 - val_loss: 0.2267 - val_accuracy: 0.9479\n",
            "Epoch 40/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 0.2252 - val_accuracy: 0.9509\n",
            "Epoch 41/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0850 - accuracy: 0.9770 - val_loss: 0.2178 - val_accuracy: 0.9499\n",
            "Epoch 42/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0798 - accuracy: 0.9779 - val_loss: 0.2230 - val_accuracy: 0.9504\n",
            "Epoch 43/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9781 - val_loss: 0.2156 - val_accuracy: 0.9507\n",
            "Epoch 44/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0762 - accuracy: 0.9791 - val_loss: 0.2190 - val_accuracy: 0.9507\n",
            "Epoch 45/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0772 - accuracy: 0.9772 - val_loss: 0.2151 - val_accuracy: 0.9519\n",
            "Epoch 46/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 0.2203 - val_accuracy: 0.9527\n",
            "Epoch 47/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.2154 - val_accuracy: 0.9542\n",
            "Epoch 48/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0618 - accuracy: 0.9839 - val_loss: 0.2178 - val_accuracy: 0.9535\n",
            "Epoch 49/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0621 - accuracy: 0.9830 - val_loss: 0.2166 - val_accuracy: 0.9553\n",
            "Epoch 50/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 0.9829 - val_loss: 0.2222 - val_accuracy: 0.9522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 7/9 [03:22<01:05, 32.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9525\n",
            "fr 0.3296\n",
            "it 0.3341\n",
            "(15000, 31) (15000, 75)\n",
            "Model: \"model_98\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_59 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_165 (Conv1D)             (None, 29, 100)      90100       embedding_59[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_166 (Conv1D)             (None, 28, 100)      120100      embedding_59[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_167 (Conv1D)             (None, 27, 100)      150100      embedding_59[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_159 (MaxPooling1D (None, 1, 100)       0           conv1d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_160 (MaxPooling1D (None, 1, 100)       0           conv1d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_161 (MaxPooling1D (None, 1, 100)       0           conv1d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 3, 100)       0           max_pooling1d_159[0][0]          \n",
            "                                                                 max_pooling1d_160[0][0]          \n",
            "                                                                 max_pooling1d_161[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.8638 - accuracy: 0.1412 - val_loss: 3.0670 - val_accuracy: 0.5517\n",
            "Epoch 2/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4242 - accuracy: 0.5309 - val_loss: 1.6021 - val_accuracy: 0.7780\n",
            "Epoch 3/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.6205 - accuracy: 0.6977 - val_loss: 1.0526 - val_accuracy: 0.8340\n",
            "Epoch 4/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1686 - accuracy: 0.7726 - val_loss: 0.7576 - val_accuracy: 0.8660\n",
            "Epoch 5/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.9100 - accuracy: 0.8175 - val_loss: 0.6190 - val_accuracy: 0.8805\n",
            "Epoch 6/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.7420 - accuracy: 0.8471 - val_loss: 0.5019 - val_accuracy: 0.8937\n",
            "Epoch 7/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.6481 - accuracy: 0.8643 - val_loss: 0.4558 - val_accuracy: 0.9080\n",
            "Epoch 8/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.5354 - accuracy: 0.8859 - val_loss: 0.4001 - val_accuracy: 0.9181\n",
            "Epoch 9/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8969 - val_loss: 0.3603 - val_accuracy: 0.9273\n",
            "Epoch 10/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.9071 - val_loss: 0.3348 - val_accuracy: 0.9242\n",
            "Epoch 11/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3844 - accuracy: 0.9179 - val_loss: 0.3152 - val_accuracy: 0.9303\n",
            "Epoch 12/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.9205 - val_loss: 0.2863 - val_accuracy: 0.9392\n",
            "Epoch 13/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3082 - accuracy: 0.9321 - val_loss: 0.2897 - val_accuracy: 0.9326\n",
            "Epoch 14/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2827 - accuracy: 0.9355 - val_loss: 0.2573 - val_accuracy: 0.9425\n",
            "Epoch 15/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2648 - accuracy: 0.9381 - val_loss: 0.2542 - val_accuracy: 0.9441\n",
            "Epoch 16/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9463 - val_loss: 0.2492 - val_accuracy: 0.9430\n",
            "Epoch 17/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9465 - val_loss: 0.2347 - val_accuracy: 0.9451\n",
            "Epoch 18/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2005 - accuracy: 0.9542 - val_loss: 0.2286 - val_accuracy: 0.9448\n",
            "Epoch 19/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1898 - accuracy: 0.9541 - val_loss: 0.2295 - val_accuracy: 0.9486\n",
            "Epoch 20/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9590 - val_loss: 0.2240 - val_accuracy: 0.9489\n",
            "Epoch 21/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9589 - val_loss: 0.2141 - val_accuracy: 0.9479\n",
            "Epoch 22/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1456 - accuracy: 0.9626 - val_loss: 0.2113 - val_accuracy: 0.9502\n",
            "Epoch 23/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1421 - accuracy: 0.9639 - val_loss: 0.2213 - val_accuracy: 0.9491\n",
            "Epoch 24/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1325 - accuracy: 0.9645 - val_loss: 0.2040 - val_accuracy: 0.9504\n",
            "Epoch 25/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9715 - val_loss: 0.1987 - val_accuracy: 0.9542\n",
            "Epoch 26/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.9693 - val_loss: 0.1980 - val_accuracy: 0.9542\n",
            "Epoch 27/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1140 - accuracy: 0.9715 - val_loss: 0.2027 - val_accuracy: 0.9542\n",
            "Epoch 28/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1039 - accuracy: 0.9730 - val_loss: 0.1940 - val_accuracy: 0.9550\n",
            "Epoch 29/150\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9765 - val_loss: 0.1948 - val_accuracy: 0.9553\n",
            "Epoch 30/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9763 - val_loss: 0.2034 - val_accuracy: 0.9560\n",
            "Epoch 31/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9761 - val_loss: 0.2021 - val_accuracy: 0.9547\n",
            "Epoch 32/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9783 - val_loss: 0.1956 - val_accuracy: 0.9550\n",
            "Epoch 33/150\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0850 - accuracy: 0.9772 - val_loss: 0.1960 - val_accuracy: 0.9540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 8/9 [04:06<00:36, 36.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9578\n",
            "fr 0.2879\n",
            "it 0.3483\n",
            "(25000, 31) (25000, 75)\n",
            "Model: \"model_99\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_60 (Embedding)        (None, 31, 300)      6760200     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_168 (Conv1D)             (None, 29, 100)      90100       embedding_60[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_169 (Conv1D)             (None, 28, 100)      120100      embedding_60[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_170 (Conv1D)             (None, 27, 100)      150100      embedding_60[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_162 (MaxPooling1D (None, 1, 100)       0           conv1d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_163 (MaxPooling1D (None, 1, 100)       0           conv1d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_164 (MaxPooling1D (None, 1, 100)       0           conv1d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 3, 100)       0           max_pooling1d_162[0][0]          \n",
            "                                                                 max_pooling1d_163[0][0]          \n",
            "                                                                 max_pooling1d_164[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,143,075\n",
            "Trainable params: 382,875\n",
            "Non-trainable params: 6,760,200\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 3.3536 - accuracy: 0.2888 - val_loss: 1.9992 - val_accuracy: 0.7508\n",
            "Epoch 2/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6390 - accuracy: 0.6919 - val_loss: 0.8803 - val_accuracy: 0.8457\n",
            "Epoch 3/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0313 - accuracy: 0.7916 - val_loss: 0.6204 - val_accuracy: 0.8835\n",
            "Epoch 4/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.7529 - accuracy: 0.8460 - val_loss: 0.4856 - val_accuracy: 0.9057\n",
            "Epoch 5/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.8778 - val_loss: 0.4007 - val_accuracy: 0.9163\n",
            "Epoch 6/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4824 - accuracy: 0.8968 - val_loss: 0.3359 - val_accuracy: 0.9291\n",
            "Epoch 7/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4098 - accuracy: 0.9119 - val_loss: 0.3078 - val_accuracy: 0.9308\n",
            "Epoch 8/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3467 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9387\n",
            "Epoch 9/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3010 - accuracy: 0.9346 - val_loss: 0.2487 - val_accuracy: 0.9438\n",
            "Epoch 10/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2719 - accuracy: 0.9382 - val_loss: 0.2285 - val_accuracy: 0.9479\n",
            "Epoch 11/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2382 - accuracy: 0.9441 - val_loss: 0.2206 - val_accuracy: 0.9466\n",
            "Epoch 12/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2175 - accuracy: 0.9484 - val_loss: 0.2053 - val_accuracy: 0.9486\n",
            "Epoch 13/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1935 - accuracy: 0.9538 - val_loss: 0.2026 - val_accuracy: 0.9499\n",
            "Epoch 14/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1737 - accuracy: 0.9568 - val_loss: 0.1942 - val_accuracy: 0.9519\n",
            "Epoch 15/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1616 - accuracy: 0.9596 - val_loss: 0.1864 - val_accuracy: 0.9550\n",
            "Epoch 16/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1484 - accuracy: 0.9636 - val_loss: 0.1815 - val_accuracy: 0.9563\n",
            "Epoch 17/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1297 - accuracy: 0.9658 - val_loss: 0.1768 - val_accuracy: 0.9570\n",
            "Epoch 18/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1230 - accuracy: 0.9682 - val_loss: 0.1748 - val_accuracy: 0.9555\n",
            "Epoch 19/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1176 - accuracy: 0.9692 - val_loss: 0.1699 - val_accuracy: 0.9588\n",
            "Epoch 20/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9707 - val_loss: 0.1678 - val_accuracy: 0.9575\n",
            "Epoch 21/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0990 - accuracy: 0.9731 - val_loss: 0.1626 - val_accuracy: 0.9591\n",
            "Epoch 22/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0913 - accuracy: 0.9752 - val_loss: 0.1682 - val_accuracy: 0.9603\n",
            "Epoch 23/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 0.1639 - val_accuracy: 0.9588\n",
            "Epoch 24/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.1684 - val_accuracy: 0.9560\n",
            "Epoch 25/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0788 - accuracy: 0.9779 - val_loss: 0.1680 - val_accuracy: 0.9588\n",
            "Epoch 26/150\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.0741 - accuracy: 0.9793 - val_loss: 0.1684 - val_accuracy: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [04:58<00:00, 33.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.958\n",
            "fr 0.2718\n",
            "it 0.3246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN1D_WOET</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6481</td>\n",
              "      <td>0.7714</td>\n",
              "      <td>0.8708</td>\n",
              "      <td>0.9108</td>\n",
              "      <td>0.9413</td>\n",
              "      <td>0.9525</td>\n",
              "      <td>0.9578</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN1D_WOET</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5542</td>\n",
              "      <td>0.6733</td>\n",
              "      <td>0.7967</td>\n",
              "      <td>0.8576</td>\n",
              "      <td>0.8931</td>\n",
              "      <td>0.9174</td>\n",
              "      <td>0.9127</td>\n",
              "      <td>0.9152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        model    task      metric    0  ...    5000   10000   15000   25000\n",
              "2  CNN1D_WOET  slc_de    accuracy  NaN  ...  0.9413  0.9525  0.9578   0.958\n",
              "3  CNN1D_WOET  slc_de  avg_recall  NaN  ...  0.8931  0.9174  0.9127  0.9152\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAWPBcxANbCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_CNN(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= 0.7\n",
        "    filter_sizes =  [2,3,5]\n",
        "    num_filters = 100\n",
        "    lr = .0005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "        maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    #dense_layer = Dense(150,activation='relu')(falt_layer)\n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(X_train_emb[idx,:].shape, y_train_enc[idx,:].shape)\n",
        "    print(de_cnn1d.summary())\n",
        "    hist = de_cnn1d.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "\n",
        "    y_pred_test = pred_encode(de_cnn1d,X_test_emb)\n",
        "\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "    all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFXqJ_rYNd07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b29514b-2900-4494-b569-8607f4562a5f"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'CNN1D_345'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "obs =25000\n",
        "run_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 31) (25000, 75)\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_41 (Embedding)        (None, 31, 300)      6846300     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_95 (Conv1D)              (None, 29, 70)       63070       embedding_41[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_96 (Conv1D)              (None, 28, 70)       84070       embedding_41[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_97 (Conv1D)              (None, 27, 70)       105070      embedding_41[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_94 (MaxPooling1D) (None, 1, 70)        0           conv1d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_95 (MaxPooling1D) (None, 1, 70)        0           conv1d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_96 (MaxPooling1D) (None, 1, 70)        0           conv1d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 3, 70)        0           max_pooling1d_94[0][0]           \n",
            "                                                                 max_pooling1d_95[0][0]           \n",
            "                                                                 max_pooling1d_96[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 210)          0           concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 210)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           15825       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,114,335\n",
            "Trainable params: 7,114,335\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 4.1483 - accuracy: 0.1111 - val_loss: 3.6762 - val_accuracy: 0.6209\n",
            "Epoch 2/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 3.4753 - accuracy: 0.4240 - val_loss: 2.3910 - val_accuracy: 0.7790\n",
            "Epoch 3/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 2.5674 - accuracy: 0.6387 - val_loss: 1.3312 - val_accuracy: 0.8426\n",
            "Epoch 4/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.7937 - accuracy: 0.7424 - val_loss: 0.8135 - val_accuracy: 0.8853\n",
            "Epoch 5/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.2938 - accuracy: 0.8066 - val_loss: 0.5616 - val_accuracy: 0.9057\n",
            "Epoch 6/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.0019 - accuracy: 0.8509 - val_loss: 0.4386 - val_accuracy: 0.9156\n",
            "Epoch 7/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.7927 - accuracy: 0.8838 - val_loss: 0.3595 - val_accuracy: 0.9252\n",
            "Epoch 8/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.6464 - accuracy: 0.9049 - val_loss: 0.3045 - val_accuracy: 0.9354\n",
            "Epoch 9/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.5328 - accuracy: 0.9228 - val_loss: 0.2726 - val_accuracy: 0.9425\n",
            "Epoch 10/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.4561 - accuracy: 0.9323 - val_loss: 0.2452 - val_accuracy: 0.9484\n",
            "Epoch 11/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.3994 - accuracy: 0.9412 - val_loss: 0.2237 - val_accuracy: 0.9537\n",
            "Epoch 12/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.3258 - accuracy: 0.9521 - val_loss: 0.2064 - val_accuracy: 0.9555\n",
            "Epoch 13/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.2849 - accuracy: 0.9600 - val_loss: 0.1906 - val_accuracy: 0.9575\n",
            "Epoch 14/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.2507 - accuracy: 0.9636 - val_loss: 0.1822 - val_accuracy: 0.9603\n",
            "Epoch 15/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.2253 - accuracy: 0.9681 - val_loss: 0.1721 - val_accuracy: 0.9621\n",
            "Epoch 16/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.2038 - accuracy: 0.9709 - val_loss: 0.1664 - val_accuracy: 0.9626\n",
            "Epoch 17/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.1765 - accuracy: 0.9740 - val_loss: 0.1587 - val_accuracy: 0.9647\n",
            "Epoch 18/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.1568 - accuracy: 0.9767 - val_loss: 0.1529 - val_accuracy: 0.9654\n",
            "Epoch 19/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.1409 - accuracy: 0.9792 - val_loss: 0.1455 - val_accuracy: 0.9657\n",
            "Epoch 20/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.1274 - accuracy: 0.9807 - val_loss: 0.1458 - val_accuracy: 0.9659\n",
            "Epoch 21/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.1220 - accuracy: 0.9812 - val_loss: 0.1412 - val_accuracy: 0.9664\n",
            "Epoch 22/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.1007 - accuracy: 0.9840 - val_loss: 0.1381 - val_accuracy: 0.9662\n",
            "Epoch 23/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0941 - accuracy: 0.9849 - val_loss: 0.1372 - val_accuracy: 0.9680\n",
            "Epoch 24/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.0864 - accuracy: 0.9863 - val_loss: 0.1336 - val_accuracy: 0.9690\n",
            "Epoch 25/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0817 - accuracy: 0.9869 - val_loss: 0.1334 - val_accuracy: 0.9690\n",
            "Epoch 26/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0717 - accuracy: 0.9882 - val_loss: 0.1315 - val_accuracy: 0.9690\n",
            "Epoch 27/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0690 - accuracy: 0.9877 - val_loss: 0.1306 - val_accuracy: 0.9708\n",
            "Epoch 28/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0624 - accuracy: 0.9891 - val_loss: 0.1301 - val_accuracy: 0.9710\n",
            "Epoch 29/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0595 - accuracy: 0.9902 - val_loss: 0.1301 - val_accuracy: 0.9725\n",
            "Epoch 30/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.0513 - accuracy: 0.9913 - val_loss: 0.1300 - val_accuracy: 0.9705\n",
            "Epoch 31/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.0506 - accuracy: 0.9909 - val_loss: 0.1290 - val_accuracy: 0.9720\n",
            "Epoch 32/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0455 - accuracy: 0.9919 - val_loss: 0.1261 - val_accuracy: 0.9713\n",
            "Epoch 33/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0420 - accuracy: 0.9928 - val_loss: 0.1242 - val_accuracy: 0.9725\n",
            "Epoch 34/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0436 - accuracy: 0.9924 - val_loss: 0.1276 - val_accuracy: 0.9718\n",
            "Epoch 35/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.0359 - accuracy: 0.9934 - val_loss: 0.1284 - val_accuracy: 0.9730\n",
            "Epoch 36/150\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0347 - accuracy: 0.9929 - val_loss: 0.1282 - val_accuracy: 0.9741\n",
            "Epoch 37/150\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 0.0348 - accuracy: 0.9939 - val_loss: 0.1292 - val_accuracy: 0.9736\n",
            "Epoch 38/150\n",
            "391/391 [==============================] - 15s 37ms/step - loss: 0.0307 - accuracy: 0.9942 - val_loss: 0.1291 - val_accuracy: 0.9728\n",
            "\n",
            "de 0.9692\n",
            "fr 0.3891\n",
            "it 0.2506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CNN1D_345</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1876</td>\n",
              "      <td>0.6959</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.8515</td>\n",
              "      <td>0.9085</td>\n",
              "      <td>0.9255</td>\n",
              "      <td>0.9484</td>\n",
              "      <td>0.9634</td>\n",
              "      <td>0.9692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNN1D_345</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4487</td>\n",
              "      <td>0.6129</td>\n",
              "      <td>0.6651</td>\n",
              "      <td>0.7404</td>\n",
              "      <td>0.8057</td>\n",
              "      <td>0.8225</td>\n",
              "      <td>0.8888</td>\n",
              "      <td>0.9157</td>\n",
              "      <td>0.9231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model    task      metric    0  ...    5000   10000   15000   25000\n",
              "8  CNN1D_345  slc_de    accuracy  NaN  ...  0.9255  0.9484  0.9634  0.9692\n",
              "9  CNN1D_345  slc_de  avg_recall  NaN  ...  0.8225  0.8888  0.9157  0.9231\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxDU8K4-pXUP",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJpAAQgIqVkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_RNN(X_train_emb,y_train_enc,X_val_emb,y_val_enc,X_test_emb,y_test,class_weight_dict,no):\n",
        "    \n",
        "    dropout_rate= .2\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb), size=no)\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "    lstm_layer = Bidirectional(LSTM(256,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(embedd_seq)\n",
        "    drop_layer = Dropout(dropout_rate)(lstm_layer)\n",
        "\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_rnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    de_rnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = de_rnn.fit(x = X_train_emb[idx,:], y = y_train_enc[idx,:],\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 100, batch_size = 64, shuffle = True, class_weight = class_weight_dict,  \\\n",
        "                    callbacks = [early_stopping])\n",
        "    #verbose =0,\n",
        "    y_pred_test = pred_encode(de_rnn,X_test_emb)\n",
        "\n",
        "    fill_df_res(y_pred_test,y_test,no)\n",
        "    all_tests(de_rnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSRAT0vAo7s-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbefc4a2-b819-40c1-b461-7169d8e9cdbd"
      },
      "source": [
        "task = 'slc_de'\n",
        "model = 'RNN'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000,25000]):\n",
        "     #run_RNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_RNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,class_weight_dict_de,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 445ms/step - loss: 3.8426 - accuracy: 0.0100 - val_loss: 4.7085 - val_accuracy: 0.0036\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.4206 - accuracy: 0.0100 - val_loss: 4.3288 - val_accuracy: 0.0056\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 180ms/step - loss: 3.0390 - accuracy: 0.0200 - val_loss: 4.4322 - val_accuracy: 0.0086\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 2.8171 - accuracy: 0.0300 - val_loss: 4.7518 - val_accuracy: 0.0211\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 2.6519 - accuracy: 0.0500 - val_loss: 4.6468 - val_accuracy: 0.0371\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.4769 - accuracy: 0.0900 - val_loss: 4.8137 - val_accuracy: 0.0554\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 2.3530 - accuracy: 0.1600 - val_loss: 4.6145 - val_accuracy: 0.0392\n",
            "\n",
            "de 0.0325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 11%|█         | 1/9 [00:07<01:03,  7.91s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.0091\n",
            "it 0.015\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 4.6376 - accuracy: 0.0080 - val_loss: 4.4319 - val_accuracy: 0.0107\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 4.3216 - accuracy: 0.0240 - val_loss: 4.3898 - val_accuracy: 0.0175\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 3.8234 - accuracy: 0.0440 - val_loss: 4.4058 - val_accuracy: 0.0369\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 3.6946 - accuracy: 0.0640 - val_loss: 4.1748 - val_accuracy: 0.0506\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 3.3379 - accuracy: 0.0920 - val_loss: 4.1069 - val_accuracy: 0.0501\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 3.0063 - accuracy: 0.1080 - val_loss: 4.1625 - val_accuracy: 0.0503\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 2.7740 - accuracy: 0.1480 - val_loss: 3.9606 - val_accuracy: 0.0842\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.6050 - accuracy: 0.1280 - val_loss: 3.8483 - val_accuracy: 0.1165\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.2492 - accuracy: 0.2240 - val_loss: 3.8299 - val_accuracy: 0.2090\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 2.0215 - accuracy: 0.3440 - val_loss: 3.5609 - val_accuracy: 0.2387\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.8199 - accuracy: 0.3960 - val_loss: 3.7943 - val_accuracy: 0.1955\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.6670 - accuracy: 0.4080 - val_loss: 3.4991 - val_accuracy: 0.3166\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.4975 - accuracy: 0.4880 - val_loss: 3.8610 - val_accuracy: 0.2199\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 1.3154 - accuracy: 0.4160 - val_loss: 3.4849 - val_accuracy: 0.2848\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 1.2619 - accuracy: 0.5320 - val_loss: 3.2392 - val_accuracy: 0.3872\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.1365 - accuracy: 0.6360 - val_loss: 3.2496 - val_accuracy: 0.4015\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.9002 - accuracy: 0.6640 - val_loss: 3.1873 - val_accuracy: 0.4378\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.8973 - accuracy: 0.7200 - val_loss: 3.3015 - val_accuracy: 0.3804\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.7647 - accuracy: 0.7280 - val_loss: 3.1751 - val_accuracy: 0.4526\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.6750 - accuracy: 0.7600 - val_loss: 3.0333 - val_accuracy: 0.4755\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.7168 - accuracy: 0.8080 - val_loss: 3.0428 - val_accuracy: 0.4981\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.5858 - accuracy: 0.8040 - val_loss: 3.2476 - val_accuracy: 0.4587\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.5583 - accuracy: 0.8240 - val_loss: 3.2081 - val_accuracy: 0.4505\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.5792 - accuracy: 0.8040 - val_loss: 3.1252 - val_accuracy: 0.4737\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.5454 - accuracy: 0.8560 - val_loss: 3.1809 - val_accuracy: 0.4844\n",
            "\n",
            "de 0.4973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 22%|██▏       | 2/9 [00:22<01:10, 10.06s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.0683\n",
            "it 0.033\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 4.0793 - accuracy: 0.0160 - val_loss: 4.2525 - val_accuracy: 0.0272\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 3.6531 - accuracy: 0.0580 - val_loss: 3.9270 - val_accuracy: 0.0595\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 3.3098 - accuracy: 0.1000 - val_loss: 3.8932 - val_accuracy: 0.0674\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.9142 - accuracy: 0.1220 - val_loss: 3.6532 - val_accuracy: 0.1192\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 2.5547 - accuracy: 0.3120 - val_loss: 3.5133 - val_accuracy: 0.1704\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.1681 - accuracy: 0.3160 - val_loss: 3.1996 - val_accuracy: 0.2754\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.9055 - accuracy: 0.4380 - val_loss: 2.6819 - val_accuracy: 0.4180\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.6021 - accuracy: 0.5080 - val_loss: 2.5870 - val_accuracy: 0.4277\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.3522 - accuracy: 0.6060 - val_loss: 2.2403 - val_accuracy: 0.5256\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.1706 - accuracy: 0.6320 - val_loss: 2.0931 - val_accuracy: 0.5848\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.0019 - accuracy: 0.7500 - val_loss: 1.9766 - val_accuracy: 0.5767\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.8450 - accuracy: 0.7540 - val_loss: 1.9532 - val_accuracy: 0.6011\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.7828 - accuracy: 0.7760 - val_loss: 2.2244 - val_accuracy: 0.5156\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.7937 - accuracy: 0.7620 - val_loss: 1.9347 - val_accuracy: 0.6028\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.6751 - accuracy: 0.8080 - val_loss: 1.7431 - val_accuracy: 0.6639\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.6488 - accuracy: 0.8380 - val_loss: 1.7361 - val_accuracy: 0.6697\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.5331 - accuracy: 0.8680 - val_loss: 1.8026 - val_accuracy: 0.6448\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.5215 - accuracy: 0.8680 - val_loss: 1.7246 - val_accuracy: 0.6789\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4572 - accuracy: 0.8900 - val_loss: 1.7447 - val_accuracy: 0.6753\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4753 - accuracy: 0.8900 - val_loss: 1.7262 - val_accuracy: 0.6751\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.4636 - accuracy: 0.8900 - val_loss: 1.7820 - val_accuracy: 0.6712\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4056 - accuracy: 0.9000 - val_loss: 1.7210 - val_accuracy: 0.6814\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3311 - accuracy: 0.9120 - val_loss: 1.6169 - val_accuracy: 0.7109\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.3139 - accuracy: 0.9140 - val_loss: 1.9568 - val_accuracy: 0.6351\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.2633 - accuracy: 0.9100 - val_loss: 1.6272 - val_accuracy: 0.7229\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.2057 - accuracy: 0.9640 - val_loss: 1.6182 - val_accuracy: 0.7267\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.1772 - accuracy: 0.9620 - val_loss: 1.6269 - val_accuracy: 0.7399\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.1743 - accuracy: 0.9680 - val_loss: 1.6252 - val_accuracy: 0.7358\n",
            "\n",
            "de 0.745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 3/9 [00:39<01:12, 12.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1093\n",
            "it 0.1409\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 4.7643 - accuracy: 0.0020 - val_loss: 4.1336 - val_accuracy: 0.0196\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 4.2638 - accuracy: 0.0250 - val_loss: 4.0490 - val_accuracy: 0.0290\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 3.7863 - accuracy: 0.0510 - val_loss: 3.4867 - val_accuracy: 0.1233\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 3.2111 - accuracy: 0.1490 - val_loss: 3.1580 - val_accuracy: 0.2532\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 2.8993 - accuracy: 0.2950 - val_loss: 3.0676 - val_accuracy: 0.1381\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.3909 - accuracy: 0.3230 - val_loss: 2.7285 - val_accuracy: 0.3092\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.9207 - accuracy: 0.4860 - val_loss: 2.2305 - val_accuracy: 0.4315\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.6327 - accuracy: 0.5280 - val_loss: 1.7591 - val_accuracy: 0.5665\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.3503 - accuracy: 0.6070 - val_loss: 1.7080 - val_accuracy: 0.5950\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.1247 - accuracy: 0.7230 - val_loss: 1.4307 - val_accuracy: 0.6555\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9570 - accuracy: 0.7460 - val_loss: 1.3014 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.8455 - accuracy: 0.7840 - val_loss: 1.2592 - val_accuracy: 0.6995\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.7460 - accuracy: 0.8130 - val_loss: 1.2391 - val_accuracy: 0.7079\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.7475 - accuracy: 0.8190 - val_loss: 1.2974 - val_accuracy: 0.6972\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.6179 - accuracy: 0.8360 - val_loss: 1.1765 - val_accuracy: 0.7389\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.5270 - accuracy: 0.8570 - val_loss: 1.2342 - val_accuracy: 0.7251\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.5323 - accuracy: 0.8640 - val_loss: 1.1803 - val_accuracy: 0.7312\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.5022 - accuracy: 0.7900 - val_loss: 1.1561 - val_accuracy: 0.7290\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.4105 - accuracy: 0.8940 - val_loss: 1.1018 - val_accuracy: 0.7752\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.3491 - accuracy: 0.8990 - val_loss: 1.1241 - val_accuracy: 0.7470\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.3724 - accuracy: 0.9070 - val_loss: 1.0338 - val_accuracy: 0.7790\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.3223 - accuracy: 0.9180 - val_loss: 1.0964 - val_accuracy: 0.7623\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.2907 - accuracy: 0.9170 - val_loss: 1.1444 - val_accuracy: 0.7707\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.3506 - accuracy: 0.9160 - val_loss: 1.1046 - val_accuracy: 0.7834\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.4349 - accuracy: 0.9060 - val_loss: 1.7943 - val_accuracy: 0.6654\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.6552 - accuracy: 0.8010 - val_loss: 1.1842 - val_accuracy: 0.7442\n",
            "\n",
            "de 0.7613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 44%|████▍     | 4/9 [00:59<01:12, 14.42s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.0799\n",
            "it 0.1484\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 4.2112 - accuracy: 0.0330 - val_loss: 3.7866 - val_accuracy: 0.0974\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 3.3087 - accuracy: 0.3060 - val_loss: 2.2492 - val_accuracy: 0.4246\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 2.3193 - accuracy: 0.4805 - val_loss: 2.0571 - val_accuracy: 0.4668\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.7861 - accuracy: 0.6095 - val_loss: 1.4375 - val_accuracy: 0.6206\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.3719 - accuracy: 0.6890 - val_loss: 1.1732 - val_accuracy: 0.6901\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.2587 - accuracy: 0.7280 - val_loss: 1.1037 - val_accuracy: 0.6903\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.0679 - accuracy: 0.7520 - val_loss: 0.9801 - val_accuracy: 0.7366\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.9745 - accuracy: 0.7880 - val_loss: 0.9769 - val_accuracy: 0.7251\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.8353 - accuracy: 0.7860 - val_loss: 1.0622 - val_accuracy: 0.7447\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.7757 - accuracy: 0.8215 - val_loss: 0.8440 - val_accuracy: 0.7778\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.6476 - accuracy: 0.8440 - val_loss: 0.8102 - val_accuracy: 0.8050\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.5546 - accuracy: 0.8670 - val_loss: 0.7172 - val_accuracy: 0.8113\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.5030 - accuracy: 0.8805 - val_loss: 0.7700 - val_accuracy: 0.8167\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.4350 - accuracy: 0.8915 - val_loss: 0.7009 - val_accuracy: 0.8302\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3655 - accuracy: 0.9030 - val_loss: 0.6863 - val_accuracy: 0.8497\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3251 - accuracy: 0.9185 - val_loss: 0.7736 - val_accuracy: 0.8129\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3132 - accuracy: 0.9025 - val_loss: 0.6841 - val_accuracy: 0.8413\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3257 - accuracy: 0.9175 - val_loss: 0.6973 - val_accuracy: 0.8429\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3040 - accuracy: 0.9210 - val_loss: 0.6439 - val_accuracy: 0.8553\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2888 - accuracy: 0.9230 - val_loss: 0.6985 - val_accuracy: 0.8363\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2536 - accuracy: 0.9330 - val_loss: 0.6756 - val_accuracy: 0.8609\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2386 - accuracy: 0.9380 - val_loss: 0.6436 - val_accuracy: 0.8530\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1840 - accuracy: 0.9490 - val_loss: 0.7716 - val_accuracy: 0.8225\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1750 - accuracy: 0.9480 - val_loss: 0.6780 - val_accuracy: 0.8525\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1655 - accuracy: 0.9555 - val_loss: 0.6900 - val_accuracy: 0.8650\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1383 - accuracy: 0.9615 - val_loss: 0.6653 - val_accuracy: 0.8617\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1312 - accuracy: 0.9615 - val_loss: 0.6805 - val_accuracy: 0.8617\n",
            "\n",
            "de 0.8752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 56%|█████▌    | 5/9 [01:23<01:09, 17.26s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1187\n",
            "it 0.2114\n",
            "Epoch 1/100\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 3.7297 - accuracy: 0.1770 - val_loss: 2.5483 - val_accuracy: 0.4302\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 2.1480 - accuracy: 0.5692 - val_loss: 1.1468 - val_accuracy: 0.6827\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 1.5105 - accuracy: 0.6924 - val_loss: 1.0671 - val_accuracy: 0.7338\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 1.1121 - accuracy: 0.7730 - val_loss: 0.7832 - val_accuracy: 0.7790\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.9493 - accuracy: 0.8064 - val_loss: 0.8665 - val_accuracy: 0.7773\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.8273 - accuracy: 0.8124 - val_loss: 0.6380 - val_accuracy: 0.8230\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.7292 - accuracy: 0.8532 - val_loss: 0.5683 - val_accuracy: 0.8510\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.6325 - accuracy: 0.8668 - val_loss: 0.5500 - val_accuracy: 0.8541\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.5284 - accuracy: 0.8856 - val_loss: 0.4906 - val_accuracy: 0.8691\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.3611 - accuracy: 0.9112 - val_loss: 0.4668 - val_accuracy: 0.8785\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2999 - accuracy: 0.9246 - val_loss: 0.4281 - val_accuracy: 0.8907\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2422 - accuracy: 0.9408 - val_loss: 0.4283 - val_accuracy: 0.8922\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2180 - accuracy: 0.9474 - val_loss: 0.4022 - val_accuracy: 0.9016\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2022 - accuracy: 0.9494 - val_loss: 0.4066 - val_accuracy: 0.9054\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1905 - accuracy: 0.9464 - val_loss: 0.4134 - val_accuracy: 0.9064\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1674 - accuracy: 0.9588 - val_loss: 0.3999 - val_accuracy: 0.9125\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1238 - accuracy: 0.9686 - val_loss: 0.4103 - val_accuracy: 0.9141\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.0928 - accuracy: 0.9776 - val_loss: 0.4100 - val_accuracy: 0.9158\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.0861 - accuracy: 0.9742 - val_loss: 0.4215 - val_accuracy: 0.9181\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.0742 - accuracy: 0.9812 - val_loss: 0.4081 - val_accuracy: 0.9207\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.0821 - accuracy: 0.9770 - val_loss: 0.4158 - val_accuracy: 0.9207\n",
            "\n",
            "de 0.923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 6/9 [01:53<01:03, 21.13s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1303\n",
            "it 0.2309\n",
            "Epoch 1/100\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 2.7737 - accuracy: 0.3710 - val_loss: 1.2610 - val_accuracy: 0.6949\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.3073 - accuracy: 0.7475 - val_loss: 0.6768 - val_accuracy: 0.8241\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.9866 - accuracy: 0.8139 - val_loss: 0.6061 - val_accuracy: 0.8314\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.7778 - accuracy: 0.8483 - val_loss: 0.5220 - val_accuracy: 0.8556\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.6810 - accuracy: 0.8638 - val_loss: 0.4754 - val_accuracy: 0.8632\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.6029 - accuracy: 0.8789 - val_loss: 0.4417 - val_accuracy: 0.8851\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.5399 - accuracy: 0.8910 - val_loss: 0.4609 - val_accuracy: 0.8675\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4155 - accuracy: 0.9090 - val_loss: 0.4906 - val_accuracy: 0.8607\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4106 - accuracy: 0.9098 - val_loss: 0.4114 - val_accuracy: 0.8942\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.3648 - accuracy: 0.9234 - val_loss: 0.3860 - val_accuracy: 0.8970\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.2687 - accuracy: 0.9350 - val_loss: 0.3538 - val_accuracy: 0.9194\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.2153 - accuracy: 0.9464 - val_loss: 0.3572 - val_accuracy: 0.9074\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.2021 - accuracy: 0.9521 - val_loss: 0.3431 - val_accuracy: 0.9209\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.2030 - accuracy: 0.9526 - val_loss: 0.3797 - val_accuracy: 0.9153\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.2355 - accuracy: 0.9469 - val_loss: 0.3596 - val_accuracy: 0.9158\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1711 - accuracy: 0.9594 - val_loss: 0.3305 - val_accuracy: 0.9280\n",
            "Epoch 17/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1409 - accuracy: 0.9666 - val_loss: 0.3119 - val_accuracy: 0.9336\n",
            "Epoch 18/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1055 - accuracy: 0.9726 - val_loss: 0.3073 - val_accuracy: 0.9354\n",
            "Epoch 19/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1186 - accuracy: 0.9691 - val_loss: 0.3145 - val_accuracy: 0.9385\n",
            "Epoch 20/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1024 - accuracy: 0.9756 - val_loss: 0.3144 - val_accuracy: 0.9408\n",
            "Epoch 21/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1178 - accuracy: 0.9726 - val_loss: 0.3370 - val_accuracy: 0.9331\n",
            "Epoch 22/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.0961 - accuracy: 0.9771 - val_loss: 0.2916 - val_accuracy: 0.9441\n",
            "Epoch 23/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.0669 - accuracy: 0.9849 - val_loss: 0.3130 - val_accuracy: 0.9425\n",
            "Epoch 24/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.0489 - accuracy: 0.9866 - val_loss: 0.3143 - val_accuracy: 0.9448\n",
            "Epoch 25/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.0644 - accuracy: 0.9860 - val_loss: 0.3925 - val_accuracy: 0.9214\n",
            "Epoch 26/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1819 - accuracy: 0.9581 - val_loss: 0.3369 - val_accuracy: 0.9359\n",
            "Epoch 27/100\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1059 - accuracy: 0.9735 - val_loss: 0.3121 - val_accuracy: 0.9380\n",
            "\n",
            "de 0.9451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 78%|███████▊  | 7/9 [02:52<01:05, 32.55s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1821\n",
            "it 0.2294\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 2.4767 - accuracy: 0.4852 - val_loss: 0.8770 - val_accuracy: 0.7719\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.1423 - accuracy: 0.7927 - val_loss: 0.6769 - val_accuracy: 0.8035\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.8385 - accuracy: 0.8441 - val_loss: 0.5679 - val_accuracy: 0.8380\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.6813 - accuracy: 0.8756 - val_loss: 0.4653 - val_accuracy: 0.8719\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.4839 - accuracy: 0.9040 - val_loss: 0.4204 - val_accuracy: 0.8777\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.4436 - accuracy: 0.9113 - val_loss: 0.3743 - val_accuracy: 0.9064\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.3668 - accuracy: 0.9217 - val_loss: 0.3366 - val_accuracy: 0.9184\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.3018 - accuracy: 0.9384 - val_loss: 0.3463 - val_accuracy: 0.9161\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2561 - accuracy: 0.9509 - val_loss: 0.3205 - val_accuracy: 0.9176\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2495 - accuracy: 0.9456 - val_loss: 0.3153 - val_accuracy: 0.9225\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2254 - accuracy: 0.9507 - val_loss: 0.3499 - val_accuracy: 0.9252\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1663 - accuracy: 0.9586 - val_loss: 0.2968 - val_accuracy: 0.9311\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1853 - accuracy: 0.9663 - val_loss: 0.3779 - val_accuracy: 0.9085\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1911 - accuracy: 0.9608 - val_loss: 0.3359 - val_accuracy: 0.9247\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1354 - accuracy: 0.9689 - val_loss: 0.3101 - val_accuracy: 0.9303\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1433 - accuracy: 0.9663 - val_loss: 0.2783 - val_accuracy: 0.9415\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1150 - accuracy: 0.9726 - val_loss: 0.2791 - val_accuracy: 0.9458\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1155 - accuracy: 0.9777 - val_loss: 0.3149 - val_accuracy: 0.9390\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0957 - accuracy: 0.9798 - val_loss: 0.2745 - val_accuracy: 0.9425\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0858 - accuracy: 0.9813 - val_loss: 0.2995 - val_accuracy: 0.9436\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0907 - accuracy: 0.9800 - val_loss: 0.3048 - val_accuracy: 0.9433\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0994 - accuracy: 0.9803 - val_loss: 0.3079 - val_accuracy: 0.9352\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0720 - accuracy: 0.9791 - val_loss: 0.3225 - val_accuracy: 0.9336\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0876 - accuracy: 0.9784 - val_loss: 0.2818 - val_accuracy: 0.9489\n",
            "\n",
            "de 0.9527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 89%|████████▉ | 8/9 [04:06<00:44, 44.88s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1037\n",
            "it 0.2099\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.9785 - accuracy: 0.5859 - val_loss: 0.6871 - val_accuracy: 0.8241\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8309 - accuracy: 0.8390 - val_loss: 0.4482 - val_accuracy: 0.8764\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5266 - accuracy: 0.8958 - val_loss: 0.4331 - val_accuracy: 0.8912\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4070 - accuracy: 0.9128 - val_loss: 0.3374 - val_accuracy: 0.9006\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3196 - accuracy: 0.9321 - val_loss: 0.3311 - val_accuracy: 0.9067\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2529 - accuracy: 0.9472 - val_loss: 0.3120 - val_accuracy: 0.9219\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.2216 - accuracy: 0.9498 - val_loss: 0.2928 - val_accuracy: 0.9291\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1864 - accuracy: 0.9578 - val_loss: 0.2666 - val_accuracy: 0.9364\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1781 - accuracy: 0.9586 - val_loss: 0.2341 - val_accuracy: 0.9479\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1550 - accuracy: 0.9635 - val_loss: 0.2545 - val_accuracy: 0.9486\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1595 - accuracy: 0.9659 - val_loss: 0.2601 - val_accuracy: 0.9402\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1687 - accuracy: 0.9638 - val_loss: 0.2829 - val_accuracy: 0.9387\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1256 - accuracy: 0.9725 - val_loss: 0.2368 - val_accuracy: 0.9491\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1053 - accuracy: 0.9750 - val_loss: 0.2743 - val_accuracy: 0.9456\n",
            "\n",
            "de 0.9464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 9/9 [05:14<00:00, 34.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.1352\n",
            "it 0.2189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.4973</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.8752</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.9451</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>0.9464</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.2888</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.7455</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.8722</td>\n",
              "      <td>0.8921</td>\n",
              "      <td>0.888</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model    task      metric    0     100  ...    5000   10000   15000   25000 40000\n",
              "8   RNN  slc_de    accuracy  NaN  0.0325  ...   0.923  0.9451  0.9527  0.9464   NaN\n",
              "9   RNN  slc_de  avg_recall  NaN   0.043  ...  0.8338  0.8722  0.8921   0.888   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xswHlh4DAfRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "d50e76ec-6e95-4220-c5e9-e9900cc75eef"
      },
      "source": [
        "task = 'slc_de'\n",
        "df_results[(df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2747</td>\n",
              "      <td>0.4469</td>\n",
              "      <td>0.5665</td>\n",
              "      <td>0.7278</td>\n",
              "      <td>0.8264</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.9094</td>\n",
              "      <td>0.9286</td>\n",
              "      <td>0.9387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7303</td>\n",
              "      <td>0.7093</td>\n",
              "      <td>0.7707</td>\n",
              "      <td>0.7983</td>\n",
              "      <td>0.8695</td>\n",
              "      <td>0.8924</td>\n",
              "      <td>0.9067</td>\n",
              "      <td>0.9255</td>\n",
              "      <td>0.9364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.7071</td>\n",
              "      <td>0.8449</td>\n",
              "      <td>0.8934</td>\n",
              "      <td>0.9311</td>\n",
              "      <td>0.9478</td>\n",
              "      <td>0.9525</td>\n",
              "      <td>0.9554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1202</td>\n",
              "      <td>0.3464</td>\n",
              "      <td>0.6924</td>\n",
              "      <td>0.7751</td>\n",
              "      <td>0.8209</td>\n",
              "      <td>0.8888</td>\n",
              "      <td>0.9139</td>\n",
              "      <td>0.9208</td>\n",
              "      <td>0.9281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN1D_max</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.6546</td>\n",
              "      <td>0.7626</td>\n",
              "      <td>0.8579</td>\n",
              "      <td>0.8985</td>\n",
              "      <td>0.9416</td>\n",
              "      <td>0.9551</td>\n",
              "      <td>0.9569</td>\n",
              "      <td>0.9561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN1D_max</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.6697</td>\n",
              "      <td>0.723</td>\n",
              "      <td>0.8214</td>\n",
              "      <td>0.8564</td>\n",
              "      <td>0.9248</td>\n",
              "      <td>0.9369</td>\n",
              "      <td>0.9305</td>\n",
              "      <td>0.9372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0671</td>\n",
              "      <td>0.3766</td>\n",
              "      <td>0.6354</td>\n",
              "      <td>0.7688</td>\n",
              "      <td>0.8706</td>\n",
              "      <td>0.905</td>\n",
              "      <td>0.9217</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0984</td>\n",
              "      <td>0.4014</td>\n",
              "      <td>0.6026</td>\n",
              "      <td>0.7121</td>\n",
              "      <td>0.8312</td>\n",
              "      <td>0.8696</td>\n",
              "      <td>0.8846</td>\n",
              "      <td>0.8713</td>\n",
              "      <td>0.9082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model    task      metric    0  ...    5000   10000   15000   25000\n",
              "0     LogReg  slc_de    accuracy  NaN  ...  0.8804  0.9094  0.9286  0.9387\n",
              "1     LogReg  slc_de  avg_recall  NaN  ...  0.8924  0.9067  0.9255  0.9364\n",
              "2   avg_pool  slc_de    accuracy  NaN  ...  0.9311  0.9478  0.9525  0.9554\n",
              "3   avg_pool  slc_de  avg_recall  NaN  ...  0.8888  0.9139  0.9208  0.9281\n",
              "4  CNN1D_max  slc_de    accuracy  NaN  ...  0.9416  0.9551  0.9569  0.9561\n",
              "5  CNN1D_max  slc_de  avg_recall  NaN  ...  0.9248  0.9369  0.9305  0.9372\n",
              "6        RNN  slc_de    accuracy  NaN  ...   0.905  0.9217  0.9119   0.938\n",
              "7        RNN  slc_de  avg_recall  NaN  ...  0.8696  0.8846  0.8713  0.9082\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t6ZEVE7KRxxI"
      },
      "source": [
        "# Single Language Classifier French"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wG6eoMcYRxxY"
      },
      "source": [
        "##LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0t-g2JplYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "94d3f863-489f-439e-cd8f-0d05212f0057"
      },
      "source": [
        "task = 'slc_fr'\n",
        "model = 'LogReg'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "    \n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "    tf_idf_log_reg(X_train_fr,y_train_fr,X_test_fr,y_test_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  7.96it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:01,  5.75it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 3/8 [00:00<00:01,  3.61it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 4/8 [00:01<00:01,  2.01it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 62%|██████▎   | 5/8 [00:03<00:02,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:08<00:04,  2.17s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 88%|████████▊ | 7/8 [00:19<00:04,  4.78s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 8/8 [00:37<00:00,  4.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4841</td>\n",
              "      <td>0.5846</td>\n",
              "      <td>0.7156</td>\n",
              "      <td>0.7867</td>\n",
              "      <td>0.8508</td>\n",
              "      <td>0.9075</td>\n",
              "      <td>0.918</td>\n",
              "      <td>0.937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1019</td>\n",
              "      <td>0.1692</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.3362</td>\n",
              "      <td>0.4519</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>0.7182</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model    task      metric    0     100  ...    5000   10000   15000 25000 40000\n",
              "10  LogReg  slc_fr    accuracy  NaN  0.4841  ...  0.9075   0.918   0.937   NaN   NaN\n",
              "11  LogReg  slc_fr  avg_recall  NaN  0.1019  ...   0.592  0.6549  0.7182   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okde_IWgiBYG",
        "colab_type": "text"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdllK9xmIqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48fc4cd7-57db-4cd4-e22c-43cbd1e17dba"
      },
      "source": [
        "task = 'slc_fr'\n",
        "model = 'avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "     #run_CNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,class_weight_dict_de,obs)\n",
        "     run_avg_pool(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,class_weight_dict_fr,obs)\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 34) (100, 75)\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 5.6611 - accuracy: 0.0200 - val_loss: 4.2407 - val_accuracy: 0.0242\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 5.3250 - accuracy: 0.1500 - val_loss: 4.1935 - val_accuracy: 0.0221\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 5.0312 - accuracy: 0.1800 - val_loss: 4.1681 - val_accuracy: 0.0182\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 4.6823 - accuracy: 0.1700 - val_loss: 4.1696 - val_accuracy: 0.0154\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 4.3147 - accuracy: 0.1500 - val_loss: 4.2031 - val_accuracy: 0.0165\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.8912 - accuracy: 0.1800 - val_loss: 4.2734 - val_accuracy: 0.0175\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 3.5704 - accuracy: 0.1800 - val_loss: 4.3603 - val_accuracy: 0.0242\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.1753 - accuracy: 0.2300 - val_loss: 4.4322 - val_accuracy: 0.0357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 12%|█▎        | 1/8 [00:03<00:22,  3.28s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.0137\n",
            "fr 0.0357\n",
            "it 0.0015\n",
            "(250, 34) (250, 75)\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 4.0911 - accuracy: 0.0400 - val_loss: 4.1116 - val_accuracy: 0.1559\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 3.8111 - accuracy: 0.2920 - val_loss: 3.9678 - val_accuracy: 0.2355\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 3.5133 - accuracy: 0.4520 - val_loss: 3.8331 - val_accuracy: 0.2074\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 3.2076 - accuracy: 0.4320 - val_loss: 3.7061 - val_accuracy: 0.1994\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 2.8677 - accuracy: 0.5800 - val_loss: 3.5616 - val_accuracy: 0.3371\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 2.5304 - accuracy: 0.7240 - val_loss: 3.3573 - val_accuracy: 0.4184\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 2.1351 - accuracy: 0.7800 - val_loss: 3.0845 - val_accuracy: 0.4138\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 1.7556 - accuracy: 0.8040 - val_loss: 2.7893 - val_accuracy: 0.4678\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 1.3944 - accuracy: 0.8600 - val_loss: 2.5149 - val_accuracy: 0.5361\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 1.0242 - accuracy: 0.8760 - val_loss: 2.2874 - val_accuracy: 0.5869\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.7429 - accuracy: 0.9240 - val_loss: 2.0968 - val_accuracy: 0.6233\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.5686 - accuracy: 0.9520 - val_loss: 1.9537 - val_accuracy: 0.6468\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.3917 - accuracy: 0.9680 - val_loss: 1.8481 - val_accuracy: 0.6633\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.2778 - accuracy: 0.9720 - val_loss: 1.7721 - val_accuracy: 0.6657\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.2109 - accuracy: 0.9760 - val_loss: 1.7037 - val_accuracy: 0.6776\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.1491 - accuracy: 0.9880 - val_loss: 1.6419 - val_accuracy: 0.7008\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.1255 - accuracy: 0.9880 - val_loss: 1.5968 - val_accuracy: 0.7165\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0925 - accuracy: 0.9920 - val_loss: 1.5528 - val_accuracy: 0.7316\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 1.5167 - val_accuracy: 0.7365\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0624 - accuracy: 0.9960 - val_loss: 1.4876 - val_accuracy: 0.7418\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 1.4639 - val_accuracy: 0.7498\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0442 - accuracy: 0.9960 - val_loss: 1.4483 - val_accuracy: 0.7558\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 1.4371 - val_accuracy: 0.7579\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.4272 - val_accuracy: 0.7572\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.7561\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.4113 - val_accuracy: 0.7565\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.7582\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.3972 - val_accuracy: 0.7586\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.3911 - val_accuracy: 0.7593\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.7610\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.7621\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.7635\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3706 - val_accuracy: 0.7631\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3665 - val_accuracy: 0.7631\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3631 - val_accuracy: 0.7645\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3611 - val_accuracy: 0.7642\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.7642\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3564 - val_accuracy: 0.7642\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.7642\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.7645\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3497 - val_accuracy: 0.7645\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.7645\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7649\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7638\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.7645\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.7649\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3442 - val_accuracy: 0.7649\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.7649\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.7649\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3401 - val_accuracy: 0.7649\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.3389 - val_accuracy: 0.7656\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.7663\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.7666\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.3360 - val_accuracy: 0.7666\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.7666\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3348 - val_accuracy: 0.7666\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3342 - val_accuracy: 0.7666\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3333 - val_accuracy: 0.7666\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3326 - val_accuracy: 0.7670\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.7673\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.7673\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3309 - val_accuracy: 0.7673\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3306 - val_accuracy: 0.7677\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.7673\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.7670\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3305 - val_accuracy: 0.7666\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3305 - val_accuracy: 0.7666\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3301 - val_accuracy: 0.7666\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3296 - val_accuracy: 0.7666\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.7670\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3289 - val_accuracy: 0.7670\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.7663\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3283 - val_accuracy: 0.7663\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.7663\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3276 - val_accuracy: 0.7673\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3272 - val_accuracy: 0.7680\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.7687\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.7691\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.7691\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.7691\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.7691\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.7694\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.7694\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.7698\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.7701\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.7701\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.7694\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3250 - val_accuracy: 0.7694\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.7694\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.7694\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.7694\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.7691\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.7691\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.7694\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.7687\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.7691\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.7691\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.7691\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.7698\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3242 - val_accuracy: 0.7698\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.7698\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3246 - val_accuracy: 0.7701\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.7701\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.7701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 2/8 [00:46<01:31, 15.27s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.0496\n",
            "fr 0.7653\n",
            "it 0.012\n",
            "(500, 34) (500, 75)\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 4.0390 - accuracy: 0.0980 - val_loss: 3.9192 - val_accuracy: 0.0456\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 3.6344 - accuracy: 0.1680 - val_loss: 3.6677 - val_accuracy: 0.1321\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 3.1536 - accuracy: 0.3560 - val_loss: 3.2405 - val_accuracy: 0.3641\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.6528 - accuracy: 0.6320 - val_loss: 2.7388 - val_accuracy: 0.4968\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 2.0508 - accuracy: 0.7720 - val_loss: 2.1689 - val_accuracy: 0.5743\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.4695 - accuracy: 0.8840 - val_loss: 1.7254 - val_accuracy: 0.7102\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.9848 - accuracy: 0.9320 - val_loss: 1.4514 - val_accuracy: 0.7544\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.6299 - accuracy: 0.9620 - val_loss: 1.2866 - val_accuracy: 0.7761\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.3522 - accuracy: 0.9920 - val_loss: 1.1776 - val_accuracy: 0.7852\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.2496 - accuracy: 0.9840 - val_loss: 1.1168 - val_accuracy: 0.7887\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.1570 - accuracy: 0.9920 - val_loss: 1.0699 - val_accuracy: 0.7968\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.1188 - accuracy: 0.9960 - val_loss: 1.0329 - val_accuracy: 0.8055\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0824 - accuracy: 0.9960 - val_loss: 1.0079 - val_accuracy: 0.8097\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0721 - accuracy: 0.9980 - val_loss: 0.9894 - val_accuracy: 0.8122\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.0531 - accuracy: 0.9980 - val_loss: 0.9808 - val_accuracy: 0.8146\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0403 - accuracy: 0.9960 - val_loss: 0.9749 - val_accuracy: 0.8157\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0412 - accuracy: 0.9980 - val_loss: 0.9708 - val_accuracy: 0.8157\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.8150\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.0305 - accuracy: 0.9980 - val_loss: 0.9640 - val_accuracy: 0.8157\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.8178\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.8185\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8181\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.8189\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.8192\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.8189\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.8192\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8192\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.8185\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8192\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8192\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.8189\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.8196\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9428 - val_accuracy: 0.8189\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8196\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9431 - val_accuracy: 0.8189\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.8185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 3/8 [01:12<01:32, 18.43s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.0829\n",
            "fr 0.8207\n",
            "it 0.0075\n",
            "(1000, 34) (1000, 75)\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 4.4218 - accuracy: 0.1830 - val_loss: 3.7381 - val_accuracy: 0.2975\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 3.6347 - accuracy: 0.5670 - val_loss: 2.7249 - val_accuracy: 0.5084\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 2.5565 - accuracy: 0.7280 - val_loss: 1.7493 - val_accuracy: 0.6959\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 1.5521 - accuracy: 0.8590 - val_loss: 1.1621 - val_accuracy: 0.8143\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.8387 - accuracy: 0.9500 - val_loss: 0.9304 - val_accuracy: 0.8308\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 0.4047 - accuracy: 0.9740 - val_loss: 0.8302 - val_accuracy: 0.8360\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 0.2295 - accuracy: 0.9820 - val_loss: 0.7558 - val_accuracy: 0.8462\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1286 - accuracy: 0.9870 - val_loss: 0.7218 - val_accuracy: 0.8493\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0905 - accuracy: 0.9910 - val_loss: 0.6943 - val_accuracy: 0.8549\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0636 - accuracy: 0.9960 - val_loss: 0.6830 - val_accuracy: 0.8546\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0480 - accuracy: 0.9970 - val_loss: 0.6744 - val_accuracy: 0.8581\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8556\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8588\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8584\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8570\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.6622 - val_accuracy: 0.8581\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8570\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8567\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8570\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8584\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 4/8 [01:40<01:24, 21.23s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.1192\n",
            "fr 0.8704\n",
            "it 0.0075\n",
            "(2000, 34) (2000, 75)\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_11 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 4.0066 - accuracy: 0.4430 - val_loss: 2.6996 - val_accuracy: 0.7677\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 2.4616 - accuracy: 0.8475 - val_loss: 1.0349 - val_accuracy: 0.8549\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 1.1616 - accuracy: 0.9250 - val_loss: 0.6701 - val_accuracy: 0.8763\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.5056 - accuracy: 0.9585 - val_loss: 0.5406 - val_accuracy: 0.8907\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.2639 - accuracy: 0.9765 - val_loss: 0.4883 - val_accuracy: 0.8945\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.1333 - accuracy: 0.9860 - val_loss: 0.4714 - val_accuracy: 0.8984\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.0843 - accuracy: 0.9910 - val_loss: 0.4606 - val_accuracy: 0.9001\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.0555 - accuracy: 0.9940 - val_loss: 0.4545 - val_accuracy: 0.8994\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0397 - accuracy: 0.9965 - val_loss: 0.4550 - val_accuracy: 0.9029\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0280 - accuracy: 0.9975 - val_loss: 0.4524 - val_accuracy: 0.9019\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.4550 - val_accuracy: 0.9008\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0189 - accuracy: 0.9980 - val_loss: 0.4548 - val_accuracy: 0.9026\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.0160 - accuracy: 0.9990 - val_loss: 0.4588 - val_accuracy: 0.9026\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.4580 - val_accuracy: 0.9033\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 62%|██████▎   | 5/8 [02:16<01:17, 25.87s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.1259\n",
            "fr 0.9079\n",
            "it 0.03\n",
            "(5000, 34) (5000, 75)\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_6 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 3.2770 - accuracy: 0.6202 - val_loss: 0.7894 - val_accuracy: 0.8493\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 1.0299 - accuracy: 0.9152 - val_loss: 0.4212 - val_accuracy: 0.9022\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.3931 - accuracy: 0.9618 - val_loss: 0.3481 - val_accuracy: 0.9173\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.2151 - accuracy: 0.9698 - val_loss: 0.3305 - val_accuracy: 0.9236\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.1188 - accuracy: 0.9830 - val_loss: 0.3332 - val_accuracy: 0.9250\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0704 - accuracy: 0.9910 - val_loss: 0.3216 - val_accuracy: 0.9310\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0479 - accuracy: 0.9922 - val_loss: 0.3266 - val_accuracy: 0.9282\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0386 - accuracy: 0.9942 - val_loss: 0.3275 - val_accuracy: 0.9310\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0262 - accuracy: 0.9962 - val_loss: 0.3312 - val_accuracy: 0.9292\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0264 - accuracy: 0.9968 - val_loss: 0.3384 - val_accuracy: 0.9289\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.3386 - val_accuracy: 0.9317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 6/8 [03:20<01:14, 37.26s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.2001\n",
            "fr 0.9394\n",
            "it 0.075\n",
            "(10000, 34) (10000, 75)\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_13 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 2.1344 - accuracy: 0.7797 - val_loss: 0.4207 - val_accuracy: 0.9114\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.4411 - accuracy: 0.9502 - val_loss: 0.2904 - val_accuracy: 0.9362\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.1813 - accuracy: 0.9761 - val_loss: 0.2652 - val_accuracy: 0.9401\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.0894 - accuracy: 0.9864 - val_loss: 0.2505 - val_accuracy: 0.9422\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.0544 - accuracy: 0.9918 - val_loss: 0.2588 - val_accuracy: 0.9443\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.0395 - accuracy: 0.9942 - val_loss: 0.2595 - val_accuracy: 0.9460\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0317 - accuracy: 0.9954 - val_loss: 0.2742 - val_accuracy: 0.9460\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.2752 - val_accuracy: 0.9436\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.2860 - val_accuracy: 0.9443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 7/8 [05:02<00:56, 56.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.2207\n",
            "fr 0.9503\n",
            "it 0.1049\n",
            "(15000, 34) (15000, 75)\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_14 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 1.7318 - accuracy: 0.8142 - val_loss: 0.3302 - val_accuracy: 0.9240\n",
            "Epoch 2/150\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 0.2878 - accuracy: 0.9621 - val_loss: 0.2647 - val_accuracy: 0.9394\n",
            "Epoch 3/150\n",
            "235/235 [==============================] - 16s 70ms/step - loss: 0.1229 - accuracy: 0.9819 - val_loss: 0.2655 - val_accuracy: 0.9408\n",
            "Epoch 4/150\n",
            "235/235 [==============================] - 16s 70ms/step - loss: 0.0716 - accuracy: 0.9882 - val_loss: 0.2541 - val_accuracy: 0.9457\n",
            "Epoch 5/150\n",
            "235/235 [==============================] - 16s 70ms/step - loss: 0.0399 - accuracy: 0.9934 - val_loss: 0.2646 - val_accuracy: 0.9481\n",
            "Epoch 6/150\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 0.0359 - accuracy: 0.9948 - val_loss: 0.2666 - val_accuracy: 0.9516\n",
            "Epoch 7/150\n",
            "235/235 [==============================] - 17s 70ms/step - loss: 0.0367 - accuracy: 0.9944 - val_loss: 0.2820 - val_accuracy: 0.9485\n",
            "Epoch 8/150\n",
            "235/235 [==============================] - 16s 70ms/step - loss: 0.0269 - accuracy: 0.9955 - val_loss: 0.2872 - val_accuracy: 0.9506\n",
            "Epoch 9/150\n",
            "235/235 [==============================] - 17s 70ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 0.2867 - val_accuracy: 0.9552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 8/8 [07:32<00:00, 84.68s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.1729\n",
            "fr 0.9664\n",
            "it 0.0885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 8/8 [07:32<00:00, 56.56s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.7653</td>\n",
              "      <td>0.8207</td>\n",
              "      <td>0.8704</td>\n",
              "      <td>0.9079</td>\n",
              "      <td>0.9394</td>\n",
              "      <td>0.9503</td>\n",
              "      <td>0.9664</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.4174</td>\n",
              "      <td>0.4927</td>\n",
              "      <td>0.5704</td>\n",
              "      <td>0.6615</td>\n",
              "      <td>0.7719</td>\n",
              "      <td>0.7746</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model    task      metric    0  ...   10000   15000 25000 40000\n",
              "0  avg_pool  slc_fr    accuracy  NaN  ...  0.9503  0.9664   NaN   NaN\n",
              "1  avg_pool  slc_fr  avg_recall  NaN  ...  0.7746  0.8275   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uQOx-1YTRxxf"
      },
      "source": [
        "##CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyhESFtFp3qt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56c2fb1e-2828-4a24-8d6b-29cc47b0b3a4"
      },
      "source": [
        "task = 'slc_fr'\n",
        "model = 'CNN1D'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "     run_CNN(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,class_weight_dict_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 34) (100, 75)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 32, 100)      90100       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 31, 100)      120100      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 30, 100)      150100      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 1, 100)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 100)       0           max_pooling1d[0][0]              \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 2s 928ms/step - loss: 4.3647 - accuracy: 0.0100 - val_loss: 4.3191 - val_accuracy: 0.0154\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 2s 814ms/step - loss: 4.0739 - accuracy: 0.0200 - val_loss: 4.2351 - val_accuracy: 0.0039\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 2s 836ms/step - loss: 3.7406 - accuracy: 0.0300 - val_loss: 4.2247 - val_accuracy: 0.0049\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 2s 813ms/step - loss: 3.4926 - accuracy: 0.0100 - val_loss: 4.2515 - val_accuracy: 0.0011\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 2s 815ms/step - loss: 3.5864 - accuracy: 0.0100 - val_loss: 4.3032 - val_accuracy: 0.0011\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 2s 823ms/step - loss: 3.2505 - accuracy: 0.0400 - val_loss: 4.3852 - val_accuracy: 0.0011\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 2s 804ms/step - loss: 3.1672 - accuracy: 0.0400 - val_loss: 4.4534 - val_accuracy: 0.0011\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 2s 804ms/step - loss: 3.1339 - accuracy: 0.0400 - val_loss: 4.4747 - val_accuracy: 0.0011\n",
            "\n",
            "de 0.0074\n",
            "fr 0.0004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 1/8 [00:21<02:32, 21.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0015\n",
            "(250, 34) (250, 75)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 32, 100)      90100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 31, 100)      120100      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 30, 100)      150100      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 100)       0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 1, 100)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 1, 100)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 100)       0           max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "                                                                 max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 4.7184 - accuracy: 0.0200 - val_loss: 4.2485 - val_accuracy: 0.0280\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 4.2181 - accuracy: 0.0320 - val_loss: 4.2281 - val_accuracy: 0.0245\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 4.0641 - accuracy: 0.0280 - val_loss: 4.2176 - val_accuracy: 0.0081\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 3.8918 - accuracy: 0.0320 - val_loss: 4.2181 - val_accuracy: 0.0056\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 3.8853 - accuracy: 0.0400 - val_loss: 4.2245 - val_accuracy: 0.0018\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 2s 519ms/step - loss: 3.7302 - accuracy: 0.0240 - val_loss: 4.2209 - val_accuracy: 0.0014\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 3.6645 - accuracy: 0.0440 - val_loss: 4.2219 - val_accuracy: 0.0014\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 3.5376 - accuracy: 0.0360 - val_loss: 4.2190 - val_accuracy: 0.0042\n",
            "\n",
            "de 0.0053\n",
            "fr 0.0042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 2/8 [00:46<02:16, 22.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.003\n",
            "(500, 34) (500, 75)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 32, 100)      90100       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 31, 100)      120100      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 30, 100)      150100      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 1, 100)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 1, 100)       0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 1, 100)       0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 100)       0           max_pooling1d_6[0][0]            \n",
            "                                                                 max_pooling1d_7[0][0]            \n",
            "                                                                 max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 3.9433 - accuracy: 0.0080 - val_loss: 4.1475 - val_accuracy: 0.0088\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 3.5828 - accuracy: 0.0240 - val_loss: 4.0810 - val_accuracy: 0.0102\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 3.4802 - accuracy: 0.0220 - val_loss: 4.0264 - val_accuracy: 0.0147\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 3s 388ms/step - loss: 3.3702 - accuracy: 0.0320 - val_loss: 3.9838 - val_accuracy: 0.0252\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 3s 427ms/step - loss: 3.2573 - accuracy: 0.0540 - val_loss: 3.9049 - val_accuracy: 0.0767\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 4s 476ms/step - loss: 3.1818 - accuracy: 0.0640 - val_loss: 3.8600 - val_accuracy: 0.0823\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 3.0444 - accuracy: 0.1140 - val_loss: 3.8508 - val_accuracy: 0.0922\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 2.9745 - accuracy: 0.1280 - val_loss: 3.8386 - val_accuracy: 0.0799\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 3s 360ms/step - loss: 2.9136 - accuracy: 0.1400 - val_loss: 3.7937 - val_accuracy: 0.2106\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 3s 362ms/step - loss: 2.8061 - accuracy: 0.1740 - val_loss: 3.7369 - val_accuracy: 0.3097\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 2.6943 - accuracy: 0.2020 - val_loss: 3.6528 - val_accuracy: 0.3924\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 2.6458 - accuracy: 0.2580 - val_loss: 3.5850 - val_accuracy: 0.4394\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 3s 361ms/step - loss: 2.4704 - accuracy: 0.3140 - val_loss: 3.5327 - val_accuracy: 0.4674\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 2.4340 - accuracy: 0.3240 - val_loss: 3.4699 - val_accuracy: 0.5420\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 2.3219 - accuracy: 0.4000 - val_loss: 3.4221 - val_accuracy: 0.5613\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 2.1818 - accuracy: 0.5040 - val_loss: 3.3603 - val_accuracy: 0.5634\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 2.1482 - accuracy: 0.5180 - val_loss: 3.2767 - val_accuracy: 0.5666\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 2.0054 - accuracy: 0.5860 - val_loss: 3.1638 - val_accuracy: 0.6135\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 3s 362ms/step - loss: 1.9529 - accuracy: 0.6260 - val_loss: 3.0508 - val_accuracy: 0.6244\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 1.7752 - accuracy: 0.7060 - val_loss: 2.9384 - val_accuracy: 0.6352\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 3s 364ms/step - loss: 1.7024 - accuracy: 0.7140 - val_loss: 2.8550 - val_accuracy: 0.6493\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 3s 364ms/step - loss: 1.6381 - accuracy: 0.7280 - val_loss: 2.7437 - val_accuracy: 0.6657\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 3s 363ms/step - loss: 1.5457 - accuracy: 0.7900 - val_loss: 2.6416 - val_accuracy: 0.6826\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 1.3602 - accuracy: 0.8340 - val_loss: 2.5341 - val_accuracy: 0.6969\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 1.2672 - accuracy: 0.8200 - val_loss: 2.4150 - val_accuracy: 0.7116\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 1.2085 - accuracy: 0.8520 - val_loss: 2.3065 - val_accuracy: 0.7218\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 1.1488 - accuracy: 0.8860 - val_loss: 2.2167 - val_accuracy: 0.7411\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 1.0379 - accuracy: 0.8820 - val_loss: 2.1263 - val_accuracy: 0.7624\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 0.9410 - accuracy: 0.9260 - val_loss: 2.0166 - val_accuracy: 0.7715\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.8925 - accuracy: 0.9040 - val_loss: 1.9245 - val_accuracy: 0.7835\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.7663 - accuracy: 0.9140 - val_loss: 1.8386 - val_accuracy: 0.7859\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.7870 - accuracy: 0.9320 - val_loss: 1.7662 - val_accuracy: 0.7877\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 0.6482 - accuracy: 0.9360 - val_loss: 1.6921 - val_accuracy: 0.7933\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 0.5583 - accuracy: 0.9460 - val_loss: 1.6357 - val_accuracy: 0.7978\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.5560 - accuracy: 0.9320 - val_loss: 1.5729 - val_accuracy: 0.8010\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.4988 - accuracy: 0.9580 - val_loss: 1.5245 - val_accuracy: 0.8003\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 3s 378ms/step - loss: 0.4641 - accuracy: 0.9540 - val_loss: 1.4910 - val_accuracy: 0.8017\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.4606 - accuracy: 0.9680 - val_loss: 1.4508 - val_accuracy: 0.8041\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 3s 362ms/step - loss: 0.4074 - accuracy: 0.9660 - val_loss: 1.4096 - val_accuracy: 0.8045\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 0.3752 - accuracy: 0.9640 - val_loss: 1.3721 - val_accuracy: 0.8076\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.3475 - accuracy: 0.9620 - val_loss: 1.3404 - val_accuracy: 0.8090\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 3s 364ms/step - loss: 0.3098 - accuracy: 0.9660 - val_loss: 1.3125 - val_accuracy: 0.8111\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 3s 364ms/step - loss: 0.3276 - accuracy: 0.9740 - val_loss: 1.2863 - val_accuracy: 0.8129\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.2798 - accuracy: 0.9700 - val_loss: 1.2670 - val_accuracy: 0.8164\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 0.2621 - accuracy: 0.9800 - val_loss: 1.2406 - val_accuracy: 0.8178\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.2592 - accuracy: 0.9780 - val_loss: 1.2172 - val_accuracy: 0.8171\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 3s 377ms/step - loss: 0.2413 - accuracy: 0.9740 - val_loss: 1.2003 - val_accuracy: 0.8199\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 0.1966 - accuracy: 0.9880 - val_loss: 1.1821 - val_accuracy: 0.8217\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 0.2048 - accuracy: 0.9780 - val_loss: 1.1735 - val_accuracy: 0.8231\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.1859 - accuracy: 0.9860 - val_loss: 1.1621 - val_accuracy: 0.8213\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 3s 377ms/step - loss: 0.1647 - accuracy: 0.9820 - val_loss: 1.1465 - val_accuracy: 0.8199\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.1607 - accuracy: 0.9880 - val_loss: 1.1325 - val_accuracy: 0.8213\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.1707 - accuracy: 0.9860 - val_loss: 1.1171 - val_accuracy: 0.8220\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 0.1617 - accuracy: 0.9860 - val_loss: 1.1067 - val_accuracy: 0.8217\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 0.1332 - accuracy: 0.9880 - val_loss: 1.0956 - val_accuracy: 0.8213\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.1178 - accuracy: 0.9940 - val_loss: 1.0854 - val_accuracy: 0.8220\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 0.1314 - accuracy: 0.9980 - val_loss: 1.0766 - val_accuracy: 0.8252\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.1215 - accuracy: 0.9920 - val_loss: 1.0697 - val_accuracy: 0.8248\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 0.1190 - accuracy: 0.9900 - val_loss: 1.0637 - val_accuracy: 0.8245\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 0.1150 - accuracy: 0.9860 - val_loss: 1.0585 - val_accuracy: 0.8241\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.1023 - accuracy: 0.9900 - val_loss: 1.0547 - val_accuracy: 0.8241\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.0978 - accuracy: 0.9960 - val_loss: 1.0499 - val_accuracy: 0.8234\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 3s 363ms/step - loss: 0.0909 - accuracy: 0.9960 - val_loss: 1.0455 - val_accuracy: 0.8224\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 0.0915 - accuracy: 0.9920 - val_loss: 1.0414 - val_accuracy: 0.8231\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 0.0852 - accuracy: 0.9920 - val_loss: 1.0342 - val_accuracy: 0.8210\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.0915 - accuracy: 0.9960 - val_loss: 1.0304 - val_accuracy: 0.8210\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.0911 - accuracy: 0.9920 - val_loss: 1.0263 - val_accuracy: 0.8234\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 0.0808 - accuracy: 0.9960 - val_loss: 1.0240 - val_accuracy: 0.8227\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 3s 377ms/step - loss: 0.0754 - accuracy: 0.9960 - val_loss: 1.0200 - val_accuracy: 0.8238\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 0.0687 - accuracy: 0.9960 - val_loss: 1.0173 - val_accuracy: 0.8238\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 3s 373ms/step - loss: 0.0753 - accuracy: 0.9920 - val_loss: 1.0113 - val_accuracy: 0.8255\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 3s 362ms/step - loss: 0.0607 - accuracy: 0.9920 - val_loss: 1.0065 - val_accuracy: 0.8255\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 0.0546 - accuracy: 0.9980 - val_loss: 1.0008 - val_accuracy: 0.8262\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 0.0615 - accuracy: 0.9960 - val_loss: 0.9978 - val_accuracy: 0.8273\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 3s 364ms/step - loss: 0.0674 - accuracy: 0.9960 - val_loss: 0.9982 - val_accuracy: 0.8259\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.0577 - accuracy: 0.9960 - val_loss: 0.9984 - val_accuracy: 0.8262\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 3s 370ms/step - loss: 0.0653 - accuracy: 0.9920 - val_loss: 0.9964 - val_accuracy: 0.8273\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.0539 - accuracy: 0.9980 - val_loss: 0.9942 - val_accuracy: 0.8287\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.8290\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 0.0460 - accuracy: 0.9980 - val_loss: 0.9894 - val_accuracy: 0.8287\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 0.0500 - accuracy: 0.9940 - val_loss: 0.9864 - val_accuracy: 0.8276\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 0.0486 - accuracy: 0.9960 - val_loss: 0.9807 - val_accuracy: 0.8262\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 0.0499 - accuracy: 0.9980 - val_loss: 0.9772 - val_accuracy: 0.8266\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 3s 373ms/step - loss: 0.0388 - accuracy: 0.9980 - val_loss: 0.9758 - val_accuracy: 0.8276\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 5s 564ms/step - loss: 0.0404 - accuracy: 0.9960 - val_loss: 0.9764 - val_accuracy: 0.8266\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 0.0440 - accuracy: 0.9940 - val_loss: 0.9762 - val_accuracy: 0.8269\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.0426 - accuracy: 0.9980 - val_loss: 0.9740 - val_accuracy: 0.8266\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 0.0366 - accuracy: 0.9980 - val_loss: 0.9745 - val_accuracy: 0.8269\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 3s 374ms/step - loss: 0.0351 - accuracy: 0.9980 - val_loss: 0.9741 - val_accuracy: 0.8276\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 3s 391ms/step - loss: 0.0367 - accuracy: 0.9980 - val_loss: 0.9737 - val_accuracy: 0.8276\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.8283\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.0373 - accuracy: 0.9980 - val_loss: 0.9694 - val_accuracy: 0.8294\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.8297\n",
            "Epoch 94/150\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 0.0410 - accuracy: 0.9960 - val_loss: 0.9667 - val_accuracy: 0.8287\n",
            "Epoch 95/150\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.8294\n",
            "Epoch 96/150\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.0330 - accuracy: 0.9980 - val_loss: 0.9678 - val_accuracy: 0.8294\n",
            "Epoch 97/150\n",
            "8/8 [==============================] - 3s 374ms/step - loss: 0.0328 - accuracy: 0.9980 - val_loss: 0.9659 - val_accuracy: 0.8297\n",
            "Epoch 98/150\n",
            "8/8 [==============================] - 3s 378ms/step - loss: 0.0315 - accuracy: 0.9960 - val_loss: 0.9624 - val_accuracy: 0.8311\n",
            "Epoch 99/150\n",
            "8/8 [==============================] - 3s 378ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.9599 - val_accuracy: 0.8315\n",
            "Epoch 100/150\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.8315\n",
            "Epoch 101/150\n",
            "8/8 [==============================] - 4s 442ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.8311\n",
            "Epoch 102/150\n",
            "8/8 [==============================] - 5s 579ms/step - loss: 0.0271 - accuracy: 0.9980 - val_loss: 0.9603 - val_accuracy: 0.8301\n",
            "Epoch 103/150\n",
            "8/8 [==============================] - 3s 392ms/step - loss: 0.0286 - accuracy: 0.9980 - val_loss: 0.9618 - val_accuracy: 0.8304\n",
            "Epoch 104/150\n",
            "8/8 [==============================] - 3s 401ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 0.9623 - val_accuracy: 0.8304\n",
            "Epoch 105/150\n",
            "8/8 [==============================] - 3s 419ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.8308\n",
            "\n",
            "de 0.1609\n",
            "fr 0.828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 3/8 [06:34<10:01, 120.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1169\n",
            "(1000, 34) (1000, 75)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 32, 100)      90100       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 31, 100)      120100      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 30, 100)      150100      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 1, 100)       0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 1, 100)       0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 1, 100)       0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 100)       0           max_pooling1d_9[0][0]            \n",
            "                                                                 max_pooling1d_10[0][0]           \n",
            "                                                                 max_pooling1d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 4.6867 - accuracy: 0.0080 - val_loss: 4.2585 - val_accuracy: 0.0049\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 4.4119 - accuracy: 0.0150 - val_loss: 4.1683 - val_accuracy: 0.0032\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 4.2019 - accuracy: 0.0180 - val_loss: 4.0972 - val_accuracy: 0.0028\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 4.0111 - accuracy: 0.0210 - val_loss: 4.0752 - val_accuracy: 0.0028\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 3.9645 - accuracy: 0.0410 - val_loss: 4.0082 - val_accuracy: 0.0182\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 3.7626 - accuracy: 0.0670 - val_loss: 3.9232 - val_accuracy: 0.0091\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 3.5966 - accuracy: 0.1080 - val_loss: 3.7544 - val_accuracy: 0.0673\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 3.4835 - accuracy: 0.1880 - val_loss: 3.6440 - val_accuracy: 0.3886\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 3.2521 - accuracy: 0.2730 - val_loss: 3.5933 - val_accuracy: 0.1811\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 3.1096 - accuracy: 0.2720 - val_loss: 3.4612 - val_accuracy: 0.4594\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 2.8715 - accuracy: 0.3600 - val_loss: 3.3067 - val_accuracy: 0.6030\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 2.7370 - accuracy: 0.4990 - val_loss: 3.1215 - val_accuracy: 0.6412\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 2.6487 - accuracy: 0.5960 - val_loss: 2.9654 - val_accuracy: 0.6864\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 2.3972 - accuracy: 0.6760 - val_loss: 2.7668 - val_accuracy: 0.6875\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 2.1875 - accuracy: 0.7150 - val_loss: 2.5248 - val_accuracy: 0.7330\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 2.0639 - accuracy: 0.7690 - val_loss: 2.3526 - val_accuracy: 0.7533\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 1.8142 - accuracy: 0.8210 - val_loss: 2.1538 - val_accuracy: 0.7470\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 1.6523 - accuracy: 0.8390 - val_loss: 1.9300 - val_accuracy: 0.7873\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 1.4911 - accuracy: 0.8650 - val_loss: 1.7469 - val_accuracy: 0.7961\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 1.3818 - accuracy: 0.8620 - val_loss: 1.6559 - val_accuracy: 0.7954\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 1.2385 - accuracy: 0.8820 - val_loss: 1.5126 - val_accuracy: 0.8157\n",
            "Epoch 22/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 1.0615 - accuracy: 0.8980 - val_loss: 1.3865 - val_accuracy: 0.8115\n",
            "Epoch 23/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.9821 - accuracy: 0.9080 - val_loss: 1.3240 - val_accuracy: 0.8196\n",
            "Epoch 24/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.8911 - accuracy: 0.9090 - val_loss: 1.2462 - val_accuracy: 0.8171\n",
            "Epoch 25/150\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.7634 - accuracy: 0.9240 - val_loss: 1.1518 - val_accuracy: 0.8329\n",
            "Epoch 26/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.7382 - accuracy: 0.9320 - val_loss: 1.1032 - val_accuracy: 0.8360\n",
            "Epoch 27/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.6495 - accuracy: 0.9350 - val_loss: 1.0590 - val_accuracy: 0.8339\n",
            "Epoch 28/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.5636 - accuracy: 0.9340 - val_loss: 1.0134 - val_accuracy: 0.8409\n",
            "Epoch 29/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.5040 - accuracy: 0.9530 - val_loss: 0.9807 - val_accuracy: 0.8420\n",
            "Epoch 30/150\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.4648 - accuracy: 0.9530 - val_loss: 0.9347 - val_accuracy: 0.8465\n",
            "Epoch 31/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.4347 - accuracy: 0.9570 - val_loss: 0.9080 - val_accuracy: 0.8479\n",
            "Epoch 32/150\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.3748 - accuracy: 0.9610 - val_loss: 0.8870 - val_accuracy: 0.8444\n",
            "Epoch 33/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.3716 - accuracy: 0.9560 - val_loss: 0.8559 - val_accuracy: 0.8567\n",
            "Epoch 34/150\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.2983 - accuracy: 0.9670 - val_loss: 0.8322 - val_accuracy: 0.8616\n",
            "Epoch 35/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.2811 - accuracy: 0.9740 - val_loss: 0.8148 - val_accuracy: 0.8595\n",
            "Epoch 36/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.2879 - accuracy: 0.9640 - val_loss: 0.8019 - val_accuracy: 0.8570\n",
            "Epoch 37/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.2798 - accuracy: 0.9760 - val_loss: 0.7884 - val_accuracy: 0.8577\n",
            "Epoch 38/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.2299 - accuracy: 0.9710 - val_loss: 0.7833 - val_accuracy: 0.8584\n",
            "Epoch 39/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.2333 - accuracy: 0.9790 - val_loss: 0.7694 - val_accuracy: 0.8616\n",
            "Epoch 40/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.2251 - accuracy: 0.9760 - val_loss: 0.7575 - val_accuracy: 0.8644\n",
            "Epoch 41/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.2316 - accuracy: 0.9760 - val_loss: 0.7511 - val_accuracy: 0.8612\n",
            "Epoch 42/150\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.1865 - accuracy: 0.9800 - val_loss: 0.7403 - val_accuracy: 0.8655\n",
            "Epoch 43/150\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.1722 - accuracy: 0.9820 - val_loss: 0.7314 - val_accuracy: 0.8655\n",
            "Epoch 44/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.1544 - accuracy: 0.9820 - val_loss: 0.7219 - val_accuracy: 0.8669\n",
            "Epoch 45/150\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 0.1326 - accuracy: 0.9890 - val_loss: 0.7149 - val_accuracy: 0.8697\n",
            "Epoch 46/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.1367 - accuracy: 0.9870 - val_loss: 0.7062 - val_accuracy: 0.8686\n",
            "Epoch 47/150\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.1317 - accuracy: 0.9880 - val_loss: 0.7028 - val_accuracy: 0.8686\n",
            "Epoch 48/150\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 0.1305 - accuracy: 0.9800 - val_loss: 0.7004 - val_accuracy: 0.8707\n",
            "Epoch 49/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.1220 - accuracy: 0.9860 - val_loss: 0.6964 - val_accuracy: 0.8707\n",
            "Epoch 50/150\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.1264 - accuracy: 0.9920 - val_loss: 0.6892 - val_accuracy: 0.8725\n",
            "Epoch 51/150\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.1016 - accuracy: 0.9860 - val_loss: 0.6851 - val_accuracy: 0.8739\n",
            "Epoch 52/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.1026 - accuracy: 0.9890 - val_loss: 0.6848 - val_accuracy: 0.8714\n",
            "Epoch 53/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.0887 - accuracy: 0.9860 - val_loss: 0.6827 - val_accuracy: 0.8704\n",
            "Epoch 54/150\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.0833 - accuracy: 0.9910 - val_loss: 0.6772 - val_accuracy: 0.8739\n",
            "Epoch 55/150\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.0935 - accuracy: 0.9960 - val_loss: 0.6813 - val_accuracy: 0.8718\n",
            "Epoch 56/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.0828 - accuracy: 0.9930 - val_loss: 0.6784 - val_accuracy: 0.8711\n",
            "Epoch 57/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.0666 - accuracy: 0.9960 - val_loss: 0.6762 - val_accuracy: 0.8700\n",
            "Epoch 58/150\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.0734 - accuracy: 0.9950 - val_loss: 0.6728 - val_accuracy: 0.8718\n",
            "Epoch 59/150\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 0.0648 - accuracy: 0.9930 - val_loss: 0.6662 - val_accuracy: 0.8721\n",
            "Epoch 60/150\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.0761 - accuracy: 0.9950 - val_loss: 0.6668 - val_accuracy: 0.8739\n",
            "Epoch 61/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.0788 - accuracy: 0.9930 - val_loss: 0.6692 - val_accuracy: 0.8704\n",
            "Epoch 62/150\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.0608 - accuracy: 0.9920 - val_loss: 0.6648 - val_accuracy: 0.8697\n",
            "Epoch 63/150\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.0655 - accuracy: 0.9940 - val_loss: 0.6589 - val_accuracy: 0.8721\n",
            "Epoch 64/150\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 0.0516 - accuracy: 0.9970 - val_loss: 0.6536 - val_accuracy: 0.8763\n",
            "Epoch 65/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.0616 - accuracy: 0.9960 - val_loss: 0.6560 - val_accuracy: 0.8753\n",
            "Epoch 66/150\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.0505 - accuracy: 0.9970 - val_loss: 0.6568 - val_accuracy: 0.8760\n",
            "Epoch 67/150\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.0517 - accuracy: 0.9960 - val_loss: 0.6541 - val_accuracy: 0.8746\n",
            "Epoch 68/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.0542 - accuracy: 0.9940 - val_loss: 0.6520 - val_accuracy: 0.8777\n",
            "Epoch 69/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.0530 - accuracy: 0.9950 - val_loss: 0.6546 - val_accuracy: 0.8763\n",
            "Epoch 70/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.0473 - accuracy: 0.9970 - val_loss: 0.6546 - val_accuracy: 0.8770\n",
            "Epoch 71/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.0430 - accuracy: 0.9940 - val_loss: 0.6528 - val_accuracy: 0.8777\n",
            "Epoch 72/150\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.0497 - accuracy: 0.9940 - val_loss: 0.6470 - val_accuracy: 0.8777\n",
            "Epoch 73/150\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.0367 - accuracy: 0.9980 - val_loss: 0.6434 - val_accuracy: 0.8795\n",
            "Epoch 74/150\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.0333 - accuracy: 0.9980 - val_loss: 0.6435 - val_accuracy: 0.8809\n",
            "Epoch 75/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8802\n",
            "Epoch 76/150\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.0386 - accuracy: 0.9970 - val_loss: 0.6450 - val_accuracy: 0.8795\n",
            "Epoch 77/150\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.0389 - accuracy: 0.9960 - val_loss: 0.6466 - val_accuracy: 0.8784\n",
            "Epoch 78/150\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.0414 - accuracy: 0.9960 - val_loss: 0.6485 - val_accuracy: 0.8774\n",
            "\n",
            "de 0.1147\n",
            "fr 0.8729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 4/8 [12:59<13:19, 199.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1004\n",
            "(2000, 34) (2000, 75)\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 32, 100)      90100       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 31, 100)      120100      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 30, 100)      150100      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling1D) (None, 1, 100)       0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling1D) (None, 1, 100)       0           conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling1D) (None, 1, 100)       0           conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 100)       0           max_pooling1d_12[0][0]           \n",
            "                                                                 max_pooling1d_13[0][0]           \n",
            "                                                                 max_pooling1d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 8s 251ms/step - loss: 3.9364 - accuracy: 0.0240 - val_loss: 3.9947 - val_accuracy: 0.0456\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 3.6644 - accuracy: 0.0415 - val_loss: 3.9298 - val_accuracy: 0.0484\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 3.4687 - accuracy: 0.1105 - val_loss: 3.6808 - val_accuracy: 0.2730\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 3.2385 - accuracy: 0.2165 - val_loss: 3.4854 - val_accuracy: 0.3570\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 3.0293 - accuracy: 0.3415 - val_loss: 3.1598 - val_accuracy: 0.6573\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 2.7777 - accuracy: 0.5300 - val_loss: 2.7796 - val_accuracy: 0.7477\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 8s 248ms/step - loss: 2.4532 - accuracy: 0.6685 - val_loss: 2.3532 - val_accuracy: 0.7582\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 8s 249ms/step - loss: 2.1590 - accuracy: 0.7300 - val_loss: 1.9858 - val_accuracy: 0.7677\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 1.8278 - accuracy: 0.8065 - val_loss: 1.5686 - val_accuracy: 0.8217\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 1.5197 - accuracy: 0.8470 - val_loss: 1.3073 - val_accuracy: 0.8311\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 8s 250ms/step - loss: 1.2968 - accuracy: 0.8645 - val_loss: 1.1466 - val_accuracy: 0.8276\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 1.1091 - accuracy: 0.8765 - val_loss: 0.9944 - val_accuracy: 0.8469\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.9521 - accuracy: 0.8895 - val_loss: 0.8804 - val_accuracy: 0.8556\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.7720 - accuracy: 0.9140 - val_loss: 0.8099 - val_accuracy: 0.8570\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 8s 242ms/step - loss: 0.7249 - accuracy: 0.9110 - val_loss: 0.7578 - val_accuracy: 0.8641\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 8s 242ms/step - loss: 0.6056 - accuracy: 0.9285 - val_loss: 0.7246 - val_accuracy: 0.8641\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 8s 243ms/step - loss: 0.5174 - accuracy: 0.9315 - val_loss: 0.6855 - val_accuracy: 0.8693\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.4462 - accuracy: 0.9370 - val_loss: 0.6447 - val_accuracy: 0.8795\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 9s 288ms/step - loss: 0.3941 - accuracy: 0.9500 - val_loss: 0.6227 - val_accuracy: 0.8819\n",
            "Epoch 20/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.3850 - accuracy: 0.9550 - val_loss: 0.6047 - val_accuracy: 0.8840\n",
            "Epoch 21/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.3394 - accuracy: 0.9535 - val_loss: 0.5913 - val_accuracy: 0.8854\n",
            "Epoch 22/150\n",
            "32/32 [==============================] - 8s 248ms/step - loss: 0.2568 - accuracy: 0.9630 - val_loss: 0.5751 - val_accuracy: 0.8851\n",
            "Epoch 23/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.2430 - accuracy: 0.9640 - val_loss: 0.5663 - val_accuracy: 0.8865\n",
            "Epoch 24/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.2097 - accuracy: 0.9735 - val_loss: 0.5573 - val_accuracy: 0.8886\n",
            "Epoch 25/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.2037 - accuracy: 0.9755 - val_loss: 0.5433 - val_accuracy: 0.8914\n",
            "Epoch 26/150\n",
            "32/32 [==============================] - 8s 257ms/step - loss: 0.1629 - accuracy: 0.9775 - val_loss: 0.5344 - val_accuracy: 0.8924\n",
            "Epoch 27/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.1687 - accuracy: 0.9815 - val_loss: 0.5262 - val_accuracy: 0.8952\n",
            "Epoch 28/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.1494 - accuracy: 0.9780 - val_loss: 0.5236 - val_accuracy: 0.8966\n",
            "Epoch 29/150\n",
            "32/32 [==============================] - 8s 264ms/step - loss: 0.1338 - accuracy: 0.9805 - val_loss: 0.5277 - val_accuracy: 0.8945\n",
            "Epoch 30/150\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 0.1108 - accuracy: 0.9840 - val_loss: 0.5222 - val_accuracy: 0.8928\n",
            "Epoch 31/150\n",
            "32/32 [==============================] - 8s 252ms/step - loss: 0.1086 - accuracy: 0.9830 - val_loss: 0.5157 - val_accuracy: 0.8949\n",
            "Epoch 32/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.1036 - accuracy: 0.9825 - val_loss: 0.5131 - val_accuracy: 0.8942\n",
            "Epoch 33/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.0955 - accuracy: 0.9880 - val_loss: 0.5125 - val_accuracy: 0.8956\n",
            "Epoch 34/150\n",
            "32/32 [==============================] - 8s 240ms/step - loss: 0.0835 - accuracy: 0.9925 - val_loss: 0.5081 - val_accuracy: 0.8959\n",
            "Epoch 35/150\n",
            "32/32 [==============================] - 8s 243ms/step - loss: 0.0910 - accuracy: 0.9900 - val_loss: 0.5114 - val_accuracy: 0.8966\n",
            "Epoch 36/150\n",
            "32/32 [==============================] - 8s 244ms/step - loss: 0.0813 - accuracy: 0.9895 - val_loss: 0.5091 - val_accuracy: 0.8959\n",
            "Epoch 37/150\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 0.0647 - accuracy: 0.9890 - val_loss: 0.5086 - val_accuracy: 0.8959\n",
            "Epoch 38/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.0635 - accuracy: 0.9895 - val_loss: 0.5118 - val_accuracy: 0.8970\n",
            "Epoch 39/150\n",
            "32/32 [==============================] - 8s 248ms/step - loss: 0.0677 - accuracy: 0.9905 - val_loss: 0.5065 - val_accuracy: 0.8959\n",
            "Epoch 40/150\n",
            "32/32 [==============================] - 8s 250ms/step - loss: 0.0532 - accuracy: 0.9915 - val_loss: 0.5077 - val_accuracy: 0.8963\n",
            "Epoch 41/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.0519 - accuracy: 0.9915 - val_loss: 0.5078 - val_accuracy: 0.8977\n",
            "Epoch 42/150\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 0.0537 - accuracy: 0.9890 - val_loss: 0.5069 - val_accuracy: 0.8980\n",
            "Epoch 43/150\n",
            "32/32 [==============================] - 8s 244ms/step - loss: 0.0501 - accuracy: 0.9905 - val_loss: 0.5059 - val_accuracy: 0.8987\n",
            "Epoch 44/150\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 0.0386 - accuracy: 0.9965 - val_loss: 0.5073 - val_accuracy: 0.8984\n",
            "Epoch 45/150\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.0467 - accuracy: 0.9940 - val_loss: 0.5102 - val_accuracy: 0.9005\n",
            "Epoch 46/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.0385 - accuracy: 0.9945 - val_loss: 0.5084 - val_accuracy: 0.9005\n",
            "Epoch 47/150\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 0.0345 - accuracy: 0.9980 - val_loss: 0.5069 - val_accuracy: 0.8984\n",
            "Epoch 48/150\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.0322 - accuracy: 0.9960 - val_loss: 0.5070 - val_accuracy: 0.8973\n",
            "\n",
            "de 0.271\n",
            "fr 0.9026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 5/8 [19:37<12:57, 259.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1799\n",
            "(5000, 34) (5000, 75)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 32, 100)      90100       embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 31, 100)      120100      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 30, 100)      150100      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling1D) (None, 1, 100)       0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling1D) (None, 1, 100)       0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling1D) (None, 1, 100)       0           conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 3, 100)       0           max_pooling1d_15[0][0]           \n",
            "                                                                 max_pooling1d_16[0][0]           \n",
            "                                                                 max_pooling1d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 4.2453 - accuracy: 0.0342 - val_loss: 3.9429 - val_accuracy: 0.1650\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.7864 - accuracy: 0.1590 - val_loss: 3.6069 - val_accuracy: 0.5676\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.3068 - accuracy: 0.4942 - val_loss: 2.7219 - val_accuracy: 0.7873\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 2.6324 - accuracy: 0.7436 - val_loss: 1.7236 - val_accuracy: 0.8315\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 1.9668 - accuracy: 0.8212 - val_loss: 1.0915 - val_accuracy: 0.8574\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 1.4451 - accuracy: 0.8584 - val_loss: 0.8118 - val_accuracy: 0.8676\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 1.0661 - accuracy: 0.8832 - val_loss: 0.6584 - val_accuracy: 0.8872\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.8537 - accuracy: 0.9036 - val_loss: 0.5722 - val_accuracy: 0.8994\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 0.6915 - accuracy: 0.9108 - val_loss: 0.5003 - val_accuracy: 0.9019\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.5596 - accuracy: 0.9298 - val_loss: 0.4622 - val_accuracy: 0.9068\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.4754 - accuracy: 0.9378 - val_loss: 0.4345 - val_accuracy: 0.9135\n",
            "Epoch 12/150\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.3924 - accuracy: 0.9446 - val_loss: 0.4130 - val_accuracy: 0.9117\n",
            "Epoch 13/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.3383 - accuracy: 0.9462 - val_loss: 0.3940 - val_accuracy: 0.9152\n",
            "Epoch 14/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.2961 - accuracy: 0.9522 - val_loss: 0.3778 - val_accuracy: 0.9184\n",
            "Epoch 15/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.2462 - accuracy: 0.9560 - val_loss: 0.3658 - val_accuracy: 0.9240\n",
            "Epoch 16/150\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 0.2107 - accuracy: 0.9664 - val_loss: 0.3535 - val_accuracy: 0.9254\n",
            "Epoch 17/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.1843 - accuracy: 0.9686 - val_loss: 0.3528 - val_accuracy: 0.9257\n",
            "Epoch 18/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.1731 - accuracy: 0.9708 - val_loss: 0.3439 - val_accuracy: 0.9275\n",
            "Epoch 19/150\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 0.1515 - accuracy: 0.9742 - val_loss: 0.3403 - val_accuracy: 0.9261\n",
            "Epoch 20/150\n",
            "79/79 [==============================] - 19s 246ms/step - loss: 0.1236 - accuracy: 0.9788 - val_loss: 0.3327 - val_accuracy: 0.9285\n",
            "Epoch 21/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.1091 - accuracy: 0.9826 - val_loss: 0.3309 - val_accuracy: 0.9299\n",
            "Epoch 22/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.1118 - accuracy: 0.9802 - val_loss: 0.3290 - val_accuracy: 0.9296\n",
            "Epoch 23/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0883 - accuracy: 0.9836 - val_loss: 0.3287 - val_accuracy: 0.9296\n",
            "Epoch 24/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.0765 - accuracy: 0.9868 - val_loss: 0.3271 - val_accuracy: 0.9285\n",
            "Epoch 25/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0746 - accuracy: 0.9858 - val_loss: 0.3265 - val_accuracy: 0.9296\n",
            "Epoch 26/150\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.0707 - accuracy: 0.9858 - val_loss: 0.3249 - val_accuracy: 0.9306\n",
            "Epoch 27/150\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 0.0654 - accuracy: 0.9892 - val_loss: 0.3251 - val_accuracy: 0.9313\n",
            "Epoch 28/150\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 0.0488 - accuracy: 0.9894 - val_loss: 0.3278 - val_accuracy: 0.9285\n",
            "Epoch 29/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0547 - accuracy: 0.9908 - val_loss: 0.3264 - val_accuracy: 0.9306\n",
            "Epoch 30/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0513 - accuracy: 0.9900 - val_loss: 0.3242 - val_accuracy: 0.9303\n",
            "Epoch 31/150\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.0396 - accuracy: 0.9938 - val_loss: 0.3244 - val_accuracy: 0.9320\n",
            "Epoch 32/150\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.0363 - accuracy: 0.9934 - val_loss: 0.3271 - val_accuracy: 0.9320\n",
            "Epoch 33/150\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.0367 - accuracy: 0.9920 - val_loss: 0.3269 - val_accuracy: 0.9320\n",
            "Epoch 34/150\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0327 - accuracy: 0.9942 - val_loss: 0.3275 - val_accuracy: 0.9341\n",
            "Epoch 35/150\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 0.3280 - val_accuracy: 0.9324\n",
            "\n",
            "de 0.2535\n",
            "fr 0.9356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 6/8 [30:26<12:32, 376.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2069\n",
            "(10000, 34) (10000, 75)\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 32, 100)      90100       embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 31, 100)      120100      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 30, 100)      150100      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling1D) (None, 1, 100)       0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling1D) (None, 1, 100)       0           conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling1D) (None, 1, 100)       0           conv1d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 3, 100)       0           max_pooling1d_18[0][0]           \n",
            "                                                                 max_pooling1d_19[0][0]           \n",
            "                                                                 max_pooling1d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 4.2748 - accuracy: 0.0708 - val_loss: 3.6561 - val_accuracy: 0.4947\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 3.2630 - accuracy: 0.5204 - val_loss: 1.8575 - val_accuracy: 0.8252\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 1.9003 - accuracy: 0.8104 - val_loss: 0.8308 - val_accuracy: 0.8749\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 1.1726 - accuracy: 0.8684 - val_loss: 0.5416 - val_accuracy: 0.8970\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.7986 - accuracy: 0.9010 - val_loss: 0.4464 - val_accuracy: 0.9110\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 34s 215ms/step - loss: 0.5778 - accuracy: 0.9207 - val_loss: 0.3838 - val_accuracy: 0.9191\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 34s 217ms/step - loss: 0.4526 - accuracy: 0.9349 - val_loss: 0.3509 - val_accuracy: 0.9268\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 34s 217ms/step - loss: 0.3600 - accuracy: 0.9422 - val_loss: 0.3220 - val_accuracy: 0.9331\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 34s 220ms/step - loss: 0.2840 - accuracy: 0.9538 - val_loss: 0.3077 - val_accuracy: 0.9355\n",
            "Epoch 10/150\n",
            "157/157 [==============================] - 36s 228ms/step - loss: 0.2394 - accuracy: 0.9634 - val_loss: 0.2982 - val_accuracy: 0.9359\n",
            "Epoch 11/150\n",
            "157/157 [==============================] - 34s 217ms/step - loss: 0.2006 - accuracy: 0.9680 - val_loss: 0.2778 - val_accuracy: 0.9411\n",
            "Epoch 12/150\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 0.1657 - accuracy: 0.9726 - val_loss: 0.2707 - val_accuracy: 0.9443\n",
            "Epoch 13/150\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 0.1309 - accuracy: 0.9776 - val_loss: 0.2659 - val_accuracy: 0.9439\n",
            "Epoch 14/150\n",
            "157/157 [==============================] - 36s 227ms/step - loss: 0.1223 - accuracy: 0.9782 - val_loss: 0.2618 - val_accuracy: 0.9450\n",
            "Epoch 15/150\n",
            "157/157 [==============================] - 34s 218ms/step - loss: 0.1129 - accuracy: 0.9815 - val_loss: 0.2577 - val_accuracy: 0.9464\n",
            "Epoch 16/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0893 - accuracy: 0.9826 - val_loss: 0.2541 - val_accuracy: 0.9474\n",
            "Epoch 17/150\n",
            "157/157 [==============================] - 34s 218ms/step - loss: 0.0762 - accuracy: 0.9859 - val_loss: 0.2528 - val_accuracy: 0.9481\n",
            "Epoch 18/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0620 - accuracy: 0.9867 - val_loss: 0.2501 - val_accuracy: 0.9481\n",
            "Epoch 19/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0565 - accuracy: 0.9888 - val_loss: 0.2526 - val_accuracy: 0.9502\n",
            "Epoch 20/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0484 - accuracy: 0.9907 - val_loss: 0.2466 - val_accuracy: 0.9509\n",
            "Epoch 21/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0497 - accuracy: 0.9901 - val_loss: 0.2501 - val_accuracy: 0.9502\n",
            "Epoch 22/150\n",
            "157/157 [==============================] - 35s 220ms/step - loss: 0.0526 - accuracy: 0.9905 - val_loss: 0.2477 - val_accuracy: 0.9513\n",
            "Epoch 23/150\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 0.0460 - accuracy: 0.9903 - val_loss: 0.2459 - val_accuracy: 0.9520\n",
            "Epoch 24/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0394 - accuracy: 0.9921 - val_loss: 0.2459 - val_accuracy: 0.9527\n",
            "Epoch 25/150\n",
            "157/157 [==============================] - 34s 219ms/step - loss: 0.0296 - accuracy: 0.9940 - val_loss: 0.2546 - val_accuracy: 0.9502\n",
            "Epoch 26/150\n",
            "157/157 [==============================] - 35s 220ms/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: 0.2542 - val_accuracy: 0.9520\n",
            "Epoch 27/150\n",
            "157/157 [==============================] - 36s 227ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 0.2536 - val_accuracy: 0.9520\n",
            "Epoch 28/150\n",
            "157/157 [==============================] - 34s 218ms/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.2534 - val_accuracy: 0.9537\n",
            "\n",
            "de 0.3331\n",
            "fr 0.9496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 7/8 [46:47<09:17, 557.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2249\n",
            "(15000, 34) (15000, 75)\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 34, 300)      6875100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 32, 100)      90100       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 31, 100)      120100      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 30, 100)      150100      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling1D) (None, 1, 100)       0           conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling1D) (None, 1, 100)       0           conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling1D) (None, 1, 100)       0           conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 3, 100)       0           max_pooling1d_21[0][0]           \n",
            "                                                                 max_pooling1d_22[0][0]           \n",
            "                                                                 max_pooling1d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 300)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           22575       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,257,975\n",
            "Trainable params: 7,257,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "235/235 [==============================] - 51s 217ms/step - loss: 4.0163 - accuracy: 0.1963 - val_loss: 2.9345 - val_accuracy: 0.7807\n",
            "Epoch 2/150\n",
            "235/235 [==============================] - 50s 213ms/step - loss: 2.3188 - accuracy: 0.7655 - val_loss: 0.8179 - val_accuracy: 0.8805\n",
            "Epoch 3/150\n",
            "235/235 [==============================] - 52s 220ms/step - loss: 1.1525 - accuracy: 0.8708 - val_loss: 0.4808 - val_accuracy: 0.9103\n",
            "Epoch 4/150\n",
            "235/235 [==============================] - 51s 217ms/step - loss: 0.7115 - accuracy: 0.9080 - val_loss: 0.3764 - val_accuracy: 0.9240\n",
            "Epoch 5/150\n",
            "235/235 [==============================] - 51s 217ms/step - loss: 0.5036 - accuracy: 0.9301 - val_loss: 0.3297 - val_accuracy: 0.9334\n",
            "Epoch 6/150\n",
            "235/235 [==============================] - 51s 217ms/step - loss: 0.3597 - accuracy: 0.9472 - val_loss: 0.2915 - val_accuracy: 0.9401\n",
            "Epoch 7/150\n",
            "235/235 [==============================] - 52s 219ms/step - loss: 0.2749 - accuracy: 0.9566 - val_loss: 0.2800 - val_accuracy: 0.9411\n",
            "Epoch 8/150\n",
            "235/235 [==============================] - 51s 215ms/step - loss: 0.2036 - accuracy: 0.9645 - val_loss: 0.2596 - val_accuracy: 0.9460\n",
            "Epoch 9/150\n",
            "235/235 [==============================] - 51s 219ms/step - loss: 0.1677 - accuracy: 0.9708 - val_loss: 0.2543 - val_accuracy: 0.9488\n",
            "Epoch 10/150\n",
            "235/235 [==============================] - 50s 214ms/step - loss: 0.1356 - accuracy: 0.9747 - val_loss: 0.2432 - val_accuracy: 0.9492\n",
            "Epoch 11/150\n",
            "235/235 [==============================] - 52s 221ms/step - loss: 0.1067 - accuracy: 0.9795 - val_loss: 0.2507 - val_accuracy: 0.9492\n",
            "Epoch 12/150\n",
            "235/235 [==============================] - 50s 215ms/step - loss: 0.0852 - accuracy: 0.9828 - val_loss: 0.2402 - val_accuracy: 0.9523\n",
            "Epoch 13/150\n",
            "235/235 [==============================] - 52s 219ms/step - loss: 0.0729 - accuracy: 0.9859 - val_loss: 0.2406 - val_accuracy: 0.9544\n",
            "Epoch 14/150\n",
            "235/235 [==============================] - 50s 213ms/step - loss: 0.0603 - accuracy: 0.9876 - val_loss: 0.2414 - val_accuracy: 0.9523\n",
            "Epoch 15/150\n",
            "235/235 [==============================] - 52s 223ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.2415 - val_accuracy: 0.9548\n",
            "Epoch 16/150\n",
            "235/235 [==============================] - 51s 215ms/step - loss: 0.0438 - accuracy: 0.9916 - val_loss: 0.2458 - val_accuracy: 0.9548\n",
            "Epoch 17/150\n",
            "235/235 [==============================] - 50s 214ms/step - loss: 0.0412 - accuracy: 0.9913 - val_loss: 0.2473 - val_accuracy: 0.9541\n",
            "\n",
            "de 0.2332\n",
            "fr 0.9615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [1:01:24<00:00, 460.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.8729</td>\n",
              "      <td>0.9026</td>\n",
              "      <td>0.9356</td>\n",
              "      <td>0.9496</td>\n",
              "      <td>0.9615</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0133</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.4694</td>\n",
              "      <td>0.5792</td>\n",
              "      <td>0.6432</td>\n",
              "      <td>0.7488</td>\n",
              "      <td>0.8025</td>\n",
              "      <td>0.8347</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model    task      metric    0     100  ...    5000   10000   15000 25000 40000\n",
              "0  CNN1D  slc_fr    accuracy  NaN  0.0004  ...  0.9356  0.9496  0.9615   NaN   NaN\n",
              "1  CNN1D  slc_fr  avg_recall  NaN  0.0133  ...  0.7488  0.8025  0.8347   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ak041rTCRxxl"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txHRaAiAqDVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04c3cf83-a110-493f-9885-2bec3144b1dd"
      },
      "source": [
        "task = 'slc_fr'\n",
        "model = 'RNN'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "     run_RNN(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,class_weight_dict_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 3s/step - loss: 3.3244 - accuracy: 0.0200 - val_loss: 4.4377 - val_accuracy: 0.0025\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 3.1207 - accuracy: 0.0000e+00 - val_loss: 4.0022 - val_accuracy: 0.0081\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 2.6763 - accuracy: 0.0300 - val_loss: 4.2977 - val_accuracy: 0.0035\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 2.3951 - accuracy: 0.0400 - val_loss: 4.5412 - val_accuracy: 0.0053\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 2.2903 - accuracy: 0.0400 - val_loss: 4.4361 - val_accuracy: 0.0067\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 2.1499 - accuracy: 0.0400 - val_loss: 4.4353 - val_accuracy: 0.0126\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 2.0535 - accuracy: 0.0800 - val_loss: 4.5737 - val_accuracy: 0.0116\n",
            "\n",
            "de 0.0074\n",
            "fr 0.0119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 1/8 [01:15<08:51, 75.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0015\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 4.0770 - accuracy: 0.0000e+00 - val_loss: 4.1683 - val_accuracy: 0.0070\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 3.6812 - accuracy: 0.0040 - val_loss: 4.1312 - val_accuracy: 0.0081\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 3.3367 - accuracy: 0.0320 - val_loss: 3.9392 - val_accuracy: 0.0119\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 3.0868 - accuracy: 0.0680 - val_loss: 3.9945 - val_accuracy: 0.0368\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 2.7704 - accuracy: 0.0800 - val_loss: 4.1935 - val_accuracy: 0.0158\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 2.5162 - accuracy: 0.0960 - val_loss: 3.8751 - val_accuracy: 0.0925\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 2.1597 - accuracy: 0.1920 - val_loss: 4.0906 - val_accuracy: 0.1076\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.8289 - accuracy: 0.1560 - val_loss: 4.1550 - val_accuracy: 0.0767\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.7308 - accuracy: 0.2280 - val_loss: 3.7606 - val_accuracy: 0.2130\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.6361 - accuracy: 0.3000 - val_loss: 3.9436 - val_accuracy: 0.1391\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3411 - accuracy: 0.3160 - val_loss: 3.8111 - val_accuracy: 0.2057\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.1944 - accuracy: 0.3840 - val_loss: 3.7645 - val_accuracy: 0.1472\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.0249 - accuracy: 0.3920 - val_loss: 3.4883 - val_accuracy: 0.2537\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.8311 - accuracy: 0.4440 - val_loss: 3.7611 - val_accuracy: 0.2442\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.7220 - accuracy: 0.4760 - val_loss: 3.6587 - val_accuracy: 0.2554\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6095 - accuracy: 0.5320 - val_loss: 3.5217 - val_accuracy: 0.3055\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.5350 - accuracy: 0.5880 - val_loss: 3.3997 - val_accuracy: 0.3707\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4713 - accuracy: 0.6640 - val_loss: 3.4088 - val_accuracy: 0.3865\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4462 - accuracy: 0.6800 - val_loss: 3.6001 - val_accuracy: 0.3549\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3896 - accuracy: 0.6920 - val_loss: 3.4631 - val_accuracy: 0.4078\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3730 - accuracy: 0.7160 - val_loss: 3.4370 - val_accuracy: 0.4226\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2871 - accuracy: 0.7760 - val_loss: 3.5574 - val_accuracy: 0.4404\n",
            "\n",
            "de 0.0353\n",
            "fr 0.4333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 2/8 [04:22<10:55, 109.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0345\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 9s 1s/step - loss: 4.1707 - accuracy: 0.0120 - val_loss: 4.1363 - val_accuracy: 0.0067\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 3.8398 - accuracy: 0.0320 - val_loss: 3.7785 - val_accuracy: 0.0424\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 9s 1s/step - loss: 3.4585 - accuracy: 0.0480 - val_loss: 3.7389 - val_accuracy: 0.0291\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 9s 1s/step - loss: 3.1379 - accuracy: 0.0640 - val_loss: 3.8239 - val_accuracy: 0.0736\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 2.8717 - accuracy: 0.0900 - val_loss: 3.7633 - val_accuracy: 0.0224\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 2.6613 - accuracy: 0.1140 - val_loss: 3.5876 - val_accuracy: 0.1391\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 2.3521 - accuracy: 0.1740 - val_loss: 3.3916 - val_accuracy: 0.1230\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.9232 - accuracy: 0.2440 - val_loss: 3.0861 - val_accuracy: 0.2351\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7386 - accuracy: 0.3200 - val_loss: 3.0907 - val_accuracy: 0.2530\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.4203 - accuracy: 0.3780 - val_loss: 2.7075 - val_accuracy: 0.3605\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.2782 - accuracy: 0.4760 - val_loss: 2.8485 - val_accuracy: 0.2954\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.0280 - accuracy: 0.4480 - val_loss: 2.5445 - val_accuracy: 0.3980\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.9066 - accuracy: 0.5880 - val_loss: 2.3459 - val_accuracy: 0.4664\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.7049 - accuracy: 0.6460 - val_loss: 2.3848 - val_accuracy: 0.4622\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.5101 - accuracy: 0.7240 - val_loss: 2.2872 - val_accuracy: 0.5028\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.3950 - accuracy: 0.7840 - val_loss: 2.0758 - val_accuracy: 0.5988\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.3218 - accuracy: 0.8240 - val_loss: 2.0534 - val_accuracy: 0.5844\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.2639 - accuracy: 0.8480 - val_loss: 2.1160 - val_accuracy: 0.5813\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.1928 - accuracy: 0.9120 - val_loss: 2.0130 - val_accuracy: 0.6465\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.1455 - accuracy: 0.9120 - val_loss: 1.9853 - val_accuracy: 0.6356\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.1112 - accuracy: 0.9360 - val_loss: 1.9783 - val_accuracy: 0.6759\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0856 - accuracy: 0.9640 - val_loss: 2.0934 - val_accuracy: 0.6545\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0658 - accuracy: 0.9620 - val_loss: 2.0062 - val_accuracy: 0.6731\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0450 - accuracy: 0.9820 - val_loss: 2.0580 - val_accuracy: 0.6668\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 2.1232 - val_accuracy: 0.6556\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.0615 - accuracy: 0.9740 - val_loss: 2.0873 - val_accuracy: 0.6622\n",
            "\n",
            "de 0.0511\n",
            "fr 0.6641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 3/8 [08:40<12:48, 153.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1169\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 4.5506 - accuracy: 0.0070 - val_loss: 4.1123 - val_accuracy: 0.0158\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 11s 715ms/step - loss: 4.0682 - accuracy: 0.0800 - val_loss: 3.5533 - val_accuracy: 0.1009\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 11s 718ms/step - loss: 3.5436 - accuracy: 0.1290 - val_loss: 3.4087 - val_accuracy: 0.1854\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 12s 719ms/step - loss: 2.8197 - accuracy: 0.2680 - val_loss: 3.1713 - val_accuracy: 0.1626\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 11s 716ms/step - loss: 2.3627 - accuracy: 0.3470 - val_loss: 2.5625 - val_accuracy: 0.3315\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 11s 713ms/step - loss: 1.8029 - accuracy: 0.4350 - val_loss: 2.3020 - val_accuracy: 0.4019\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 11s 716ms/step - loss: 1.4161 - accuracy: 0.5400 - val_loss: 2.0313 - val_accuracy: 0.4758\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 11s 706ms/step - loss: 1.1297 - accuracy: 0.5620 - val_loss: 1.9463 - val_accuracy: 0.5112\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 11s 706ms/step - loss: 0.9278 - accuracy: 0.6640 - val_loss: 1.9102 - val_accuracy: 0.5284\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 11s 711ms/step - loss: 0.7424 - accuracy: 0.6970 - val_loss: 1.6485 - val_accuracy: 0.6303\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 12s 724ms/step - loss: 0.5062 - accuracy: 0.8060 - val_loss: 1.4026 - val_accuracy: 0.6843\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 0.4852 - accuracy: 0.7520 - val_loss: 1.6735 - val_accuracy: 0.6377\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 12s 725ms/step - loss: 0.3787 - accuracy: 0.8400 - val_loss: 1.4192 - val_accuracy: 0.7032\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 0.3214 - accuracy: 0.8700 - val_loss: 1.3839 - val_accuracy: 0.7043\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 12s 722ms/step - loss: 0.2710 - accuracy: 0.8620 - val_loss: 1.3711 - val_accuracy: 0.7172\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 12s 721ms/step - loss: 0.1889 - accuracy: 0.8950 - val_loss: 1.3075 - val_accuracy: 0.7495\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 0.1636 - accuracy: 0.9220 - val_loss: 1.2834 - val_accuracy: 0.7484\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 12s 723ms/step - loss: 0.1198 - accuracy: 0.9470 - val_loss: 1.2210 - val_accuracy: 0.7730\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 0.1164 - accuracy: 0.9540 - val_loss: 1.1621 - val_accuracy: 0.7926\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 12s 722ms/step - loss: 0.0920 - accuracy: 0.9610 - val_loss: 1.2828 - val_accuracy: 0.7751\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 12s 722ms/step - loss: 0.0831 - accuracy: 0.9570 - val_loss: 1.2635 - val_accuracy: 0.7600\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 12s 720ms/step - loss: 0.0583 - accuracy: 0.9660 - val_loss: 1.1561 - val_accuracy: 0.8027\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 11s 715ms/step - loss: 0.0393 - accuracy: 0.9810 - val_loss: 1.1626 - val_accuracy: 0.8034\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 12s 719ms/step - loss: 0.0557 - accuracy: 0.9750 - val_loss: 1.1946 - val_accuracy: 0.7796\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 12s 719ms/step - loss: 0.0769 - accuracy: 0.9670 - val_loss: 1.3738 - val_accuracy: 0.7509\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0776 - accuracy: 0.9590 - val_loss: 1.2432 - val_accuracy: 0.7887\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 0.0612 - accuracy: 0.9730 - val_loss: 1.2680 - val_accuracy: 0.7863\n",
            "\n",
            "de 0.0905\n",
            "fr 0.7937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 4/8 [14:33<14:14, 213.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0975\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 19s 592ms/step - loss: 4.1069 - accuracy: 0.0440 - val_loss: 3.5692 - val_accuracy: 0.1468\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 19s 594ms/step - loss: 3.5897 - accuracy: 0.1490 - val_loss: 3.2465 - val_accuracy: 0.2200\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 18s 552ms/step - loss: 2.8546 - accuracy: 0.3045 - val_loss: 2.4476 - val_accuracy: 0.3584\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 2.2175 - accuracy: 0.4480 - val_loss: 1.7863 - val_accuracy: 0.5617\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 18s 559ms/step - loss: 1.8764 - accuracy: 0.5590 - val_loss: 1.7694 - val_accuracy: 0.5441\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 18s 553ms/step - loss: 1.4837 - accuracy: 0.6435 - val_loss: 1.4543 - val_accuracy: 0.6748\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 18s 575ms/step - loss: 1.2461 - accuracy: 0.7030 - val_loss: 1.5963 - val_accuracy: 0.6051\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 18s 565ms/step - loss: 1.1601 - accuracy: 0.7230 - val_loss: 1.3008 - val_accuracy: 0.6826\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 18s 555ms/step - loss: 0.8540 - accuracy: 0.7880 - val_loss: 1.1567 - val_accuracy: 0.7316\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 18s 560ms/step - loss: 0.8223 - accuracy: 0.8090 - val_loss: 1.0603 - val_accuracy: 0.7586\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 18s 575ms/step - loss: 0.5872 - accuracy: 0.8590 - val_loss: 0.9463 - val_accuracy: 0.7912\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 18s 576ms/step - loss: 0.5230 - accuracy: 0.8780 - val_loss: 1.0070 - val_accuracy: 0.7649\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 19s 579ms/step - loss: 0.4339 - accuracy: 0.8785 - val_loss: 0.9156 - val_accuracy: 0.8034\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 19s 593ms/step - loss: 0.3245 - accuracy: 0.9100 - val_loss: 0.9398 - val_accuracy: 0.8045\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 22s 673ms/step - loss: 0.2760 - accuracy: 0.9225 - val_loss: 0.9628 - val_accuracy: 0.7954\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 18s 565ms/step - loss: 0.2534 - accuracy: 0.9195 - val_loss: 0.8911 - val_accuracy: 0.8315\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 18s 564ms/step - loss: 0.1481 - accuracy: 0.9505 - val_loss: 0.9240 - val_accuracy: 0.8273\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 18s 568ms/step - loss: 0.1178 - accuracy: 0.9605 - val_loss: 0.8840 - val_accuracy: 0.8353\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 18s 573ms/step - loss: 0.1096 - accuracy: 0.9625 - val_loss: 0.9608 - val_accuracy: 0.8269\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 18s 577ms/step - loss: 0.1111 - accuracy: 0.9650 - val_loss: 1.0370 - val_accuracy: 0.7996\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 18s 573ms/step - loss: 0.1787 - accuracy: 0.9285 - val_loss: 0.9664 - val_accuracy: 0.8241\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 18s 565ms/step - loss: 0.0873 - accuracy: 0.9625 - val_loss: 0.9563 - val_accuracy: 0.8315\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 19s 591ms/step - loss: 0.0567 - accuracy: 0.9755 - val_loss: 0.8887 - val_accuracy: 0.8486\n",
            "\n",
            "de 0.21\n",
            "fr 0.8529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 5/8 [22:15<14:24, 288.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1469\n",
            "Epoch 1/100\n",
            "79/79 [==============================] - 38s 476ms/step - loss: 3.9002 - accuracy: 0.1538 - val_loss: 2.6580 - val_accuracy: 0.3886\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 37s 465ms/step - loss: 2.5462 - accuracy: 0.4438 - val_loss: 1.6531 - val_accuracy: 0.5676\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 37s 472ms/step - loss: 1.7330 - accuracy: 0.6002 - val_loss: 1.2400 - val_accuracy: 0.6542\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 38s 479ms/step - loss: 1.3257 - accuracy: 0.7408 - val_loss: 0.9673 - val_accuracy: 0.7596\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 39s 488ms/step - loss: 1.1212 - accuracy: 0.7938 - val_loss: 0.8132 - val_accuracy: 0.8020\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 37s 472ms/step - loss: 0.9477 - accuracy: 0.8056 - val_loss: 0.7661 - val_accuracy: 0.8115\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 37s 470ms/step - loss: 0.7346 - accuracy: 0.8490 - val_loss: 0.8209 - val_accuracy: 0.7915\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 38s 477ms/step - loss: 0.7220 - accuracy: 0.8610 - val_loss: 0.6394 - val_accuracy: 0.8504\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 37s 468ms/step - loss: 0.6600 - accuracy: 0.8648 - val_loss: 0.6869 - val_accuracy: 0.8367\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 37s 471ms/step - loss: 0.5622 - accuracy: 0.8726 - val_loss: 0.7585 - val_accuracy: 0.8353\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 37s 472ms/step - loss: 0.4974 - accuracy: 0.8948 - val_loss: 0.5632 - val_accuracy: 0.8739\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 38s 481ms/step - loss: 0.2991 - accuracy: 0.9286 - val_loss: 0.5864 - val_accuracy: 0.8777\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 37s 470ms/step - loss: 0.2450 - accuracy: 0.9336 - val_loss: 0.5134 - val_accuracy: 0.9005\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 37s 471ms/step - loss: 0.1984 - accuracy: 0.9462 - val_loss: 0.5794 - val_accuracy: 0.8847\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 37s 471ms/step - loss: 0.1908 - accuracy: 0.9410 - val_loss: 0.5322 - val_accuracy: 0.8987\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 38s 478ms/step - loss: 0.1286 - accuracy: 0.9622 - val_loss: 0.5688 - val_accuracy: 0.8935\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 38s 477ms/step - loss: 0.0923 - accuracy: 0.9668 - val_loss: 0.5695 - val_accuracy: 0.8970\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 38s 477ms/step - loss: 0.0985 - accuracy: 0.9606 - val_loss: 0.5694 - val_accuracy: 0.8984\n",
            "\n",
            "de 0.2825\n",
            "fr 0.8907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 6/8 [34:07<13:50, 415.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2429\n",
            "Epoch 1/100\n",
            "157/157 [==============================] - 73s 466ms/step - loss: 3.0852 - accuracy: 0.3172 - val_loss: 1.6981 - val_accuracy: 0.5879\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 71s 452ms/step - loss: 1.6292 - accuracy: 0.6806 - val_loss: 1.2473 - val_accuracy: 0.6861\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 72s 457ms/step - loss: 1.1827 - accuracy: 0.7778 - val_loss: 0.7141 - val_accuracy: 0.8125\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 71s 452ms/step - loss: 0.9373 - accuracy: 0.8210 - val_loss: 0.7075 - val_accuracy: 0.8181\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 69s 443ms/step - loss: 0.7360 - accuracy: 0.8648 - val_loss: 0.5519 - val_accuracy: 0.8626\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 71s 452ms/step - loss: 0.6127 - accuracy: 0.8846 - val_loss: 0.4986 - val_accuracy: 0.8802\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 69s 441ms/step - loss: 0.5405 - accuracy: 0.8949 - val_loss: 0.5577 - val_accuracy: 0.8507\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 69s 440ms/step - loss: 0.4656 - accuracy: 0.9056 - val_loss: 0.5873 - val_accuracy: 0.8612\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 69s 440ms/step - loss: 0.3609 - accuracy: 0.9203 - val_loss: 0.4642 - val_accuracy: 0.8945\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 72s 457ms/step - loss: 0.3513 - accuracy: 0.9176 - val_loss: 0.4719 - val_accuracy: 0.8875\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 70s 445ms/step - loss: 0.2824 - accuracy: 0.9324 - val_loss: 0.4364 - val_accuracy: 0.9078\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 70s 446ms/step - loss: 0.2088 - accuracy: 0.9480 - val_loss: 0.4456 - val_accuracy: 0.9100\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 72s 456ms/step - loss: 0.1367 - accuracy: 0.9608 - val_loss: 0.4462 - val_accuracy: 0.9075\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 73s 464ms/step - loss: 0.1385 - accuracy: 0.9631 - val_loss: 0.4673 - val_accuracy: 0.9103\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 73s 465ms/step - loss: 0.1038 - accuracy: 0.9683 - val_loss: 0.4558 - val_accuracy: 0.9184\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 72s 458ms/step - loss: 0.1026 - accuracy: 0.9700 - val_loss: 0.4500 - val_accuracy: 0.9114\n",
            "\n",
            "de 0.3227\n",
            "fr 0.9068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 7/8 [53:40<10:42, 642.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2234\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 102s 435ms/step - loss: 2.6208 - accuracy: 0.4287 - val_loss: 1.2218 - val_accuracy: 0.7025\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 105s 447ms/step - loss: 1.2353 - accuracy: 0.7647 - val_loss: 0.7695 - val_accuracy: 0.8024\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 103s 437ms/step - loss: 0.8579 - accuracy: 0.8465 - val_loss: 0.6559 - val_accuracy: 0.8308\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 101s 429ms/step - loss: 0.6465 - accuracy: 0.8839 - val_loss: 0.5789 - val_accuracy: 0.8591\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 103s 439ms/step - loss: 0.5074 - accuracy: 0.8981 - val_loss: 0.5531 - val_accuracy: 0.8669\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 103s 438ms/step - loss: 0.4213 - accuracy: 0.9121 - val_loss: 0.4213 - val_accuracy: 0.9054\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 101s 431ms/step - loss: 0.3306 - accuracy: 0.9241 - val_loss: 0.4328 - val_accuracy: 0.9012\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 103s 440ms/step - loss: 0.2371 - accuracy: 0.9477 - val_loss: 0.3747 - val_accuracy: 0.9191\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 102s 432ms/step - loss: 0.2249 - accuracy: 0.9439 - val_loss: 0.3920 - val_accuracy: 0.9096\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 102s 433ms/step - loss: 0.1478 - accuracy: 0.9611 - val_loss: 0.4068 - val_accuracy: 0.9135\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 103s 440ms/step - loss: 0.1592 - accuracy: 0.9595 - val_loss: 0.3777 - val_accuracy: 0.9296\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 104s 441ms/step - loss: 0.1172 - accuracy: 0.9646 - val_loss: 0.3642 - val_accuracy: 0.9296\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 103s 439ms/step - loss: 0.0774 - accuracy: 0.9743 - val_loss: 0.4059 - val_accuracy: 0.9121\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 103s 437ms/step - loss: 0.0523 - accuracy: 0.9803 - val_loss: 0.3640 - val_accuracy: 0.9383\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 103s 436ms/step - loss: 0.0551 - accuracy: 0.9790 - val_loss: 0.3602 - val_accuracy: 0.9425\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 103s 438ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.3626 - val_accuracy: 0.9310\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 102s 435ms/step - loss: 0.1687 - accuracy: 0.9637 - val_loss: 0.3989 - val_accuracy: 0.9226\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 101s 432ms/step - loss: 0.1738 - accuracy: 0.9604 - val_loss: 0.3753 - val_accuracy: 0.9303\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 103s 438ms/step - loss: 0.1258 - accuracy: 0.9692 - val_loss: 0.3928 - val_accuracy: 0.9257\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 104s 440ms/step - loss: 0.1239 - accuracy: 0.9662 - val_loss: 0.3732 - val_accuracy: 0.9345\n",
            "\n",
            "de 0.2573\n",
            "fr 0.9257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [1:28:33<00:00, 664.13s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0119</td>\n",
              "      <td>0.4333</td>\n",
              "      <td>0.6641</td>\n",
              "      <td>0.7937</td>\n",
              "      <td>0.8529</td>\n",
              "      <td>0.8907</td>\n",
              "      <td>0.9068</td>\n",
              "      <td>0.9257</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>0.1968</td>\n",
              "      <td>0.344</td>\n",
              "      <td>0.4856</td>\n",
              "      <td>0.6012</td>\n",
              "      <td>0.6892</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.7767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model    task      metric    0     100  ...    5000   10000   15000 25000 40000\n",
              "2   RNN  slc_fr    accuracy  NaN  0.0119  ...  0.8907  0.9068  0.9257   NaN   NaN\n",
              "3   RNN  slc_fr  avg_recall  NaN  0.0288  ...  0.6892   0.743  0.7767   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6suHSiLd5CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = 'slc_fr'\n",
        "df_results[(df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSt8b0pM7PQq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ0n5Vss7nQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c3a6c7d-4efc-4311-9e16-4bb9b436ea87"
      },
      "source": [
        "X_it.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(415,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tCr7JnP7PZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = 'slc_it'\n",
        "model = 'LogReg'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "    \n",
        "tf_idf_log_reg(X_it[:365],y_it[:365],X_it[365:],y_it[365:],500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8MwsA5X7Pk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "c5b233f9-0a3d-4299-aed8-23638436e961"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN1D_max</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.7051</td>\n",
              "      <td>0.7994</td>\n",
              "      <td>0.8922</td>\n",
              "      <td>0.9283</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>0.9624</td>\n",
              "      <td>0.9697</td>\n",
              "      <td>0.973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN1D_max</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0119</td>\n",
              "      <td>0.5919</td>\n",
              "      <td>0.6787</td>\n",
              "      <td>0.8116</td>\n",
              "      <td>0.8348</td>\n",
              "      <td>0.9052</td>\n",
              "      <td>0.9014</td>\n",
              "      <td>0.9432</td>\n",
              "      <td>0.9345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN1D_WOET</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0173</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7849</td>\n",
              "      <td>0.8678</td>\n",
              "      <td>0.9204</td>\n",
              "      <td>0.9466</td>\n",
              "      <td>0.9603</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>0.9677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN1D_WOET</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2246</td>\n",
              "      <td>0.6136</td>\n",
              "      <td>0.654</td>\n",
              "      <td>0.7801</td>\n",
              "      <td>0.8632</td>\n",
              "      <td>0.8962</td>\n",
              "      <td>0.9177</td>\n",
              "      <td>0.9294</td>\n",
              "      <td>0.9223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN1D_WOET_Avg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0488</td>\n",
              "      <td>0.6031</td>\n",
              "      <td>0.6929</td>\n",
              "      <td>0.8029</td>\n",
              "      <td>0.8973</td>\n",
              "      <td>0.9265</td>\n",
              "      <td>0.9522</td>\n",
              "      <td>0.9575</td>\n",
              "      <td>0.9626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN1D_WOET_Avg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3273</td>\n",
              "      <td>0.4711</td>\n",
              "      <td>0.5453</td>\n",
              "      <td>0.6862</td>\n",
              "      <td>0.8111</td>\n",
              "      <td>0.8668</td>\n",
              "      <td>0.9071</td>\n",
              "      <td>0.9108</td>\n",
              "      <td>0.9136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0313</td>\n",
              "      <td>0.5578</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>0.8935</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0.9433</td>\n",
              "      <td>0.9408</td>\n",
              "      <td>0.9621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1149</td>\n",
              "      <td>0.3815</td>\n",
              "      <td>0.5266</td>\n",
              "      <td>0.6932</td>\n",
              "      <td>0.7806</td>\n",
              "      <td>0.8491</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8845</td>\n",
              "      <td>0.9226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5419</td>\n",
              "      <td>0.5818</td>\n",
              "      <td>0.7114</td>\n",
              "      <td>0.7765</td>\n",
              "      <td>0.8392</td>\n",
              "      <td>0.8942</td>\n",
              "      <td>0.9264</td>\n",
              "      <td>0.9436</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7418</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.9028</td>\n",
              "      <td>0.8399</td>\n",
              "      <td>0.852</td>\n",
              "      <td>0.8573</td>\n",
              "      <td>0.9192</td>\n",
              "      <td>0.9185</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.7678</td>\n",
              "      <td>0.849</td>\n",
              "      <td>0.8774</td>\n",
              "      <td>0.9236</td>\n",
              "      <td>0.9457</td>\n",
              "      <td>0.9622</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1606</td>\n",
              "      <td>0.2097</td>\n",
              "      <td>0.5381</td>\n",
              "      <td>0.6733</td>\n",
              "      <td>0.7294</td>\n",
              "      <td>0.8066</td>\n",
              "      <td>0.8721</td>\n",
              "      <td>0.8948</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.7201</td>\n",
              "      <td>0.8126</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.8935</td>\n",
              "      <td>0.9201</td>\n",
              "      <td>0.938</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.3826</td>\n",
              "      <td>0.4703</td>\n",
              "      <td>0.5976</td>\n",
              "      <td>0.6713</td>\n",
              "      <td>0.7317</td>\n",
              "      <td>0.7932</td>\n",
              "      <td>0.8389</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.711</td>\n",
              "      <td>0.7944</td>\n",
              "      <td>0.8231</td>\n",
              "      <td>0.8718</td>\n",
              "      <td>0.9037</td>\n",
              "      <td>0.9317</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4971</td>\n",
              "      <td>0.6659</td>\n",
              "      <td>0.6697</td>\n",
              "      <td>0.7077</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.8259</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5243</td>\n",
              "      <td>0.7226</td>\n",
              "      <td>0.7737</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.8687</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3199</td>\n",
              "      <td>0.4196</td>\n",
              "      <td>0.5128</td>\n",
              "      <td>0.6007</td>\n",
              "      <td>0.6987</td>\n",
              "      <td>0.7952</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_frde</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_frde</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_frde</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6344</td>\n",
              "      <td>0.7696</td>\n",
              "      <td>0.8332</td>\n",
              "      <td>0.8935</td>\n",
              "      <td>0.9219</td>\n",
              "      <td>0.9481</td>\n",
              "      <td>0.9558</td>\n",
              "      <td>0.9481</td>\n",
              "      <td>0.9639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_frde</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.552</td>\n",
              "      <td>0.6918</td>\n",
              "      <td>0.7604</td>\n",
              "      <td>0.8104</td>\n",
              "      <td>0.8495</td>\n",
              "      <td>0.9135</td>\n",
              "      <td>0.9186</td>\n",
              "      <td>0.8914</td>\n",
              "      <td>0.944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.62</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7988</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             model      task      metric    0  ...    5000   10000   15000   25000\n",
              "0        CNN1D_max    slc_de    accuracy  NaN  ...  0.9527  0.9624  0.9697   0.973\n",
              "1        CNN1D_max    slc_de  avg_recall  NaN  ...  0.9052  0.9014  0.9432  0.9345\n",
              "2       CNN1D_WOET    slc_de    accuracy  NaN  ...  0.9466  0.9603  0.9629  0.9677\n",
              "3       CNN1D_WOET    slc_de  avg_recall  NaN  ...  0.8962  0.9177  0.9294  0.9223\n",
              "4   CNN1D_WOET_Avg    slc_de    accuracy  NaN  ...  0.9265  0.9522  0.9575  0.9626\n",
              "5   CNN1D_WOET_Avg    slc_de  avg_recall  NaN  ...  0.8668  0.9071  0.9108  0.9136\n",
              "6              RNN    slc_de    accuracy  NaN  ...   0.926  0.9433  0.9408  0.9621\n",
              "7              RNN    slc_de  avg_recall  NaN  ...  0.8491  0.8711  0.8845  0.9226\n",
              "8           LogReg    slc_fr    accuracy  NaN  ...  0.8942  0.9264  0.9436     NaN\n",
              "9           LogReg    slc_fr  avg_recall  NaN  ...  0.8573  0.9192  0.9185     NaN\n",
              "10           CNN1D    slc_fr    accuracy  NaN  ...  0.9236  0.9457  0.9622     NaN\n",
              "11           CNN1D    slc_fr  avg_recall  NaN  ...  0.8066  0.8721  0.8948     NaN\n",
              "12             RNN    slc_fr    accuracy  NaN  ...  0.8935  0.9201   0.938     NaN\n",
              "13             RNN    slc_fr  avg_recall  NaN  ...  0.7317  0.7932  0.8389     NaN\n",
              "14           CNN1D  mlc_defr    accuracy  NaN  ...  0.9317     NaN     NaN     NaN\n",
              "15           CNN1D  mlc_defr  avg_recall  NaN  ...  0.8259     NaN     NaN     NaN\n",
              "16             RNN  mlc_defr    accuracy  NaN  ...  0.9191     NaN     NaN     NaN\n",
              "17             RNN  mlc_defr  avg_recall  NaN  ...  0.7952     NaN     NaN     NaN\n",
              "18          LogReg  mlc_frde    accuracy  NaN  ...     NaN     NaN     NaN     NaN\n",
              "19          LogReg  mlc_frde  avg_recall  NaN  ...     NaN     NaN     NaN     NaN\n",
              "20           CNN1D  mlc_frde    accuracy  NaN  ...  0.9481  0.9558  0.9481  0.9639\n",
              "21           CNN1D  mlc_frde  avg_recall  NaN  ...  0.9135  0.9186  0.8914   0.944\n",
              "22          LogReg    slc_it    accuracy  NaN  ...     NaN     NaN     NaN     NaN\n",
              "23          LogReg    slc_it  avg_recall  NaN  ...     NaN     NaN     NaN     NaN\n",
              "\n",
              "[24 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zESsGd7UHiw",
        "colab_type": "text"
      },
      "source": [
        "# Multilingual Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmpt9P4RQxqn",
        "colab_type": "text"
      },
      "source": [
        "## CNN DE FR "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ5mrHA9Ef68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_df_res(y,pred,no,task):\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(pred, y),4)\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(pred, y)*len(np.unique(pred))/no_Classes,4)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqBYu_Gn6kD7",
        "colab_type": "text"
      },
      "source": [
        "### LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgP9t-f63Bg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_log_reg(X_train_de,y_train_de,X_train_fr,y_train_fr,X_test_de,y_test_de,X_test_fr,y_test_fr,no):\n",
        "    \n",
        "    idx = np.random.randint(len(X_train_fr), size=no)\n",
        "    \n",
        "\n",
        "    idx_de = np.random.randint(len(X_train_de), size=no)\n",
        "\n",
        "\n",
        "    X_train  = X_train_de.iloc[idx_de].append(X_train_fr.iloc[idx])\n",
        "    y_train  = y_train_de.iloc[idx_de].append(y_train_fr.iloc[idx])\n",
        "    print(X_train.shape,X_train_fr.shape,X_train_de.shape)      \n",
        "\n",
        "    X_test_de = [str(x) for x in X_test_de]\n",
        "    X_test_fr = [str(x) for x in X_test_fr]\n",
        "    vectorizer  = TfidfVectorizer()\n",
        "    vectorizer.fit(X_train)\n",
        "\n",
        "    X_train_vec = vectorizer.transform(X_train)\n",
        "    X_test_vec_fr  = vectorizer.transform(X_test_fr)\n",
        "    X_test_vec_de  = vectorizer.transform(X_test_de)\n",
        "\n",
        "    logreg = LogisticRegression(C=1,max_iter=500, solver='newton-cg')#,class_weight=weights_dict)\n",
        "    logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred_train = logreg.predict(X_train_vec)\n",
        "    y_pred_test_fr = logreg.predict(X_test_vec_fr)\n",
        "    y_pred_test_de = logreg.predict(X_test_vec_de)\n",
        "\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test_fr , y_test_fr ),4)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test_de , y_test_de ),4)\n",
        "\n",
        "    task_fr = task + '_fr'\n",
        "    fill_df_res(y_pred_test_fr,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    fill_df_res(y_pred_test_de,y_test_de,no,task_de)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_SD-ETi6Rra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "f9386e50-4cde-4116-d291-b6016e88e96d"
      },
      "source": [
        "task = 'mlc_defr'\n",
        "model = 'LogReg'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_de'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "    tf_idf_log_reg(X_train_de,y_train_de,X_train_fr,y_train_fr,X_test_de,y_test_de,X_test_fr,y_test_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(200,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 12%|█▎        | 1/8 [00:00<00:02,  2.71it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(500,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 2/8 [00:01<00:02,  2.14it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 3/8 [00:02<00:03,  1.34it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(2000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 4/8 [00:05<00:05,  1.30s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 62%|██████▎   | 5/8 [00:10<00:07,  2.53s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:24<00:12,  6.06s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(20000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 7/8 [00:58<00:14, 14.29s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(30000,) (17124,) (23597,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 8/8 [01:49<00:00, 13.68s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3364</td>\n",
              "      <td>0.3722</td>\n",
              "      <td>0.5057</td>\n",
              "      <td>0.6834</td>\n",
              "      <td>0.7918</td>\n",
              "      <td>0.8818</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.9405</td>\n",
              "      <td>0.9542</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0302</td>\n",
              "      <td>0.0617</td>\n",
              "      <td>0.1395</td>\n",
              "      <td>0.3319</td>\n",
              "      <td>0.4836</td>\n",
              "      <td>0.632</td>\n",
              "      <td>0.7596</td>\n",
              "      <td>0.8138</td>\n",
              "      <td>0.8534</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4841</td>\n",
              "      <td>0.5846</td>\n",
              "      <td>0.7156</td>\n",
              "      <td>0.7867</td>\n",
              "      <td>0.8508</td>\n",
              "      <td>0.9075</td>\n",
              "      <td>0.918</td>\n",
              "      <td>0.937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>slc_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1019</td>\n",
              "      <td>0.1692</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.3362</td>\n",
              "      <td>0.4519</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>0.7182</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5811</td>\n",
              "      <td>0.6697</td>\n",
              "      <td>0.7685</td>\n",
              "      <td>0.8326</td>\n",
              "      <td>0.8974</td>\n",
              "      <td>0.9219</td>\n",
              "      <td>0.9338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3155</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.5095</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8238</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9275</td>\n",
              "      <td>0.9392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0611</td>\n",
              "      <td>0.1467</td>\n",
              "      <td>0.2071</td>\n",
              "      <td>0.3104</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.5603</td>\n",
              "      <td>0.6442</td>\n",
              "      <td>0.6874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0175</td>\n",
              "      <td>0.1086</td>\n",
              "      <td>0.1447</td>\n",
              "      <td>0.3563</td>\n",
              "      <td>0.5264</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.7509</td>\n",
              "      <td>0.795</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model         task      metric    0  ...   10000   15000   25000 40000\n",
              "4   LogReg       slc_de    accuracy  NaN  ...   0.924  0.9405  0.9542   NaN\n",
              "5   LogReg       slc_de  avg_recall  NaN  ...  0.7596  0.8138  0.8534   NaN\n",
              "10  LogReg       slc_fr    accuracy  NaN  ...   0.918   0.937     NaN   NaN\n",
              "11  LogReg       slc_fr  avg_recall  NaN  ...  0.6549  0.7182     NaN   NaN\n",
              "12  LogReg  mlc_defr_fr    accuracy  NaN  ...  0.9219  0.9338     NaN   NaN\n",
              "13  LogReg  mlc_defr_de    accuracy  NaN  ...  0.9275  0.9392     NaN   NaN\n",
              "14  LogReg  mlc_defr_fr  avg_recall  NaN  ...  0.6442  0.6874     NaN   NaN\n",
              "15  LogReg  mlc_defr_de  avg_recall  NaN  ...  0.7509   0.795     NaN   NaN\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LtaYycSWbpD",
        "colab_type": "text"
      },
      "source": [
        "### Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctRPquK2WbJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_pool(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,\n",
        "             X_train_emb_fr,y_train_enc_fr,X_val_emb_fr,y_val_enc_fr,X_test_emb_fr,y_test_fr,\n",
        "             class_weight_dict,no):\n",
        "   \n",
        "    idx_fr = np.random.randint(len(X_train_emb_fr), size=no)\n",
        "    idx_de = np.random.randint(len(X_train_emb_de), size=no)\n",
        "\n",
        "    X_train_emb =  np.concatenate((X_train_emb_de[idx_de,:], X_train_emb_fr[idx_fr,:]))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[idx_de,:], y_train_enc_fr[idx_fr,:]))\n",
        "\n",
        "    X_val_emb =  np.concatenate((X_val_emb_de, X_val_emb_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "\n",
        "\n",
        "    print(len(X_train_emb))\n",
        "\n",
        "    dropout_rate= 0.4\n",
        "\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "\n",
        "    pool_layer = GlobalAveragePooling1D()(embedd_seq)   \n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    avg_pool_defr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    avg_pool_defr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = avg_pool_defr.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 64, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    #task_fr = task + '_fr'\n",
        "    #y_pred_test = pred_encode(avg_pool_defr,X_test_pad_fr)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task_fr)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test, y_test_fr),4)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task_fr)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test, y_test_fr),4)\n",
        "\n",
        "    #task_de = task + '_de'\n",
        "    #y_pred_test = pred_encode(avg_pool_defr,X_test_pad_de)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task_de)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test, y_test_de),4)\n",
        "    #df_results[str(no)][(df_results['model']==model) & (df_results['task']==task_de)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test, y_test_de),4)\n",
        "    \n",
        "    task_fr = task + '_fr'\n",
        "    y_pred_test = pred_encode(avg_pool_defr,X_test_pad_fr)\n",
        "    fill_df_res(y_pred_test,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    y_pred_test = pred_encode(avg_pool_defr,X_test_pad_de)\n",
        "    fill_df_res(y_pred_test,y_test_de,no,task_de)\n",
        "\n",
        "    all_tests(avg_pool_defr,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRj-5nq_W00f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6af560b-a136-4cc1-9ccd-9eb6e330bbf2"
      },
      "source": [
        "task = 'mlc_defr'\n",
        "model = 'Avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_de'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "     run_ml_pool(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\\\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\\\n",
        "             class_weight_dict_de_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 4.4506 - accuracy: 0.0340 - val_loss: 4.2836 - val_accuracy: 0.0620\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.4154 - accuracy: 0.0720 - val_loss: 4.2707 - val_accuracy: 0.0631\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 4.3774 - accuracy: 0.1020 - val_loss: 4.2610 - val_accuracy: 0.0688\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 4.3424 - accuracy: 0.1420 - val_loss: 4.2507 - val_accuracy: 0.0814\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.3058 - accuracy: 0.1540 - val_loss: 4.2420 - val_accuracy: 0.0778\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.2753 - accuracy: 0.1520 - val_loss: 4.2345 - val_accuracy: 0.0757\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.2361 - accuracy: 0.1940 - val_loss: 4.2250 - val_accuracy: 0.0746\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.1995 - accuracy: 0.2100 - val_loss: 4.2157 - val_accuracy: 0.0716\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.1578 - accuracy: 0.2060 - val_loss: 4.2085 - val_accuracy: 0.0713\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.1238 - accuracy: 0.2220 - val_loss: 4.1994 - val_accuracy: 0.0699\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 4.0779 - accuracy: 0.2420 - val_loss: 4.1888 - val_accuracy: 0.0721\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 4.0370 - accuracy: 0.2220 - val_loss: 4.1799 - val_accuracy: 0.0694\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.9887 - accuracy: 0.2340 - val_loss: 4.1697 - val_accuracy: 0.0746\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.9418 - accuracy: 0.2380 - val_loss: 4.1575 - val_accuracy: 0.0770\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.9012 - accuracy: 0.2600 - val_loss: 4.1457 - val_accuracy: 0.0787\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.8510 - accuracy: 0.2660 - val_loss: 4.1304 - val_accuracy: 0.0828\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 3.7944 - accuracy: 0.3160 - val_loss: 4.1116 - val_accuracy: 0.0885\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.7504 - accuracy: 0.3100 - val_loss: 4.0922 - val_accuracy: 0.0994\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.7037 - accuracy: 0.3240 - val_loss: 4.0705 - val_accuracy: 0.1104\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.6415 - accuracy: 0.3340 - val_loss: 4.0480 - val_accuracy: 0.1150\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 3.5714 - accuracy: 0.3500 - val_loss: 4.0219 - val_accuracy: 0.1251\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.5127 - accuracy: 0.3840 - val_loss: 3.9920 - val_accuracy: 0.1420\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.4370 - accuracy: 0.4060 - val_loss: 3.9602 - val_accuracy: 0.1516\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.3919 - accuracy: 0.4400 - val_loss: 3.9275 - val_accuracy: 0.1601\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 3.3138 - accuracy: 0.4660 - val_loss: 3.8943 - val_accuracy: 0.1770\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.2450 - accuracy: 0.5040 - val_loss: 3.8598 - val_accuracy: 0.1885\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.1779 - accuracy: 0.5280 - val_loss: 3.8239 - val_accuracy: 0.1989\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.0969 - accuracy: 0.5220 - val_loss: 3.7875 - val_accuracy: 0.2079\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 3.0325 - accuracy: 0.5680 - val_loss: 3.7469 - val_accuracy: 0.2221\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.9647 - accuracy: 0.5840 - val_loss: 3.7126 - val_accuracy: 0.2401\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.8948 - accuracy: 0.6100 - val_loss: 3.6734 - val_accuracy: 0.2527\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.8173 - accuracy: 0.6300 - val_loss: 3.6355 - val_accuracy: 0.2658\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 2.7449 - accuracy: 0.6460 - val_loss: 3.5956 - val_accuracy: 0.2813\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.6615 - accuracy: 0.6760 - val_loss: 3.5561 - val_accuracy: 0.2986\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.5831 - accuracy: 0.6700 - val_loss: 3.5191 - val_accuracy: 0.3062\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 2.5240 - accuracy: 0.6960 - val_loss: 3.4794 - val_accuracy: 0.3204\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.4441 - accuracy: 0.7180 - val_loss: 3.4445 - val_accuracy: 0.3242\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.3749 - accuracy: 0.7100 - val_loss: 3.4078 - val_accuracy: 0.3349\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.3160 - accuracy: 0.7240 - val_loss: 3.3688 - val_accuracy: 0.3461\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 2.2462 - accuracy: 0.7320 - val_loss: 3.3345 - val_accuracy: 0.3537\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1792 - accuracy: 0.7460 - val_loss: 3.2973 - val_accuracy: 0.3671\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1143 - accuracy: 0.7480 - val_loss: 3.2626 - val_accuracy: 0.3731\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.0469 - accuracy: 0.7540 - val_loss: 3.2273 - val_accuracy: 0.3840\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.9898 - accuracy: 0.7640 - val_loss: 3.1933 - val_accuracy: 0.3898\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.9346 - accuracy: 0.7700 - val_loss: 3.1607 - val_accuracy: 0.3963\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.8620 - accuracy: 0.7800 - val_loss: 3.1294 - val_accuracy: 0.4034\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.8033 - accuracy: 0.7940 - val_loss: 3.0970 - val_accuracy: 0.4100\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.7446 - accuracy: 0.7920 - val_loss: 3.0656 - val_accuracy: 0.4155\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6956 - accuracy: 0.8080 - val_loss: 3.0373 - val_accuracy: 0.4207\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.6558 - accuracy: 0.8000 - val_loss: 3.0089 - val_accuracy: 0.4239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-692d57a67578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m      \u001b[0mrun_ml_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_de\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mX_train_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_fr\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mclass_weight_dict_de_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-12f814a0337e>\u001b[0m in \u001b[0;36mrun_ml_pool\u001b[0;34m(X_train_emb_de, y_train_enc_de, X_val_emb_de, y_val_enc_de, X_test_emb_de, y_test_de, X_train_emb_fr, y_train_enc_fr, X_val_emb_fr, y_val_enc_fr, X_test_emb_fr, y_test_fr, class_weight_dict, no)\u001b[0m\n\u001b[1;32m     47\u001b[0m    \u001b[0mtask_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_fr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m    \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_pool_defr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m    \u001b[0mfill_df_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m    \u001b[0mtask_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_de'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fill_df_res() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqGMkyi_YqT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "81d22806-549b-40f3-c7aa-87092479db76"
      },
      "source": [
        "df_results[(df_results['model']==model)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.7023</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.8806</td>\n",
              "      <td>0.9166</td>\n",
              "      <td>0.9338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.8474</td>\n",
              "      <td>0.913</td>\n",
              "      <td>0.9491</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0212</td>\n",
              "      <td>0.3395</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.5755</td>\n",
              "      <td>0.6749</td>\n",
              "      <td>0.7695</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>0.2478</td>\n",
              "      <td>0.4331</td>\n",
              "      <td>0.6675</td>\n",
              "      <td>0.7688</td>\n",
              "      <td>0.8607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model         task      metric    0  ... 10000 15000 25000 40000\n",
              "16  Avg_pool  mlc_defr_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "17  Avg_pool  mlc_defr_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "18  Avg_pool  mlc_defr_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "19  Avg_pool  mlc_defr_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQbp9tsI6oV1",
        "colab_type": "text"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sGMqk4e6qdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_CNN1D(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,\n",
        "             X_train_emb_fr,y_train_enc_fr,X_val_emb_fr,y_val_enc_fr,X_test_emb_fr,y_test_fr,\n",
        "             class_weight_dict,no):\n",
        "   \n",
        "    idx_fr = np.random.randint(len(X_train_emb_fr), size=no)\n",
        "    idx_de = np.random.randint(len(X_train_emb_de), size=no)\n",
        "\n",
        "    X_train_emb =  np.concatenate((X_train_emb_de[idx_de,:], X_train_emb_fr[idx_fr,:]))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[idx_de,:], y_train_enc_fr[idx_fr,:]))\n",
        "\n",
        "    X_val_emb =  np.concatenate((X_val_emb_de, X_val_emb_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "\n",
        "    dropout_rate= .2\n",
        "    filter_sizes = [3,4,5]\n",
        "    num_filters = 75\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "        maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    #dense_layer = Dense(150,activation='tanh')(falt_layer)\n",
        "\n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    cnn_defr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    cnn_defr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = cnn_defr.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 32, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    task_fr = task + '_fr'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_fr)\n",
        "    fill_df_res(y_pred_test,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_de)\n",
        "    fill_df_res(y_pred_test,y_test_de,no,task_de)\n",
        "\n",
        "    all_tests(cnn_defr,X_test_pad_de,X_test_emb_fr,X_pad_it)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YVW4pTO7rkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fc12db8-94fc-4096-b5f6-f876377aa521"
      },
      "source": [
        "task = 'mlc_defr'\n",
        "model = 'CNN1D'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task_l)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "        task_l = task + '_de'\n",
        "        df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    \n",
        "\n",
        "#for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "for obs in tqdm([250,500,1000,5000]):\n",
        "     run_ml_CNN1D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\\\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\\\n",
        "             class_weight_dict_de_fr,obs)\n",
        "df_results[(df_results['model']==model)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 5.0560 - accuracy: 0.0180 - val_loss: 4.1333 - val_accuracy: 0.0426\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 3.3574 - accuracy: 0.2320 - val_loss: 3.4974 - val_accuracy: 0.2426\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 2.1277 - accuracy: 0.5340 - val_loss: 2.8360 - val_accuracy: 0.4318\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 4s 240ms/step - loss: 0.9893 - accuracy: 0.7840 - val_loss: 2.4116 - val_accuracy: 0.4963\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.4565 - accuracy: 0.9160 - val_loss: 2.2002 - val_accuracy: 0.5701\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.1951 - accuracy: 0.9540 - val_loss: 2.2288 - val_accuracy: 0.5766\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.0958 - accuracy: 0.9800 - val_loss: 2.1366 - val_accuracy: 0.5968\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.0474 - accuracy: 0.9960 - val_loss: 2.1800 - val_accuracy: 0.5952\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.0334 - accuracy: 0.9940 - val_loss: 2.1636 - val_accuracy: 0.6015\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.1574 - val_accuracy: 0.6067\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.6067\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1802 - val_accuracy: 0.6089\n",
            "\n",
            "de 0.6321\n",
            "fr 0.5785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 1/4 [00:48<02:24, 48.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0885\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 5s 169ms/step - loss: 4.4700 - accuracy: 0.0850 - val_loss: 3.6329 - val_accuracy: 0.1781\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 2.7420 - accuracy: 0.4190 - val_loss: 2.3479 - val_accuracy: 0.5154\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 1.2512 - accuracy: 0.7480 - val_loss: 1.7866 - val_accuracy: 0.5725\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 5s 169ms/step - loss: 0.4921 - accuracy: 0.8820 - val_loss: 1.3756 - val_accuracy: 0.7020\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 5s 170ms/step - loss: 0.2015 - accuracy: 0.9530 - val_loss: 1.3450 - val_accuracy: 0.7173\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 5s 166ms/step - loss: 0.0942 - accuracy: 0.9820 - val_loss: 1.3231 - val_accuracy: 0.7329\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 5s 164ms/step - loss: 0.0552 - accuracy: 0.9920 - val_loss: 1.2689 - val_accuracy: 0.7457\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 5s 163ms/step - loss: 0.0245 - accuracy: 0.9950 - val_loss: 1.2667 - val_accuracy: 0.7473\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 5s 168ms/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 1.2846 - val_accuracy: 0.7523\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 5s 166ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.7577\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 5s 164ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 1.2973 - val_accuracy: 0.7561\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 5s 167ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 1.3056 - val_accuracy: 0.7569\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 5s 164ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.7523\n",
            "\n",
            "de 0.7695\n",
            "fr 0.6836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 2/4 [02:03<01:52, 56.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.0645\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 9s 142ms/step - loss: 4.3069 - accuracy: 0.2055 - val_loss: 2.4285 - val_accuracy: 0.4928\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 9s 142ms/step - loss: 1.6367 - accuracy: 0.6640 - val_loss: 1.1678 - val_accuracy: 0.7077\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 9s 141ms/step - loss: 0.6171 - accuracy: 0.8630 - val_loss: 1.0259 - val_accuracy: 0.7531\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 9s 143ms/step - loss: 0.2377 - accuracy: 0.9360 - val_loss: 0.8694 - val_accuracy: 0.8080\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 9s 143ms/step - loss: 0.0868 - accuracy: 0.9770 - val_loss: 0.8530 - val_accuracy: 0.8178\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 9s 141ms/step - loss: 0.0501 - accuracy: 0.9895 - val_loss: 0.8420 - val_accuracy: 0.8306\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 9s 141ms/step - loss: 0.0224 - accuracy: 0.9955 - val_loss: 0.8679 - val_accuracy: 0.8249\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 9s 142ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.8545 - val_accuracy: 0.8350\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 9s 142ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.8638 - val_accuracy: 0.8337\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 9s 150ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.8762 - val_accuracy: 0.8353\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 9s 140ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.8804 - val_accuracy: 0.8364\n",
            "\n",
            "de 0.8489\n",
            "fr 0.771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 3/4 [03:48<01:10, 70.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.09\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 38s 121ms/step - loss: 1.9217 - accuracy: 0.6393 - val_loss: 0.5987 - val_accuracy: 0.8596\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 38s 120ms/step - loss: 0.4634 - accuracy: 0.9073 - val_loss: 0.6216 - val_accuracy: 0.8645\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 38s 121ms/step - loss: 0.2363 - accuracy: 0.9468 - val_loss: 0.5890 - val_accuracy: 0.8962\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 38s 121ms/step - loss: 0.1532 - accuracy: 0.9642 - val_loss: 0.6091 - val_accuracy: 0.9041\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 38s 122ms/step - loss: 0.1185 - accuracy: 0.9732 - val_loss: 0.6738 - val_accuracy: 0.9000\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 38s 121ms/step - loss: 0.1121 - accuracy: 0.9740 - val_loss: 0.7838 - val_accuracy: 0.9041\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 37s 120ms/step - loss: 0.2052 - accuracy: 0.9652 - val_loss: 1.2446 - val_accuracy: 0.8733\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 38s 123ms/step - loss: 0.2163 - accuracy: 0.9611 - val_loss: 1.2148 - val_accuracy: 0.8847\n",
            "\n",
            "de 0.8971\n",
            "fr 0.8451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 4/4 [08:56<00:00, 134.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5785</td>\n",
              "      <td>0.6836</td>\n",
              "      <td>0.771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8451</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6321</td>\n",
              "      <td>0.7695</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8971</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4011</td>\n",
              "      <td>0.5031</td>\n",
              "      <td>0.6477</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5041</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>0.778</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model         task      metric    0  100  ...    5000 10000 15000 25000 40000\n",
              "4  CNN1D  mlc_defr_fr    accuracy  NaN  NaN  ...  0.8451   NaN   NaN   NaN   NaN\n",
              "5  CNN1D  mlc_defr_de    accuracy  NaN  NaN  ...  0.8971   NaN   NaN   NaN   NaN\n",
              "6  CNN1D  mlc_defr_fr  avg_recall  NaN  NaN  ...  0.7339   NaN   NaN   NaN   NaN\n",
              "7  CNN1D  mlc_defr_de  avg_recall  NaN  NaN  ...  0.8391   NaN   NaN   NaN   NaN\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIEiXtGK-k5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "2039cf64-5839-42f6-a6a9-f0bcabc23039"
      },
      "source": [
        "df_results[(df_results['model']==model)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0175</td>\n",
              "      <td>0.7758</td>\n",
              "      <td>0.8217</td>\n",
              "      <td>0.8701</td>\n",
              "      <td>0.9156</td>\n",
              "      <td>0.9415</td>\n",
              "      <td>0.9587</td>\n",
              "      <td>0.9685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.7859</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.9072</td>\n",
              "      <td>0.9497</td>\n",
              "      <td>0.9601</td>\n",
              "      <td>0.9677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>0.4024</td>\n",
              "      <td>0.4774</td>\n",
              "      <td>0.5863</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.8157</td>\n",
              "      <td>0.8582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CNN1D</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0276</td>\n",
              "      <td>0.4118</td>\n",
              "      <td>0.5669</td>\n",
              "      <td>0.6574</td>\n",
              "      <td>0.7735</td>\n",
              "      <td>0.8716</td>\n",
              "      <td>0.9027</td>\n",
              "      <td>0.9131</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    model         task      metric    0  ...   10000   15000 25000 40000\n",
              "20  CNN1D  mlc_defr_fr    accuracy  NaN  ...  0.9587  0.9685   NaN   NaN\n",
              "21  CNN1D  mlc_defr_de    accuracy  NaN  ...  0.9601  0.9677   NaN   NaN\n",
              "22  CNN1D  mlc_defr_fr  avg_recall  NaN  ...  0.8157  0.8582   NaN   NaN\n",
              "23  CNN1D  mlc_defr_de  avg_recall  NaN  ...  0.9027  0.9131   NaN   NaN\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttd51-aRImva",
        "colab_type": "text"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLhlUqCEIl_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_RNN(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,\n",
        "             X_train_emb_fr,y_train_enc_fr,X_val_emb_fr,y_val_enc_fr,X_test_emb_fr,y_test_fr,\n",
        "             class_weight_dict,no):\n",
        "   \n",
        "    idx_fr = np.random.randint(len(X_train_emb_fr), size=no)\n",
        "    idx_de = np.random.randint(len(X_train_emb_de), size=no)\n",
        "\n",
        "    X_train_emb =  np.concatenate((X_train_emb_de[idx_de,:], X_train_emb_fr[idx_fr,:]))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[idx_de,:], y_train_enc_fr[idx_fr,:]))\n",
        "\n",
        "    X_val_emb =  np.concatenate((X_val_emb_de, X_val_emb_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "\n",
        "\n",
        "    dropout_rate= .5\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "\n",
        "    lstm_layer = Bidirectional(LSTM(256,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(embedd_seq)\n",
        "    drop_layer = Dropout(dropout_rate)(lstm_layer)\n",
        "\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    rnn_defr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    rnn_defr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = rnn_defr.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 64, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    task_fr = task + '_fr'\n",
        "    y_pred_test = pred_encode(rnn_defr,X_test_pad_fr)\n",
        "    fill_df_res(y_pred_test,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    y_pred_test = pred_encode(rnn_defr,X_test_pad_de)\n",
        "    fill_df_res(y_pred_test,y_test_de,no,task_de)\n",
        "    all_tests(rnn_defr,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ruYgjaI2Eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d48cab8-16b6-4b03-ba06-8748f585bc1c"
      },
      "source": [
        "task = 'mlc_defr'\n",
        "model = 'RNN'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task_l)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "        task_l = task + '_de'\n",
        "        df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000,10000,15000]):\n",
        "     run_ml_RNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\\\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\\\n",
        "             class_weight_dict_de_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 3.9867 - accuracy: 0.0200 - val_loss: 4.3878 - val_accuracy: 0.0018\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 3.6606 - accuracy: 0.0200 - val_loss: 4.3833 - val_accuracy: 0.0015\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 3.4781 - accuracy: 0.0200 - val_loss: 4.2411 - val_accuracy: 0.0227\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 3.2474 - accuracy: 0.0550 - val_loss: 4.5300 - val_accuracy: 0.0147\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 3.1236 - accuracy: 0.0350 - val_loss: 4.2113 - val_accuracy: 0.0197\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 2.8808 - accuracy: 0.1100 - val_loss: 4.2043 - val_accuracy: 0.0645\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 2.7485 - accuracy: 0.1500 - val_loss: 4.2777 - val_accuracy: 0.0485\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 2.5430 - accuracy: 0.1350 - val_loss: 4.2640 - val_accuracy: 0.0704\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 2.2963 - accuracy: 0.1850 - val_loss: 4.2684 - val_accuracy: 0.0738\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 2.0626 - accuracy: 0.2250 - val_loss: 4.0916 - val_accuracy: 0.1031\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 1.7299 - accuracy: 0.3100 - val_loss: 3.9671 - val_accuracy: 0.2086\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 1.6096 - accuracy: 0.4600 - val_loss: 4.0163 - val_accuracy: 0.1873\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 1.3946 - accuracy: 0.4750 - val_loss: 3.6754 - val_accuracy: 0.2978\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 1.1959 - accuracy: 0.6400 - val_loss: 3.7695 - val_accuracy: 0.3104\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 1.0994 - accuracy: 0.6700 - val_loss: 3.8794 - val_accuracy: 0.2975\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.8512 - accuracy: 0.7550 - val_loss: 3.5709 - val_accuracy: 0.3639\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.7004 - accuracy: 0.8050 - val_loss: 3.4758 - val_accuracy: 0.3717\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.5406 - accuracy: 0.8550 - val_loss: 3.5329 - val_accuracy: 0.3903\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4093 - accuracy: 0.8700 - val_loss: 3.6550 - val_accuracy: 0.3834\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.3661 - accuracy: 0.9100 - val_loss: 3.6296 - val_accuracy: 0.4211\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.3305 - accuracy: 0.9350 - val_loss: 3.5090 - val_accuracy: 0.4571\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.2171 - accuracy: 0.9450 - val_loss: 3.5111 - val_accuracy: 0.4179\n",
            "\n",
            "de 0.3705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 12%|█▎        | 1/8 [00:22<02:35, 22.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.4921\n",
            "it 0.0195\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 3.8734 - accuracy: 0.0060 - val_loss: 4.1604 - val_accuracy: 0.0211\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 1s 106ms/step - loss: 3.6109 - accuracy: 0.0360 - val_loss: 3.9680 - val_accuracy: 0.0641\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 3.3948 - accuracy: 0.0680 - val_loss: 3.6776 - val_accuracy: 0.2430\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 2.9716 - accuracy: 0.3380 - val_loss: 3.0498 - val_accuracy: 0.3704\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 2.2345 - accuracy: 0.4820 - val_loss: 2.5762 - val_accuracy: 0.4893\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 1.7113 - accuracy: 0.6680 - val_loss: 2.2281 - val_accuracy: 0.5431\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 1.3027 - accuracy: 0.7480 - val_loss: 2.2283 - val_accuracy: 0.5273\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 0.8692 - accuracy: 0.8100 - val_loss: 2.1011 - val_accuracy: 0.5827\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.6350 - accuracy: 0.8820 - val_loss: 2.0508 - val_accuracy: 0.5981\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.4757 - accuracy: 0.9000 - val_loss: 1.9712 - val_accuracy: 0.6179\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 0.2956 - accuracy: 0.9480 - val_loss: 2.0690 - val_accuracy: 0.6250\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 0.1886 - accuracy: 0.9660 - val_loss: 1.9931 - val_accuracy: 0.6417\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 0.1510 - accuracy: 0.9700 - val_loss: 2.1780 - val_accuracy: 0.6249\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 1s 106ms/step - loss: 0.0799 - accuracy: 0.9880 - val_loss: 2.1383 - val_accuracy: 0.6474\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.0660 - accuracy: 0.9900 - val_loss: 2.1238 - val_accuracy: 0.6505\n",
            "\n",
            "de 0.6461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 2/8 [00:41<02:07, 21.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.6844\n",
            "it 0.0765\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 4.4437 - accuracy: 0.0130 - val_loss: 4.1510 - val_accuracy: 0.0280\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 3.9886 - accuracy: 0.0820 - val_loss: 3.6369 - val_accuracy: 0.1678\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 3.1069 - accuracy: 0.3340 - val_loss: 2.8393 - val_accuracy: 0.3526\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 2.4013 - accuracy: 0.5320 - val_loss: 1.9950 - val_accuracy: 0.5580\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 1.5226 - accuracy: 0.7180 - val_loss: 1.6138 - val_accuracy: 0.6610\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.9813 - accuracy: 0.8180 - val_loss: 1.4267 - val_accuracy: 0.7056\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.6864 - accuracy: 0.8840 - val_loss: 1.4440 - val_accuracy: 0.7056\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.5576 - accuracy: 0.9090 - val_loss: 1.3222 - val_accuracy: 0.7419\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.3482 - accuracy: 0.9400 - val_loss: 1.3595 - val_accuracy: 0.7464\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.2388 - accuracy: 0.9520 - val_loss: 1.3786 - val_accuracy: 0.7486\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 0.1743 - accuracy: 0.9610 - val_loss: 1.3375 - val_accuracy: 0.7594\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 0.1615 - accuracy: 0.9750 - val_loss: 1.3822 - val_accuracy: 0.7544\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 0.0799 - accuracy: 0.9830 - val_loss: 1.3693 - val_accuracy: 0.7603\n",
            "\n",
            "de 0.761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 3/8 [01:02<01:46, 21.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.7695\n",
            "it 0.054\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 4.1577 - accuracy: 0.0380 - val_loss: 3.5698 - val_accuracy: 0.1983\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 2.9938 - accuracy: 0.4220 - val_loss: 1.7461 - val_accuracy: 0.5606\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 1.9291 - accuracy: 0.6530 - val_loss: 1.2999 - val_accuracy: 0.6826\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 55ms/step - loss: 1.2889 - accuracy: 0.7670 - val_loss: 1.0408 - val_accuracy: 0.7520\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.8797 - accuracy: 0.8475 - val_loss: 0.9014 - val_accuracy: 0.7948\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.6138 - accuracy: 0.8920 - val_loss: 0.8598 - val_accuracy: 0.8029\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.4464 - accuracy: 0.9125 - val_loss: 0.8084 - val_accuracy: 0.8270\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.2711 - accuracy: 0.9455 - val_loss: 0.8289 - val_accuracy: 0.8341\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.1897 - accuracy: 0.9620 - val_loss: 0.8380 - val_accuracy: 0.8398\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.1199 - accuracy: 0.9760 - val_loss: 0.8609 - val_accuracy: 0.8390\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0999 - accuracy: 0.9790 - val_loss: 0.8937 - val_accuracy: 0.8357\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0722 - accuracy: 0.9810 - val_loss: 0.8803 - val_accuracy: 0.8410\n",
            "\n",
            "de 0.8408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 4/8 [01:30<01:33, 23.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.8501\n",
            "it 0.1019\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 3.6665 - accuracy: 0.2562 - val_loss: 1.7175 - val_accuracy: 0.5858\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 1.8765 - accuracy: 0.7197 - val_loss: 0.9203 - val_accuracy: 0.7679\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 1.1488 - accuracy: 0.8240 - val_loss: 0.7416 - val_accuracy: 0.8198\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.7705 - accuracy: 0.8755 - val_loss: 0.6123 - val_accuracy: 0.8518\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.5546 - accuracy: 0.9055 - val_loss: 0.5704 - val_accuracy: 0.8743\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.3475 - accuracy: 0.9373 - val_loss: 0.5641 - val_accuracy: 0.8783\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.2598 - accuracy: 0.9467 - val_loss: 0.5556 - val_accuracy: 0.8820\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1888 - accuracy: 0.9570 - val_loss: 0.5750 - val_accuracy: 0.8871\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1158 - accuracy: 0.9737 - val_loss: 0.6192 - val_accuracy: 0.8795\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1239 - accuracy: 0.9710 - val_loss: 0.5800 - val_accuracy: 0.8911\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0906 - accuracy: 0.9785 - val_loss: 0.5916 - val_accuracy: 0.8889\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0747 - accuracy: 0.9822 - val_loss: 0.5902 - val_accuracy: 0.8947\n",
            "\n",
            "de 0.908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 62%|██████▎   | 5/8 [02:13<01:27, 29.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.8932\n",
            "it 0.1154\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 8s 50ms/step - loss: 2.7792 - accuracy: 0.5029 - val_loss: 0.8276 - val_accuracy: 0.8045\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 1.2012 - accuracy: 0.8375 - val_loss: 0.5265 - val_accuracy: 0.8705\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.7370 - accuracy: 0.8980 - val_loss: 0.4202 - val_accuracy: 0.8998\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.4980 - accuracy: 0.9321 - val_loss: 0.4088 - val_accuracy: 0.9084\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.3354 - accuracy: 0.9450 - val_loss: 0.4230 - val_accuracy: 0.9069\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.2519 - accuracy: 0.9577 - val_loss: 0.3873 - val_accuracy: 0.9232\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.1948 - accuracy: 0.9676 - val_loss: 0.3942 - val_accuracy: 0.9260\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.1256 - accuracy: 0.9753 - val_loss: 0.4051 - val_accuracy: 0.9263\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 7s 44ms/step - loss: 0.0807 - accuracy: 0.9825 - val_loss: 0.4256 - val_accuracy: 0.9285\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0811 - accuracy: 0.9848 - val_loss: 0.4329 - val_accuracy: 0.9265\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.0642 - accuracy: 0.9866 - val_loss: 0.4317 - val_accuracy: 0.9316\n",
            "\n",
            "de 0.9413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 6/8 [03:35<01:29, 44.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.9229\n",
            "it 0.1409\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 1.9794 - accuracy: 0.6641 - val_loss: 0.4940 - val_accuracy: 0.8714\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.7463 - accuracy: 0.8820 - val_loss: 0.4152 - val_accuracy: 0.9032\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.4134 - accuracy: 0.9319 - val_loss: 0.3451 - val_accuracy: 0.9235\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.2747 - accuracy: 0.9510 - val_loss: 0.3242 - val_accuracy: 0.9331\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1972 - accuracy: 0.9651 - val_loss: 0.3126 - val_accuracy: 0.9368\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1338 - accuracy: 0.9738 - val_loss: 0.3232 - val_accuracy: 0.9427\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.1236 - accuracy: 0.9765 - val_loss: 0.3294 - val_accuracy: 0.9447\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.0927 - accuracy: 0.9806 - val_loss: 0.3523 - val_accuracy: 0.9399\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.0737 - accuracy: 0.9829 - val_loss: 0.3480 - val_accuracy: 0.9452\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.0645 - accuracy: 0.9858 - val_loss: 0.3456 - val_accuracy: 0.9465\n",
            "\n",
            "de 0.9583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 7/8 [05:50<01:12, 72.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.9436\n",
            "it 0.1289\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 1.5774 - accuracy: 0.7312 - val_loss: 0.4330 - val_accuracy: 0.8957\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.5231 - accuracy: 0.9154 - val_loss: 0.2994 - val_accuracy: 0.9296\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.2690 - accuracy: 0.9512 - val_loss: 0.2794 - val_accuracy: 0.9402\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1681 - accuracy: 0.9669 - val_loss: 0.2950 - val_accuracy: 0.9414\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1314 - accuracy: 0.9724 - val_loss: 0.2691 - val_accuracy: 0.9529\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1004 - accuracy: 0.9792 - val_loss: 0.2904 - val_accuracy: 0.9474\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0970 - accuracy: 0.9800 - val_loss: 0.2943 - val_accuracy: 0.9509\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0777 - accuracy: 0.9828 - val_loss: 0.3132 - val_accuracy: 0.9481\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0647 - accuracy: 0.9853 - val_loss: 0.3258 - val_accuracy: 0.9496\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0696 - accuracy: 0.9844 - val_loss: 0.3363 - val_accuracy: 0.9527\n",
            "\n",
            "de 0.9603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 8/8 [09:12<00:00, 69.06s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.951\n",
            "it 0.1724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.4973</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.8752</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.9451</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>0.9464</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RNN</td>\n",
              "      <td>slc_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.2888</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.7455</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.8722</td>\n",
              "      <td>0.8921</td>\n",
              "      <td>0.888</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4921</td>\n",
              "      <td>0.6844</td>\n",
              "      <td>0.7695</td>\n",
              "      <td>0.8501</td>\n",
              "      <td>0.8932</td>\n",
              "      <td>0.9229</td>\n",
              "      <td>0.9436</td>\n",
              "      <td>0.951</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3705</td>\n",
              "      <td>0.6461</td>\n",
              "      <td>0.761</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.9413</td>\n",
              "      <td>0.9583</td>\n",
              "      <td>0.9603</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1816</td>\n",
              "      <td>0.3354</td>\n",
              "      <td>0.4159</td>\n",
              "      <td>0.5733</td>\n",
              "      <td>0.6607</td>\n",
              "      <td>0.7299</td>\n",
              "      <td>0.7877</td>\n",
              "      <td>0.82</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>RNN</td>\n",
              "      <td>mlc_defr_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1759</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.5541</td>\n",
              "      <td>0.6708</td>\n",
              "      <td>0.7781</td>\n",
              "      <td>0.8438</td>\n",
              "      <td>0.8946</td>\n",
              "      <td>0.9001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model         task      metric    0  ...   10000   15000   25000 40000\n",
              "8    RNN       slc_de    accuracy  NaN  ...  0.9451  0.9527  0.9464   NaN\n",
              "9    RNN       slc_de  avg_recall  NaN  ...  0.8722  0.8921   0.888   NaN\n",
              "24   RNN  mlc_defr_fr    accuracy  NaN  ...  0.9436   0.951     NaN   NaN\n",
              "25   RNN  mlc_defr_de    accuracy  NaN  ...  0.9583  0.9603     NaN   NaN\n",
              "26   RNN  mlc_defr_fr  avg_recall  NaN  ...  0.7877    0.82     NaN   NaN\n",
              "27   RNN  mlc_defr_de  avg_recall  NaN  ...  0.8946  0.9001     NaN   NaN\n",
              "\n",
              "[6 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsR1Coq2ftOP",
        "colab_type": "text"
      },
      "source": [
        "# Final Model + Transfer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsxOpqbVwN4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_df_res(y,pred,no):\n",
        "    print(round(accuracy_score(pred, y),4))\n",
        "    print(round(balanced_accuracy_score(pred, y)*len(np.unique(pred))/no_Classes,4))\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(pred, y),4)\n",
        "    df_results[str(no)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(pred, y)*len(np.unique(pred))/no_Classes,4)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1lnRcpAx6W2",
        "colab_type": "text"
      },
      "source": [
        "## LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHVvNSfXwsal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a79db35f-f383-497d-f003-7182a18c82da"
      },
      "source": [
        "\n",
        "X_train = [str(x) for x in X_train_de]\n",
        "y_train = y_train_de\n",
        "X_test = [str(x) for x in X_test_fr]\n",
        "vectorizer  = TfidfVectorizer()\n",
        "vectorizer.fit(X_train)\n",
        "X_train_vec = vectorizer.transform(X_train)\n",
        "X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "logreg = LogisticRegression(C=1,max_iter=500, solver='newton-cg')\n",
        "logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_train = logreg.predict(X_train_vec)\n",
        "y_pred_test = logreg.predict(X_test_vec)\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4),round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1387 0.1448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8IGGD8jXTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transfer_cnn(model_base,model_str,few_shot,freeze,opt=opt):\n",
        "\n",
        "    model_base.load_weights(path+'/model/'+model_str)\n",
        "\n",
        "    #opt = Adam(lr=lr, decay=lr/100)\n",
        "    inp = model_base.input\n",
        "    out = model_base.output #get_layer('output_de').output\n",
        "\n",
        "    # create a new network between inp and out\n",
        "    model_transfer = Model(inp, out)    \n",
        "\n",
        "    model_transfer.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 2)\n",
        "    #freeze\n",
        "    for l , layer in enumerate(model_transfer.layers[:-2]):\n",
        "        model_transfer.layers[l].trainable = (freeze==False)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_pad_fr), size=few_shot)\n",
        "    bs = 2** (few_shot // 500 //2) *2\n",
        "    model_transfer.fit(x = X_train_pad_fr[idx,:], y = y_train_enc_fr[idx,:],\\\n",
        "                    validation_data = (X_val_pad_fr, y_val_enc_fr), \\\n",
        "                    epochs = 150, batch_size = bs, shuffle = True, \\\n",
        "                    class_weight = class_weight_dict_fr, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    print(few_shot,bs)\n",
        "    print(model_transfer.summary())\n",
        "    #all_tests(model_transfer,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test_fr = model_transfer.predict(X_test_pad_fr)\n",
        "    y_pred_arg_fr = y_pred_test_fr.argmax(axis=1)\n",
        "    y_pred_test_fr = [encoder.classes_[y] for y in y_pred_arg_fr]\n",
        "    fill_df_res(y_pred_test_fr,y_test_fr,few_shot,task)\n",
        "\n",
        "    #df_results[str(few_shot)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test_fr, y_test_fr),4)\n",
        "    #df_results[str(few_shot)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test_fr, y_test_fr),4)\n",
        "\n",
        "    print(all_tests(model_transfer,X_test_pad_de,X_test_pad_fr,X_pad_it,y_it))"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Zi_3ix4Gml",
        "colab_type": "text"
      },
      "source": [
        "## Pool FE DE - FR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eomE7bud0Nhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "b0383a5c-7c08-4d94-be16-113826866bea"
      },
      "source": [
        "dropout_rate= .4\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/150)\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "pool_layer = GlobalAveragePooling1D()(embedd_seq)   \n",
        "drop_layer = Dropout(dropout_rate)(pool_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_avg_pool = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_avg_pool.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 2)\n",
        "print(X_train_pad_de.shape)\n",
        "hist = de_avg_pool.fit(x = X_train_pad_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_pad_de, y_val_enc_de), \\\n",
        "                epochs = 150, batch_size = 256, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "print(de_avg_pool.summary())\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_avg_pool.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "round(accuracy_score(y_pred_test, y_test_fr),4)\n",
        "round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4)\n",
        "\n",
        "all_tests(de_avg_pool,X_test_pad_de,X_test_pad_fr,X_pad_it,y_it)\n",
        "#all_tests(de_avg_pool,X_test_pad_de,X_test_pad_fr,X_it,y_it)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23597, 34)\n",
            "Epoch 1/150\n",
            "93/93 [==============================] - 8s 84ms/step - loss: 3.6578 - accuracy: 0.5323 - val_loss: 1.2810 - val_accuracy: 0.8055\n",
            "Epoch 2/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 1.3629 - accuracy: 0.8732 - val_loss: 0.4418 - val_accuracy: 0.9148\n",
            "Epoch 3/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.5597 - accuracy: 0.9347 - val_loss: 0.2587 - val_accuracy: 0.9484\n",
            "Epoch 4/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.3150 - accuracy: 0.9611 - val_loss: 0.1886 - val_accuracy: 0.9601\n",
            "Epoch 5/150\n",
            "93/93 [==============================] - 8s 84ms/step - loss: 0.2089 - accuracy: 0.9733 - val_loss: 0.1556 - val_accuracy: 0.9654\n",
            "Epoch 6/150\n",
            "93/93 [==============================] - 8s 85ms/step - loss: 0.1508 - accuracy: 0.9814 - val_loss: 0.1347 - val_accuracy: 0.9697\n",
            "Epoch 7/150\n",
            "93/93 [==============================] - 8s 85ms/step - loss: 0.1160 - accuracy: 0.9848 - val_loss: 0.1242 - val_accuracy: 0.9713\n",
            "Epoch 8/150\n",
            "93/93 [==============================] - 8s 82ms/step - loss: 0.0940 - accuracy: 0.9874 - val_loss: 0.1153 - val_accuracy: 0.9746\n",
            "Epoch 9/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0768 - accuracy: 0.9905 - val_loss: 0.1124 - val_accuracy: 0.9743\n",
            "Epoch 10/150\n",
            "93/93 [==============================] - 8s 82ms/step - loss: 0.0626 - accuracy: 0.9921 - val_loss: 0.1067 - val_accuracy: 0.9756\n",
            "Epoch 11/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0538 - accuracy: 0.9926 - val_loss: 0.1054 - val_accuracy: 0.9769\n",
            "Epoch 12/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0484 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9769\n",
            "Epoch 13/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0413 - accuracy: 0.9945 - val_loss: 0.1008 - val_accuracy: 0.9781\n",
            "Epoch 14/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0359 - accuracy: 0.9946 - val_loss: 0.1012 - val_accuracy: 0.9769\n",
            "Epoch 15/150\n",
            "93/93 [==============================] - 8s 83ms/step - loss: 0.0311 - accuracy: 0.9957 - val_loss: 0.1020 - val_accuracy: 0.9761\n",
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9758\n",
            "fr 0.4011\n",
            "it 0.2054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDLmzyI8-ivZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68c5e523-dc97-4bd8-c40d-e683dd69331f"
      },
      "source": [
        "\n",
        "y_pred_test = de_avg_pool.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_fr))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4011\n",
            "0.3241\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       0.43      0.94      0.59        17\n",
            "                                        1112_Flours and other cereals       0.00      0.00      0.00        22\n",
            "                                                           1113_Bread       0.27      0.71      0.39        21\n",
            "                                           1114_Other bakery products       0.28      0.36      0.31        44\n",
            "                                                1115_Pizza and quiche       0.91      0.71      0.80        28\n",
            "                                     1116_Pasta products and couscous       0.53      0.67      0.59        90\n",
            "                                               1117_Breakfast cereals       0.39      0.95      0.55        22\n",
            "                                           1118_Other cereal products       0.00      0.00      0.00        42\n",
            "                                                   1121_Beef and veal       0.36      0.75      0.49        16\n",
            "                                                            1122_Pork       0.00      0.00      0.00         1\n",
            "                                                   1123_Lamb and goat       0.00      0.00      0.00         0\n",
            "                                                         1124_Poultry       0.00      0.00      0.00         0\n",
            "                                                     1125_Other meats       0.00      0.00      0.00         0\n",
            "                                                    1126_Edible offal       0.00      0.00      0.00         0\n",
            "                                    1127_Dried, salted or smoked meat       0.20      0.36      0.26        11\n",
            "                                         1128_Other meat preparations       0.00      0.00      0.00        18\n",
            "                                                     1132_Frozen fish       0.83      0.24      0.37        21\n",
            "                                        1133_Fresh or chilled seafood       0.00      0.00      0.00        32\n",
            "                                                  1134_Frozen seafood       0.00      0.00      0.00         5\n",
            "                        1135_Dried, smoked or salted fish and seafood       0.00      0.00      0.00         0\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.06      0.08      0.07        12\n",
            "                                                1141_Fresh whole milk       0.00      0.00      0.00        13\n",
            "                                              1142_Fresh low fat milk       0.02      0.33      0.03         3\n",
            "                                                  1143_Preserved milk       0.00      0.00      0.00         9\n",
            "                                                         1144_Yoghurt       0.01      1.00      0.03         1\n",
            "                                                 1145_Cheese and curd       0.04      0.92      0.07        13\n",
            "                                             1146_Other milk products       0.33      0.03      0.06       192\n",
            "                                                            1147_Eggs       0.00      0.00      0.00         0\n",
            "                                                          1151_Butter       0.00      0.00      0.00         1\n",
            "                              1152_Margarine and other vegetable fats       0.91      0.55      0.69        38\n",
            "                                                       1153_Olive oil       0.12      1.00      0.22         4\n",
            "                                               1154_Other edible oils       0.00      0.00      0.00         0\n",
            "                                        1155_Other edible animal fats       0.00      0.00      0.00       445\n",
            "                                          1161_Fresh or chilled fruit       0.00      0.00      0.00         4\n",
            "                                                    1162_Frozen fruit       1.00      0.06      0.11        34\n",
            "                                            1163_Dried fruit and nuts       0.00      0.00      0.00         3\n",
            "                        1164_Preserved fruit and fruit-based products       0.06      1.00      0.11         1\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       0.11      0.33      0.17         3\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.14      1.00      0.25         1\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.04      1.00      0.08         1\n",
            "                                                        1174_Potatoes       0.67      0.20      0.31        20\n",
            "                                                          1175_Crisps       0.99      0.99      0.99        74\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00        18\n",
            "                                                           1181_Sugar       0.00      0.00      0.00         0\n",
            "                                      1182_Jams, marmalades and honey       0.16      0.15      0.16        26\n",
            "                                                       1183_Chocolate       0.17      0.76      0.28        51\n",
            "                                          1184_Confectionery products       0.72      0.68      0.70        68\n",
            "                                       1185_Edible ices and ice cream       0.14      1.00      0.24         5\n",
            "                                    1186_Artificial sugar substitutes       0.00      0.00      0.00         2\n",
            "                                              1191_Sauces, condiments       0.48      0.67      0.56        15\n",
            "                                 1192_Salt, spices and culinary herbs       0.74      0.49      0.59        35\n",
            "                                                       1193_Baby food       0.00      0.00      0.00         1\n",
            "                                                1194_Ready-made meals       0.03      0.01      0.02        99\n",
            "                                      1199_Other food products n.e.c.       0.25      0.05      0.08       111\n",
            "                                                          1211_Coffee       0.98      0.97      0.98       233\n",
            "                                                             1212_Tea       0.00      0.00      0.00         0\n",
            "                                    1213_Cocoa and powdered chocolate       0.38      0.67      0.48         9\n",
            "                                        1221_Mineral or spring waters       0.31      0.67      0.42         6\n",
            "                                                     1222_Soft drinks       0.99      0.78      0.87        95\n",
            "                                      1223_Fruit and vegetable juices       0.10      0.32      0.16        38\n",
            "                                            2111_Spirits and liqueurs       0.56      0.45      0.50        20\n",
            "                                           2112_Alcoholic soft drinks       0.00      0.00      0.00         0\n",
            "                                                2121_Wine from grapes       0.99      0.81      0.89       378\n",
            "                                          2122_Wine from other fruits       0.80      0.20      0.32        20\n",
            "                                                 2123_Fortified wines       0.00      0.00      0.00        44\n",
            "                                               2124_Wine-based drinks       0.00      0.00      0.00         5\n",
            "                                                      2131_Lager beer       0.50      0.38      0.43        13\n",
            "                                            2132_Other alcoholic beer       0.00      0.00      0.00        18\n",
            "                                      2133_Low and non-alcoholic beer       0.00      0.00      0.00         1\n",
            "                                               2134_Beer-based drinks       0.11      0.33      0.17         3\n",
            "                                                      2201_Cigarettes       0.00      0.00      0.00         1\n",
            "                                                          2202_Cigars       0.00      0.00      0.00        26\n",
            "                                          2203_Other tobacco products       0.00      0.00      0.00       151\n",
            "                                                        9999_Non-Food       0.39      0.71      0.51       101\n",
            "\n",
            "                                                             accuracy                           0.40      2855\n",
            "                                                            macro avg       0.24      0.33      0.21      2855\n",
            "                                                         weighted avg       0.44      0.40      0.39      2855\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPRi8zjqDumO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "de_avg_pool.save_weights(path+'/model/de_avg_pool')\n",
        "de_avg_pool.save(path+'/model/de_avg_pool.h5')"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3RFTOH_13v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b638c661-c4f0-4c10-857d-955b69bca5f0"
      },
      "source": [
        "# run transfer\n",
        "task = 'slc_de_tf_fr'\n",
        "model = 'avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(de_avg_pool,'de_avg_pool',obs,freeze=False)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "50/50 [==============================] - 5s 100ms/step - loss: 4.9779 - accuracy: 0.4700 - val_loss: 1.6631 - val_accuracy: 0.6857\n",
            "Epoch 2/150\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.5832 - accuracy: 0.9200 - val_loss: 1.5791 - val_accuracy: 0.7085\n",
            "Epoch 3/150\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.7155\n",
            "Epoch 4/150\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.5180 - val_accuracy: 0.7200\n",
            "Epoch 5/150\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.5203 - val_accuracy: 0.7256\n",
            "Epoch 6/150\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5198 - val_accuracy: 0.7228\n",
            "100 2\n",
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9413\n",
            "fr 0.7292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [00:31<02:36, 31.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1079\n",
            "None\n",
            "Epoch 1/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.7070 - accuracy: 0.5480 - val_loss: 1.2311 - val_accuracy: 0.7270\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.4997 - accuracy: 0.8920 - val_loss: 1.0130 - val_accuracy: 0.8041\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0936 - accuracy: 0.9600 - val_loss: 0.9999 - val_accuracy: 0.8003\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.9998 - val_accuracy: 0.8003\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.7947\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 0.8031\n",
            "250 2\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [01:34<02:43, 40.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9596\n",
            "fr 0.7989\n",
            "it 0.1304\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 20s 79ms/step - loss: 3.0674 - accuracy: 0.7120 - val_loss: 0.9097 - val_accuracy: 0.8129\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 0.3592 - accuracy: 0.9500 - val_loss: 0.7853 - val_accuracy: 0.8490\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 0.0707 - accuracy: 0.9900 - val_loss: 0.7654 - val_accuracy: 0.8539\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: 0.7547 - val_accuracy: 0.8535\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8546\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.8521\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 19s 74ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8595\n",
            "500 2\n",
            "Model: \"model_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9476\n",
            "fr 0.8609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [03:48<03:26, 68.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1259\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 2.0305 - accuracy: 0.7830 - val_loss: 0.6905 - val_accuracy: 0.8686\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.2163 - accuracy: 0.9650 - val_loss: 0.6514 - val_accuracy: 0.8725\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.6204 - val_accuracy: 0.8774\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0202 - accuracy: 0.9920 - val_loss: 0.6247 - val_accuracy: 0.8795\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6180 - val_accuracy: 0.8830\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8826\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.6220 - val_accuracy: 0.8844\n",
            "1000 4\n",
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [05:57<02:53, 86.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9619\n",
            "fr 0.8942\n",
            "it 0.2159\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 1.9639 - accuracy: 0.8185 - val_loss: 0.5974 - val_accuracy: 0.8577\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.3512 - accuracy: 0.9525 - val_loss: 0.4756 - val_accuracy: 0.9057\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0863 - accuracy: 0.9835 - val_loss: 0.4416 - val_accuracy: 0.9075\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0350 - accuracy: 0.9955 - val_loss: 0.4358 - val_accuracy: 0.9124\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.0193 - accuracy: 0.9985 - val_loss: 0.4385 - val_accuracy: 0.9124\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.4412 - val_accuracy: 0.9138\n",
            "2000 8\n",
            "Model: \"model_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [07:44<01:33, 93.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.957\n",
            "fr 0.9166\n",
            "it 0.1499\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.4473 - accuracy: 0.8436 - val_loss: 0.4746 - val_accuracy: 0.8938\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.2339 - accuracy: 0.9604 - val_loss: 0.3605 - val_accuracy: 0.9222\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0848 - accuracy: 0.9820 - val_loss: 0.3308 - val_accuracy: 0.9306\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0487 - accuracy: 0.9914 - val_loss: 0.3217 - val_accuracy: 0.9348\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0344 - accuracy: 0.9942 - val_loss: 0.3234 - val_accuracy: 0.9338\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0298 - accuracy: 0.9948 - val_loss: 0.3238 - val_accuracy: 0.9359\n",
            "5000 64\n",
            "Model: \"model_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [08:21<00:00, 83.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9603\n",
            "fr 0.9426\n",
            "it 0.2789\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7292</td>\n",
              "      <td>0.7989</td>\n",
              "      <td>0.8609</td>\n",
              "      <td>0.8942</td>\n",
              "      <td>0.9166</td>\n",
              "      <td>0.9426</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3923</td>\n",
              "      <td>0.4596</td>\n",
              "      <td>0.5774</td>\n",
              "      <td>0.6134</td>\n",
              "      <td>0.7026</td>\n",
              "      <td>0.7733</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model          task      metric    0  ... 10000 15000 25000 40000\n",
              "0  avg_pool  slc_de_tf_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "1  avg_pool  slc_de_tf_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeMzPohd3-kd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f635949c-2c9e-4a93-e50f-93e3c4bf24bd"
      },
      "source": [
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "dropout_rate= .3\n",
        "lr = .0005\n",
        "opt = Adam(lr=lr, decay=lr/150)\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "sdo = SpatialDropout1D(dropout_rate)(embedd_seq)\n",
        "pool_layer = GlobalAveragePooling1D()(sdo)   \n",
        "drop_layer = Dropout(dropout_rate)(pool_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_avg_pool = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_avg_pool.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 2)\n",
        "print(X_train_pad_de.shape)\n",
        "hist = de_avg_pool.fit(x = X_train_pad_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_pad_de, y_val_enc_de), \\\n",
        "                epochs = 150, batch_size = 256, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "print(de_avg_pool.summary())\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_avg_pool.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "round(accuracy_score(y_pred_test, y_test_fr),4)\n",
        "round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4)\n",
        "\n",
        "all_tests(de_avg_pool,X_test_pad_de,X_test_pad_fr,X_pad_it,y_it)\n",
        "#all_tests(de_avg_pool,X_test_pad_de,X_test_pad_fr,X_it,y_it)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23597, 34)\n",
            "Epoch 1/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 4.5451 - accuracy: 0.2334 - val_loss: 4.0668 - val_accuracy: 0.3448\n",
            "Epoch 2/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 4.4005 - accuracy: 0.3733 - val_loss: 3.8489 - val_accuracy: 0.4444\n",
            "Epoch 3/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 4.2267 - accuracy: 0.4725 - val_loss: 3.4945 - val_accuracy: 0.5167\n",
            "Epoch 4/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 4.0060 - accuracy: 0.5491 - val_loss: 3.0322 - val_accuracy: 0.5891\n",
            "Epoch 5/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 3.7392 - accuracy: 0.6119 - val_loss: 2.6132 - val_accuracy: 0.6417\n",
            "Epoch 6/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 3.4404 - accuracy: 0.6681 - val_loss: 2.2521 - val_accuracy: 0.6921\n",
            "Epoch 7/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 3.1217 - accuracy: 0.7103 - val_loss: 1.9364 - val_accuracy: 0.7465\n",
            "Epoch 8/150\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 2.8017 - accuracy: 0.7533 - val_loss: 1.6650 - val_accuracy: 0.7869\n",
            "Epoch 9/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 2.5010 - accuracy: 0.7916 - val_loss: 1.4427 - val_accuracy: 0.8116\n",
            "Epoch 10/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 2.2364 - accuracy: 0.8135 - val_loss: 1.2574 - val_accuracy: 0.8281\n",
            "Epoch 11/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 2.0001 - accuracy: 0.8342 - val_loss: 1.1098 - val_accuracy: 0.8441\n",
            "Epoch 12/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.7955 - accuracy: 0.8519 - val_loss: 0.9854 - val_accuracy: 0.8581\n",
            "Epoch 13/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.6127 - accuracy: 0.8665 - val_loss: 0.8801 - val_accuracy: 0.8719\n",
            "Epoch 14/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.4512 - accuracy: 0.8768 - val_loss: 0.7899 - val_accuracy: 0.8856\n",
            "Epoch 15/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.3039 - accuracy: 0.8885 - val_loss: 0.7113 - val_accuracy: 0.8963\n",
            "Epoch 16/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.1798 - accuracy: 0.8971 - val_loss: 0.6460 - val_accuracy: 0.9013\n",
            "Epoch 17/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 1.0751 - accuracy: 0.9049 - val_loss: 0.5908 - val_accuracy: 0.9080\n",
            "Epoch 18/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.9761 - accuracy: 0.9113 - val_loss: 0.5427 - val_accuracy: 0.9113\n",
            "Epoch 19/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.9000 - accuracy: 0.9155 - val_loss: 0.4997 - val_accuracy: 0.9138\n",
            "Epoch 20/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.8187 - accuracy: 0.9200 - val_loss: 0.4626 - val_accuracy: 0.9166\n",
            "Epoch 21/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.7528 - accuracy: 0.9260 - val_loss: 0.4292 - val_accuracy: 0.9212\n",
            "Epoch 22/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.6993 - accuracy: 0.9291 - val_loss: 0.4029 - val_accuracy: 0.9227\n",
            "Epoch 23/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.6452 - accuracy: 0.9322 - val_loss: 0.3772 - val_accuracy: 0.9273\n",
            "Epoch 24/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.6035 - accuracy: 0.9348 - val_loss: 0.3544 - val_accuracy: 0.9329\n",
            "Epoch 25/150\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.5598 - accuracy: 0.9380 - val_loss: 0.3346 - val_accuracy: 0.9347\n",
            "Epoch 26/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.5243 - accuracy: 0.9412 - val_loss: 0.3172 - val_accuracy: 0.9387\n",
            "Epoch 27/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.4933 - accuracy: 0.9451 - val_loss: 0.3002 - val_accuracy: 0.9405\n",
            "Epoch 28/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.4616 - accuracy: 0.9472 - val_loss: 0.2860 - val_accuracy: 0.9428\n",
            "Epoch 29/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.4336 - accuracy: 0.9507 - val_loss: 0.2729 - val_accuracy: 0.9461\n",
            "Epoch 30/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.4093 - accuracy: 0.9524 - val_loss: 0.2616 - val_accuracy: 0.9499\n",
            "Epoch 31/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.3843 - accuracy: 0.9561 - val_loss: 0.2505 - val_accuracy: 0.9517\n",
            "Epoch 32/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.3669 - accuracy: 0.9575 - val_loss: 0.2396 - val_accuracy: 0.9530\n",
            "Epoch 33/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.3461 - accuracy: 0.9596 - val_loss: 0.2320 - val_accuracy: 0.9550\n",
            "Epoch 34/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.3299 - accuracy: 0.9600 - val_loss: 0.2234 - val_accuracy: 0.9565\n",
            "Epoch 35/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.3116 - accuracy: 0.9635 - val_loss: 0.2157 - val_accuracy: 0.9558\n",
            "Epoch 36/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.2964 - accuracy: 0.9654 - val_loss: 0.2095 - val_accuracy: 0.9575\n",
            "Epoch 37/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.2854 - accuracy: 0.9658 - val_loss: 0.2014 - val_accuracy: 0.9596\n",
            "Epoch 38/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.2709 - accuracy: 0.9675 - val_loss: 0.1961 - val_accuracy: 0.9606\n",
            "Epoch 39/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.2569 - accuracy: 0.9687 - val_loss: 0.1906 - val_accuracy: 0.9624\n",
            "Epoch 40/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.2454 - accuracy: 0.9711 - val_loss: 0.1848 - val_accuracy: 0.9629\n",
            "Epoch 41/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.2398 - accuracy: 0.9705 - val_loss: 0.1800 - val_accuracy: 0.9624\n",
            "Epoch 42/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.2259 - accuracy: 0.9716 - val_loss: 0.1751 - val_accuracy: 0.9634\n",
            "Epoch 43/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.2172 - accuracy: 0.9737 - val_loss: 0.1716 - val_accuracy: 0.9649\n",
            "Epoch 44/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.2073 - accuracy: 0.9744 - val_loss: 0.1679 - val_accuracy: 0.9649\n",
            "Epoch 45/150\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.1988 - accuracy: 0.9747 - val_loss: 0.1637 - val_accuracy: 0.9652\n",
            "Epoch 46/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1923 - accuracy: 0.9749 - val_loss: 0.1595 - val_accuracy: 0.9667\n",
            "Epoch 47/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1841 - accuracy: 0.9771 - val_loss: 0.1560 - val_accuracy: 0.9664\n",
            "Epoch 48/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1806 - accuracy: 0.9778 - val_loss: 0.1532 - val_accuracy: 0.9680\n",
            "Epoch 49/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.1711 - accuracy: 0.9785 - val_loss: 0.1500 - val_accuracy: 0.9680\n",
            "Epoch 50/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.1653 - accuracy: 0.9794 - val_loss: 0.1472 - val_accuracy: 0.9682\n",
            "Epoch 51/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1580 - accuracy: 0.9802 - val_loss: 0.1444 - val_accuracy: 0.9682\n",
            "Epoch 52/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.1533 - accuracy: 0.9808 - val_loss: 0.1416 - val_accuracy: 0.9682\n",
            "Epoch 53/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1477 - accuracy: 0.9810 - val_loss: 0.1392 - val_accuracy: 0.9697\n",
            "Epoch 54/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1418 - accuracy: 0.9816 - val_loss: 0.1372 - val_accuracy: 0.9697\n",
            "Epoch 55/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1397 - accuracy: 0.9827 - val_loss: 0.1350 - val_accuracy: 0.9708\n",
            "Epoch 56/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.1323 - accuracy: 0.9831 - val_loss: 0.1332 - val_accuracy: 0.9710\n",
            "Epoch 57/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.1297 - accuracy: 0.9839 - val_loss: 0.1314 - val_accuracy: 0.9705\n",
            "Epoch 58/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1240 - accuracy: 0.9841 - val_loss: 0.1294 - val_accuracy: 0.9708\n",
            "Epoch 59/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1214 - accuracy: 0.9832 - val_loss: 0.1274 - val_accuracy: 0.9705\n",
            "Epoch 60/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.1160 - accuracy: 0.9847 - val_loss: 0.1258 - val_accuracy: 0.9708\n",
            "Epoch 61/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1123 - accuracy: 0.9851 - val_loss: 0.1244 - val_accuracy: 0.9710\n",
            "Epoch 62/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1108 - accuracy: 0.9854 - val_loss: 0.1230 - val_accuracy: 0.9718\n",
            "Epoch 63/150\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.1057 - accuracy: 0.9862 - val_loss: 0.1219 - val_accuracy: 0.9723\n",
            "Epoch 64/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.1039 - accuracy: 0.9868 - val_loss: 0.1203 - val_accuracy: 0.9723\n",
            "Epoch 65/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.1018 - accuracy: 0.9861 - val_loss: 0.1190 - val_accuracy: 0.9720\n",
            "Epoch 66/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0976 - accuracy: 0.9869 - val_loss: 0.1179 - val_accuracy: 0.9725\n",
            "Epoch 67/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0944 - accuracy: 0.9883 - val_loss: 0.1166 - val_accuracy: 0.9730\n",
            "Epoch 68/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0927 - accuracy: 0.9872 - val_loss: 0.1154 - val_accuracy: 0.9728\n",
            "Epoch 69/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0880 - accuracy: 0.9885 - val_loss: 0.1143 - val_accuracy: 0.9730\n",
            "Epoch 70/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0851 - accuracy: 0.9890 - val_loss: 0.1135 - val_accuracy: 0.9736\n",
            "Epoch 71/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0836 - accuracy: 0.9890 - val_loss: 0.1122 - val_accuracy: 0.9738\n",
            "Epoch 72/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0825 - accuracy: 0.9893 - val_loss: 0.1120 - val_accuracy: 0.9738\n",
            "Epoch 73/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0802 - accuracy: 0.9892 - val_loss: 0.1109 - val_accuracy: 0.9743\n",
            "Epoch 74/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0775 - accuracy: 0.9903 - val_loss: 0.1097 - val_accuracy: 0.9743\n",
            "Epoch 75/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0750 - accuracy: 0.9905 - val_loss: 0.1088 - val_accuracy: 0.9748\n",
            "Epoch 76/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0727 - accuracy: 0.9900 - val_loss: 0.1082 - val_accuracy: 0.9746\n",
            "Epoch 77/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0706 - accuracy: 0.9908 - val_loss: 0.1077 - val_accuracy: 0.9746\n",
            "Epoch 78/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0694 - accuracy: 0.9910 - val_loss: 0.1068 - val_accuracy: 0.9746\n",
            "Epoch 79/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0689 - accuracy: 0.9919 - val_loss: 0.1064 - val_accuracy: 0.9751\n",
            "Epoch 80/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0643 - accuracy: 0.9913 - val_loss: 0.1053 - val_accuracy: 0.9748\n",
            "Epoch 81/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0646 - accuracy: 0.9916 - val_loss: 0.1051 - val_accuracy: 0.9748\n",
            "Epoch 82/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 0.0636 - accuracy: 0.9918 - val_loss: 0.1045 - val_accuracy: 0.9751\n",
            "Epoch 83/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 0.0607 - accuracy: 0.9923 - val_loss: 0.1044 - val_accuracy: 0.9753\n",
            "Epoch 84/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0607 - accuracy: 0.9917 - val_loss: 0.1038 - val_accuracy: 0.9756\n",
            "Epoch 85/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0589 - accuracy: 0.9925 - val_loss: 0.1033 - val_accuracy: 0.9756\n",
            "Epoch 86/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0562 - accuracy: 0.9928 - val_loss: 0.1033 - val_accuracy: 0.9751\n",
            "Epoch 87/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0549 - accuracy: 0.9928 - val_loss: 0.1028 - val_accuracy: 0.9753\n",
            "Epoch 88/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0540 - accuracy: 0.9926 - val_loss: 0.1025 - val_accuracy: 0.9751\n",
            "Epoch 89/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0518 - accuracy: 0.9932 - val_loss: 0.1017 - val_accuracy: 0.9756\n",
            "Epoch 90/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0509 - accuracy: 0.9933 - val_loss: 0.1013 - val_accuracy: 0.9761\n",
            "Epoch 91/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0497 - accuracy: 0.9932 - val_loss: 0.1010 - val_accuracy: 0.9761\n",
            "Epoch 92/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 0.0490 - accuracy: 0.9939 - val_loss: 0.1004 - val_accuracy: 0.9766\n",
            "Epoch 93/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0477 - accuracy: 0.9936 - val_loss: 0.1007 - val_accuracy: 0.9761\n",
            "Epoch 94/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0473 - accuracy: 0.9936 - val_loss: 0.1001 - val_accuracy: 0.9764\n",
            "Epoch 95/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0448 - accuracy: 0.9944 - val_loss: 0.0998 - val_accuracy: 0.9766\n",
            "Epoch 96/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0451 - accuracy: 0.9938 - val_loss: 0.0995 - val_accuracy: 0.9764\n",
            "Epoch 97/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0425 - accuracy: 0.9943 - val_loss: 0.0995 - val_accuracy: 0.9771\n",
            "Epoch 98/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0423 - accuracy: 0.9945 - val_loss: 0.0990 - val_accuracy: 0.9766\n",
            "Epoch 99/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0423 - accuracy: 0.9943 - val_loss: 0.0990 - val_accuracy: 0.9769\n",
            "Epoch 100/150\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 0.0401 - accuracy: 0.9947 - val_loss: 0.0988 - val_accuracy: 0.9766\n",
            "Epoch 101/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 0.0396 - accuracy: 0.9948 - val_loss: 0.0985 - val_accuracy: 0.9764\n",
            "Epoch 102/150\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 0.0384 - accuracy: 0.9942 - val_loss: 0.0986 - val_accuracy: 0.9764\n",
            "Epoch 103/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0382 - accuracy: 0.9947 - val_loss: 0.0983 - val_accuracy: 0.9761\n",
            "Epoch 104/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0379 - accuracy: 0.9945 - val_loss: 0.0982 - val_accuracy: 0.9761\n",
            "Epoch 105/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0360 - accuracy: 0.9943 - val_loss: 0.0979 - val_accuracy: 0.9764\n",
            "Epoch 106/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0357 - accuracy: 0.9948 - val_loss: 0.0977 - val_accuracy: 0.9764\n",
            "Epoch 107/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0342 - accuracy: 0.9948 - val_loss: 0.0976 - val_accuracy: 0.9769\n",
            "Epoch 108/150\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 0.0337 - accuracy: 0.9952 - val_loss: 0.0977 - val_accuracy: 0.9774\n",
            "Epoch 109/150\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 0.0339 - accuracy: 0.9949 - val_loss: 0.0977 - val_accuracy: 0.9766\n",
            "Model: \"model_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9746\n",
            "fr 0.4242\n",
            "it 0.1934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvCTQZpj3LO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a115908-d260-4379-c489-6fcbd40e4ce9"
      },
      "source": [
        "# run transfer\n",
        "task = 'slc_de_tf_fr'\n",
        "model = 'avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(de_avg_pool,'de_avg_pool',obs,freeze=False)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 4.2102 - accuracy: 0.4400 - val_loss: 1.5124 - val_accuracy: 0.6976\n",
            "Epoch 2/150\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 0.8028 - accuracy: 0.8700 - val_loss: 1.6955 - val_accuracy: 0.6461\n",
            "Epoch 3/150\n",
            "50/50 [==============================] - 5s 96ms/step - loss: 0.2008 - accuracy: 0.9700 - val_loss: 1.6275 - val_accuracy: 0.6819\n",
            "100 2\n",
            "Model: \"model_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [00:16<01:20, 16.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9286\n",
            "fr 0.6851\n",
            "it 0.0615\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.3353 - accuracy: 0.6040 - val_loss: 1.3384 - val_accuracy: 0.7043\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.9116 - accuracy: 0.9120 - val_loss: 1.1265 - val_accuracy: 0.7814\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 0.1205 - accuracy: 0.9760 - val_loss: 1.1076 - val_accuracy: 0.7873\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0397 - accuracy: 0.9840 - val_loss: 1.0790 - val_accuracy: 0.7954\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 1.0679 - val_accuracy: 0.7968\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.7964\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.7992\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.7982\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.7982\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.7985\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.7989\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0633 - val_accuracy: 0.7975\n",
            "250 2\n",
            "Model: \"model_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [02:19<03:13, 48.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9575\n",
            "fr 0.8056\n",
            "it 0.1679\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 2.6034 - accuracy: 0.6520 - val_loss: 0.9266 - val_accuracy: 0.8276\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.5964 - accuracy: 0.9340 - val_loss: 0.8253 - val_accuracy: 0.8283\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.1233 - accuracy: 0.9820 - val_loss: 0.7943 - val_accuracy: 0.8406\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 20s 81ms/step - loss: 0.0768 - accuracy: 0.9900 - val_loss: 0.7976 - val_accuracy: 0.8448\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.0858 - accuracy: 0.9940 - val_loss: 0.7906 - val_accuracy: 0.8423\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 19s 77ms/step - loss: 0.0332 - accuracy: 0.9960 - val_loss: 0.7761 - val_accuracy: 0.8462\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.7685 - val_accuracy: 0.8483\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7678 - val_accuracy: 0.8483\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.7784 - val_accuracy: 0.8462\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 19s 76ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 0.7709 - val_accuracy: 0.8483\n",
            "500 2\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [05:33<04:36, 92.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9514\n",
            "fr 0.8557\n",
            "it 0.1709\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 19s 75ms/step - loss: 2.3903 - accuracy: 0.7360 - val_loss: 0.8002 - val_accuracy: 0.8329\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 19s 74ms/step - loss: 0.4398 - accuracy: 0.9480 - val_loss: 0.6426 - val_accuracy: 0.8735\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 18s 74ms/step - loss: 0.1416 - accuracy: 0.9830 - val_loss: 0.5985 - val_accuracy: 0.8746\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0703 - accuracy: 0.9930 - val_loss: 0.5710 - val_accuracy: 0.8826\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 18s 74ms/step - loss: 0.0392 - accuracy: 0.9970 - val_loss: 0.5614 - val_accuracy: 0.8830\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0246 - accuracy: 0.9980 - val_loss: 0.5630 - val_accuracy: 0.8816\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8840\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8812\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 18s 73ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8802\n",
            "1000 4\n",
            "Model: \"model_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9667\n",
            "fr 0.8876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [08:21<03:49, 114.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.1739\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 2.1433 - accuracy: 0.7670 - val_loss: 0.6152 - val_accuracy: 0.8683\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.4318 - accuracy: 0.9485 - val_loss: 0.5235 - val_accuracy: 0.8956\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.1769 - accuracy: 0.9685 - val_loss: 0.4840 - val_accuracy: 0.9040\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0932 - accuracy: 0.9860 - val_loss: 0.4708 - val_accuracy: 0.9075\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0699 - accuracy: 0.9905 - val_loss: 0.4565 - val_accuracy: 0.9085\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0379 - accuracy: 0.9950 - val_loss: 0.4596 - val_accuracy: 0.9078\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0315 - accuracy: 0.9930 - val_loss: 0.4548 - val_accuracy: 0.9061\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0244 - accuracy: 0.9980 - val_loss: 0.4568 - val_accuracy: 0.9085\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.4499 - val_accuracy: 0.9089\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 18s 70ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.4576 - val_accuracy: 0.9071\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.4524 - val_accuracy: 0.9089\n",
            "2000 8\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [11:39<02:19, 139.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.9687\n",
            "fr 0.9145\n",
            "it 0.2144\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 2.0302 - accuracy: 0.7444 - val_loss: 0.6325 - val_accuracy: 0.8907\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5400 - accuracy: 0.9392 - val_loss: 0.4743 - val_accuracy: 0.9085\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.2736 - accuracy: 0.9620 - val_loss: 0.4148 - val_accuracy: 0.9187\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1771 - accuracy: 0.9750 - val_loss: 0.3812 - val_accuracy: 0.9222\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1287 - accuracy: 0.9794 - val_loss: 0.3652 - val_accuracy: 0.9257\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0997 - accuracy: 0.9856 - val_loss: 0.3521 - val_accuracy: 0.9292\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.0771 - accuracy: 0.9874 - val_loss: 0.3453 - val_accuracy: 0.9303\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0678 - accuracy: 0.9902 - val_loss: 0.3463 - val_accuracy: 0.9299\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0603 - accuracy: 0.9912 - val_loss: 0.3395 - val_accuracy: 0.9334\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0465 - accuracy: 0.9942 - val_loss: 0.3355 - val_accuracy: 0.9352\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0424 - accuracy: 0.9944 - val_loss: 0.3354 - val_accuracy: 0.9345\n",
            "Epoch 12/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0343 - accuracy: 0.9960 - val_loss: 0.3352 - val_accuracy: 0.9338\n",
            "Epoch 13/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0308 - accuracy: 0.9970 - val_loss: 0.3350 - val_accuracy: 0.9348\n",
            "Epoch 14/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0304 - accuracy: 0.9962 - val_loss: 0.3348 - val_accuracy: 0.9341\n",
            "Epoch 15/150\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.0252 - accuracy: 0.9968 - val_loss: 0.3357 - val_accuracy: 0.9352\n",
            "Epoch 16/150\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0255 - accuracy: 0.9970 - val_loss: 0.3374 - val_accuracy: 0.9345\n",
            "5000 64\n",
            "Model: \"model_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                22575     \n",
            "=================================================================\n",
            "Total params: 6,894,975\n",
            "Trainable params: 6,894,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [13:14<00:00, 132.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "de 0.968\n",
            "fr 0.9324\n",
            "it 0.2714\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6851</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>0.8557</td>\n",
              "      <td>0.8876</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>0.9324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>avg_pool</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3459</td>\n",
              "      <td>0.4622</td>\n",
              "      <td>0.5407</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model          task      metric    0  ... 10000 15000 25000 40000\n",
              "0  avg_pool  slc_de_tf_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "1  avg_pool  slc_de_tf_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HePqpP1G1YzS",
        "colab_type": "text"
      },
      "source": [
        "## CNN DE -> FR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i23kXE9h1dNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e711d072-93c1-42aa-e661-1e760d31dc54"
      },
      "source": [
        "dropout_rate= .4\n",
        "lr = .001\n",
        "#lr= .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "filter_sizes =  [3,4,5]\n",
        "num_filters = 75\n",
        "\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "sdo = SpatialDropout1D(dropout_rate)(embedd_seq)\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(sdo) #kernel_initializer='he_normal',\n",
        "    maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate)(falt_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_cnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 3)\n",
        "print(de_cnn.summary())\n",
        "\n",
        "#de_cnn.load_weights(path+'/model/de_cnn')\n",
        "\n",
        "hist = de_cnn.fit(x = X_train_pad_fr, y = y_train_enc_fr,\\\n",
        "                validation_data = (X_val_pad_fr, y_val_enc_fr), \\\n",
        "                epochs = 50, batch_size = 64, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_cnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_cnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "de_cnn.save_weights(path+'/model/de_cnn')\n",
        "de_cnn.save(path+'/model/de_cnn.h5')\n",
        "\n",
        "all_tests(de_cnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_49\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_35 (Embedding)        (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 34, 300)      0           embedding_35[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 32, 75)       67575       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 31, 75)       90075       spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 30, 75)       112575      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_26 (MaxPooling1D) (None, 1, 75)        0           conv1d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling1D) (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling1D) (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           max_pooling1d_26[0][0]           \n",
            "                                                                 max_pooling1d_27[0][0]           \n",
            "                                                                 max_pooling1d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_15[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,159,575\n",
            "Trainable params: 7,159,575\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "268/268 [==============================] - 48s 180ms/step - loss: 2.8651 - accuracy: 0.4387 - val_loss: 0.9748 - val_accuracy: 0.8136\n",
            "Epoch 2/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.9555 - accuracy: 0.8387 - val_loss: 0.4448 - val_accuracy: 0.9001\n",
            "Epoch 3/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.5266 - accuracy: 0.9034 - val_loss: 0.3103 - val_accuracy: 0.9236\n",
            "Epoch 4/50\n",
            "268/268 [==============================] - 48s 180ms/step - loss: 0.3407 - accuracy: 0.9314 - val_loss: 0.2435 - val_accuracy: 0.9411\n",
            "Epoch 5/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.2423 - accuracy: 0.9491 - val_loss: 0.1955 - val_accuracy: 0.9541\n",
            "Epoch 6/50\n",
            "268/268 [==============================] - 48s 180ms/step - loss: 0.1710 - accuracy: 0.9604 - val_loss: 0.1709 - val_accuracy: 0.9587\n",
            "Epoch 7/50\n",
            "268/268 [==============================] - 48s 181ms/step - loss: 0.1247 - accuracy: 0.9703 - val_loss: 0.1558 - val_accuracy: 0.9657\n",
            "Epoch 8/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.1035 - accuracy: 0.9741 - val_loss: 0.1379 - val_accuracy: 0.9695\n",
            "Epoch 9/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0750 - accuracy: 0.9809 - val_loss: 0.1331 - val_accuracy: 0.9681\n",
            "Epoch 10/50\n",
            "268/268 [==============================] - 48s 180ms/step - loss: 0.0616 - accuracy: 0.9846 - val_loss: 0.1292 - val_accuracy: 0.9741\n",
            "Epoch 11/50\n",
            "268/268 [==============================] - 48s 178ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.1284 - val_accuracy: 0.9751\n",
            "Epoch 12/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.1267 - val_accuracy: 0.9748\n",
            "Epoch 13/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.1173 - val_accuracy: 0.9793\n",
            "Epoch 14/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.1161 - val_accuracy: 0.9786\n",
            "Epoch 15/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 0.1207 - val_accuracy: 0.9807\n",
            "Epoch 16/50\n",
            "268/268 [==============================] - 48s 178ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.1294 - val_accuracy: 0.9804\n",
            "Epoch 17/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.1295 - val_accuracy: 0.9814\n",
            "0.1775\n",
            "0.232\n",
            "0.9828\n",
            "0.8618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-d676124d6034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mde_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/de_cnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mall_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_pad_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: all_tests() missing 1 required positional argument: 'y_it'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NImDvZQH35l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_fr.value_counts()[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yid3I8joZ4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "7f505d80-9577-4276-f4d2-0d0bdc089ed2"
      },
      "source": [
        "y_train_fr.value_counts()[40:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1221_Mineral or spring waters                                            73\n",
              "1136_Other preserved or processed fish and seafood-based preparations    72\n",
              "2111_Spirits and liqueurs                                                70\n",
              "1133_Fresh or chilled seafood                                            70\n",
              "1174_Potatoes                                                            69\n",
              "1161_Fresh or chilled fruit                                              68\n",
              "1171_Fresh or chilled vegetables other than potatoes and other tubers    67\n",
              "2131_Lager beer                                                          63\n",
              "1128_Other meat preparations                                             55\n",
              "1172_Frozen vegetables other than potatoes and other tubers              53\n",
              "1124_Poultry                                                             44\n",
              "1112_Flours and other cereals                                            42\n",
              "1143_Preserved milk                                                      40\n",
              "1186_Artificial sugar substitutes                                        39\n",
              "1135_Dried, smoked or salted fish and seafood                            36\n",
              "1118_Other cereal products                                               35\n",
              "1134_Frozen seafood                                                      33\n",
              "1131_Fresh or chilled fish                                               31\n",
              "1123_Lamb and goat                                                       31\n",
              "1132_Frozen fish                                                         28\n",
              "2112_Alcoholic soft drinks                                               27\n",
              "1147_Eggs                                                                23\n",
              "2134_Beer-based drinks                                                   22\n",
              "2122_Wine from other fruits                                              21\n",
              "1126_Edible offal                                                        21\n",
              "2133_Low and non-alcoholic beer                                          19\n",
              "2124_Wine-based drinks                                                   18\n",
              "1176_Other tubers and products of tuber vegetables                       17\n",
              "1162_Frozen fruit                                                        16\n",
              "1125_Other meats                                                         15\n",
              "2123_Fortified wines                                                     10\n",
              "Name: cc5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APZtVnE9sRIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88b69521-61c7-4de7-a7de-bdfa83b1bc48"
      },
      "source": [
        "y_pred_test = de_cnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_fr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.979\n",
            "0.8573\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       1.00      0.97      0.99        38\n",
            "                                        1112_Flours and other cereals       1.00      1.00      1.00         6\n",
            "                                                           1113_Bread       1.00      1.00      1.00        55\n",
            "                                           1114_Other bakery products       0.93      0.98      0.96        55\n",
            "                                                1115_Pizza and quiche       1.00      0.96      0.98        23\n",
            "                                     1116_Pasta products and couscous       0.98      0.99      0.99       112\n",
            "                                               1117_Breakfast cereals       1.00      0.95      0.97        57\n",
            "                                           1118_Other cereal products       1.00      1.00      1.00         4\n",
            "                                                   1121_Beef and veal       1.00      0.97      0.99        34\n",
            "                                                            1122_Pork       1.00      0.88      0.94        17\n",
            "                                                   1123_Lamb and goat       1.00      1.00      1.00         5\n",
            "                                                         1124_Poultry       0.57      1.00      0.73         4\n",
            "                                                     1125_Other meats       1.00      0.50      0.67         4\n",
            "                                                    1126_Edible offal       0.67      1.00      0.80         2\n",
            "                                    1127_Dried, salted or smoked meat       0.85      1.00      0.92        17\n",
            "                                         1128_Other meat preparations       1.00      0.50      0.67        12\n",
            "                                                     1132_Frozen fish       1.00      1.00      1.00         6\n",
            "                                        1133_Fresh or chilled seafood       1.00      0.82      0.90        11\n",
            "                                                  1134_Frozen seafood       1.00      0.57      0.73         7\n",
            "                        1135_Dried, smoked or salted fish and seafood       1.00      1.00      1.00         7\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.75      1.00      0.86        12\n",
            "                                                1141_Fresh whole milk       1.00      1.00      1.00        19\n",
            "                                              1142_Fresh low fat milk       1.00      1.00      1.00        63\n",
            "                                                  1143_Preserved milk       1.00      1.00      1.00         8\n",
            "                                                         1144_Yoghurt       1.00      1.00      1.00        72\n",
            "                                                 1145_Cheese and curd       1.00      1.00      1.00       337\n",
            "                                             1146_Other milk products       0.94      1.00      0.97        17\n",
            "                                                            1147_Eggs       1.00      1.00      1.00         2\n",
            "                                                          1151_Butter       1.00      1.00      1.00        47\n",
            "                              1152_Margarine and other vegetable fats       1.00      1.00      1.00        23\n",
            "                                                       1153_Olive oil       1.00      1.00      1.00        32\n",
            "                                               1154_Other edible oils       1.00      0.96      0.98        28\n",
            "                                          1161_Fresh or chilled fruit       0.87      1.00      0.93        13\n",
            "                                                    1162_Frozen fruit       1.00      1.00      1.00         2\n",
            "                                            1163_Dried fruit and nuts       0.94      0.88      0.91        17\n",
            "                        1164_Preserved fruit and fruit-based products       1.00      1.00      1.00        18\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       0.89      0.89      0.89         9\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.86      1.00      0.92         6\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.83      0.95      0.89        21\n",
            "                                                        1174_Potatoes       1.00      1.00      1.00         6\n",
            "                                                          1175_Crisps       1.00      0.99      0.99        75\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00         1\n",
            "                                                           1181_Sugar       0.88      1.00      0.93        21\n",
            "                                      1182_Jams, marmalades and honey       0.88      1.00      0.94        22\n",
            "                                                       1183_Chocolate       0.99      0.98      0.98       225\n",
            "                                          1184_Confectionery products       0.92      0.94      0.93        63\n",
            "                                       1185_Edible ices and ice cream       1.00      0.97      0.99        37\n",
            "                                    1186_Artificial sugar substitutes       1.00      0.71      0.83         7\n",
            "                                              1191_Sauces, condiments       1.00      0.95      0.98        22\n",
            "                                 1192_Salt, spices and culinary herbs       1.00      1.00      1.00        23\n",
            "                                                       1193_Baby food       1.00      1.00      1.00        54\n",
            "                                                1194_Ready-made meals       0.90      0.82      0.86        34\n",
            "                                      1199_Other food products n.e.c.       0.85      0.85      0.85        20\n",
            "                                                          1211_Coffee       1.00      1.00      1.00       232\n",
            "                                                             1212_Tea       1.00      1.00      1.00        18\n",
            "                                    1213_Cocoa and powdered chocolate       0.94      1.00      0.97        15\n",
            "                                        1221_Mineral or spring waters       1.00      1.00      1.00        13\n",
            "                                                     1222_Soft drinks       1.00      1.00      1.00        75\n",
            "                                      1223_Fruit and vegetable juices       1.00      1.00      1.00       116\n",
            "                                            2111_Spirits and liqueurs       0.88      1.00      0.93        14\n",
            "                                           2112_Alcoholic soft drinks       1.00      1.00      1.00         2\n",
            "                                                2121_Wine from grapes       1.00      1.00      1.00       310\n",
            "                                          2122_Wine from other fruits       1.00      1.00      1.00         5\n",
            "                                               2124_Wine-based drinks       1.00      0.60      0.75         5\n",
            "                                                      2131_Lager beer       0.80      1.00      0.89         8\n",
            "                                            2132_Other alcoholic beer       1.00      0.70      0.82        20\n",
            "                                      2133_Low and non-alcoholic beer       1.00      1.00      1.00         5\n",
            "                                               2134_Beer-based drinks       0.56      1.00      0.71         5\n",
            "                                                        9999_Non-Food       0.98      1.00      0.99       180\n",
            "\n",
            "                                                             accuracy                           0.98      2855\n",
            "                                                            macro avg       0.94      0.93      0.93      2855\n",
            "                                                         weighted avg       0.98      0.98      0.98      2855\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiXYFDUf3v9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "433cf5e6-551f-4c9f-fe45-fe69529fd5b9"
      },
      "source": [
        "y_pred_test_p = de_cnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test_p.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "df_y = pd.DataFrame()\n",
        "df_y['y_test'] = y_test_de\n",
        "df_y['y_pred'] = y_pred_test\n",
        "df_y['y_p'] = np.max(y_pred_test_p,axis=1)\n",
        "np.mean(df_y['y_p'][(df_y['y_pred'] =='1194_Ready-made meals') & (df_y['y_test'] !='1194_Ready-made meals')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8314691781997681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZobOt5A865I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "de1b59bd-aa84-437c-d478-ab2c7ec70474"
      },
      "source": [
        "np.mean(df_y['y_p'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9838460087776184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQcHVIlv8wV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b7afed5e-91db-4cc6-ab2e-1e4a7c31d939"
      },
      "source": [
        "np.mean(df_y['y_p'][df_y['y_test'] =='2134_Beer-based drinks'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9969618916511536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQH4JV3b4afU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_y = pd.DataFrame()\n",
        "df_y['y_test'] = y_test_de\n",
        "df_y['y_pred'] = y_pred_test\n",
        "df_y['X'][df_y['y_test'] =='1194_Ready-made meals'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkuLkPfJ4M7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiZP3WGxyoEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83d2a2ac-f0ae-4787-e376-ee16ef297e4b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "#print(classification_report(y_pred_test, y_test_de))\n",
        "#y_pred_test, y_test_de\n",
        "\n",
        "label = pd.Series(y_test_de).unique()\n",
        "label.sort()\n",
        "cm = confusion_matrix(y_test_de,y_pred_test,labels=label)#, normalize='true')\n",
        "\n",
        "df_cm = pd.DataFrame(cm, label,label)\n",
        "plt.figure(figsize=(15,15))\n",
        "sn.set(font_scale=.7) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 9}) # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ItE2kTYH-uF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70fe2fb2-f6ff-4d1a-9809-4e320b839e13"
      },
      "source": [
        "\n",
        "y_pred_test = de_cnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_fr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3884\n",
            "0.2631\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       0.32      0.92      0.48        13\n",
            "                                        1112_Flours and other cereals       0.00      0.00      0.00         7\n",
            "                                                           1113_Bread       0.02      1.00      0.04         1\n",
            "                                           1114_Other bakery products       0.33      0.49      0.39        39\n",
            "                                                1115_Pizza and quiche       0.91      0.51      0.66        39\n",
            "                                     1116_Pasta products and couscous       0.57      0.32      0.41       201\n",
            "                                               1117_Breakfast cereals       0.24      0.68      0.36        19\n",
            "                                           1118_Other cereal products       0.25      0.02      0.04        49\n",
            "                                                   1121_Beef and veal       0.03      0.12      0.05         8\n",
            "                                                            1122_Pork       0.00      0.00      0.00         0\n",
            "                                                   1123_Lamb and goat       0.00      0.00      0.00         0\n",
            "                                                         1124_Poultry       0.00      0.00      0.00         0\n",
            "                                                     1125_Other meats       0.00      0.00      0.00         1\n",
            "                                                    1126_Edible offal       0.00      0.00      0.00         0\n",
            "                                    1127_Dried, salted or smoked meat       0.15      0.19      0.17        16\n",
            "                                         1128_Other meat preparations       0.67      0.02      0.03       247\n",
            "                                                     1132_Frozen fish       0.50      0.75      0.60         4\n",
            "                                        1133_Fresh or chilled seafood       0.00      0.00      0.00         0\n",
            "                                                  1134_Frozen seafood       0.00      0.00      0.00         0\n",
            "                        1135_Dried, smoked or salted fish and seafood       0.00      0.00      0.00         0\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.50      0.07      0.13       109\n",
            "                                                1141_Fresh whole milk       0.00      0.00      0.00         0\n",
            "                                              1142_Fresh low fat milk       0.00      0.00      0.00         0\n",
            "                                                  1143_Preserved milk       0.00      0.00      0.00         0\n",
            "                                                         1144_Yoghurt       0.00      0.00      0.00         1\n",
            "                                                 1145_Cheese and curd       0.00      1.00      0.01         1\n",
            "                                             1146_Other milk products       0.17      0.06      0.09        51\n",
            "                                                            1147_Eggs       0.00      0.00      0.00         0\n",
            "                                                          1151_Butter       0.00      0.00      0.00         0\n",
            "                              1152_Margarine and other vegetable fats       0.83      0.66      0.73        29\n",
            "                                                       1153_Olive oil       0.00      0.00      0.00         0\n",
            "                                               1154_Other edible oils       0.00      0.00      0.00         0\n",
            "                                          1161_Fresh or chilled fruit       0.00      0.00      0.00         0\n",
            "                                                    1162_Frozen fruit       1.00      0.67      0.80         3\n",
            "                                            1163_Dried fruit and nuts       0.00      0.00      0.00         4\n",
            "                        1164_Preserved fruit and fruit-based products       0.06      0.10      0.07        10\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       0.11      1.00      0.20         1\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.00      0.00      0.00         0\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.00      0.00      0.00         0\n",
            "                                                        1174_Potatoes       0.50      1.00      0.67         3\n",
            "                                                          1175_Crisps       0.91      0.94      0.92        71\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00        38\n",
            "                                                           1181_Sugar       0.00      0.00      0.00         0\n",
            "                                      1182_Jams, marmalades and honey       0.12      0.75      0.21         4\n",
            "                                                       1183_Chocolate       0.91      0.41      0.56       501\n",
            "                                          1184_Confectionery products       0.81      0.41      0.54       128\n",
            "                                       1185_Edible ices and ice cream       0.00      0.00      0.00         0\n",
            "                                    1186_Artificial sugar substitutes       0.80      0.04      0.08        91\n",
            "                                              1191_Sauces, condiments       0.52      0.23      0.32        47\n",
            "                                 1192_Salt, spices and culinary herbs       0.00      0.00      0.00         1\n",
            "                                                       1193_Baby food       0.00      0.00      0.00         1\n",
            "                                                1194_Ready-made meals       0.23      0.07      0.11        97\n",
            "                                      1199_Other food products n.e.c.       0.30      0.24      0.27        25\n",
            "                                                          1211_Coffee       0.60      0.99      0.75       140\n",
            "                                                             1212_Tea       0.00      0.00      0.00         0\n",
            "                                    1213_Cocoa and powdered chocolate       0.00      0.00      0.00         0\n",
            "                                        1221_Mineral or spring waters       0.08      1.00      0.14         1\n",
            "                                                     1222_Soft drinks       0.96      0.96      0.96        75\n",
            "                                      1223_Fruit and vegetable juices       0.23      0.59      0.33        46\n",
            "                                            2111_Spirits and liqueurs       0.50      0.31      0.38        26\n",
            "                                           2112_Alcoholic soft drinks       0.00      0.00      0.00       210\n",
            "                                                2121_Wine from grapes       0.95      0.98      0.96       302\n",
            "                                          2122_Wine from other fruits       0.40      1.00      0.57         2\n",
            "                                                 2123_Fortified wines       0.00      0.00      0.00        11\n",
            "                                               2124_Wine-based drinks       0.67      0.02      0.03       127\n",
            "                                                      2131_Lager beer       0.20      0.12      0.15        16\n",
            "                                            2132_Other alcoholic beer       0.00      0.00      0.00         0\n",
            "                                      2133_Low and non-alcoholic beer       0.00      0.00      0.00         0\n",
            "                                               2134_Beer-based drinks       0.11      0.09      0.10        11\n",
            "                                                        9999_Non-Food       0.15      1.00      0.26        28\n",
            "\n",
            "                                                             accuracy                           0.39      2855\n",
            "                                                            macro avg       0.24      0.28      0.19      2855\n",
            "                                                         weighted avg       0.62      0.39      0.41      2855\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04lXOBFGq-md",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aaadc37-1fbc-4ba5-9d2c-811ce777cbb5"
      },
      "source": [
        "# run transfer\n",
        "task = 'slc_de_tf_fr'\n",
        "model = 'cnn'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(de_cnn,'de_cnn',obs,freeze=False)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 3.6910 - accuracy: 0.1900 - val_loss: 2.6126 - val_accuracy: 0.3931\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 1.1673 - accuracy: 0.5100 - val_loss: 2.5737 - val_accuracy: 0.4713\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.5285 - accuracy: 0.6900 - val_loss: 2.4529 - val_accuracy: 0.4944\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.2391 - accuracy: 0.7700 - val_loss: 2.3377 - val_accuracy: 0.5245\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.1888 - accuracy: 0.8600 - val_loss: 2.2419 - val_accuracy: 0.5582\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.1095 - accuracy: 0.9500 - val_loss: 2.2188 - val_accuracy: 0.5767\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.1196 - accuracy: 0.9000 - val_loss: 2.1899 - val_accuracy: 0.5971\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.0714 - accuracy: 0.9300 - val_loss: 2.1708 - val_accuracy: 0.5995\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0783 - accuracy: 0.9400 - val_loss: 2.1246 - val_accuracy: 0.6202\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 2.0875 - val_accuracy: 0.6237\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 2.0723 - val_accuracy: 0.6307\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.0409 - accuracy: 0.9900 - val_loss: 2.0709 - val_accuracy: 0.6310\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.0440 - accuracy: 0.9800 - val_loss: 2.0741 - val_accuracy: 0.6310\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.0390 - accuracy: 0.9800 - val_loss: 2.0735 - val_accuracy: 0.6303\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 2.0773 - val_accuracy: 0.6328\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.0357 - accuracy: 0.9700 - val_loss: 2.0667 - val_accuracy: 0.6349\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0239 - accuracy: 0.9900 - val_loss: 2.0631 - val_accuracy: 0.6374\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.0208 - accuracy: 0.9900 - val_loss: 2.0634 - val_accuracy: 0.6381\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0482 - accuracy: 0.9900 - val_loss: 2.0980 - val_accuracy: 0.6352\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 2.1269 - val_accuracy: 0.6328\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.1197 - val_accuracy: 0.6331\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.0161 - accuracy: 0.9900 - val_loss: 2.1068 - val_accuracy: 0.6359\n",
            "100\n",
            "Model: \"model_97\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9036\n",
            "fr 0.6392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [00:22<01:54, 22.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2834\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 4.5352 - accuracy: 0.4480 - val_loss: 1.3399 - val_accuracy: 0.7144\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.4067 - accuracy: 0.9320 - val_loss: 1.3961 - val_accuracy: 0.7526\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1674 - accuracy: 0.9840 - val_loss: 1.3186 - val_accuracy: 0.7666\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0475 - accuracy: 0.9800 - val_loss: 1.3081 - val_accuracy: 0.7701\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 1.3117 - val_accuracy: 0.7765\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 1.3011 - val_accuracy: 0.7775\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.7779\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 1.2840 - val_accuracy: 0.7807\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2840 - val_accuracy: 0.7803\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.2771 - val_accuracy: 0.7800\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 2s 68ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2797 - val_accuracy: 0.7810\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 2s 68ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2844 - val_accuracy: 0.7849\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 2s 69ms/step - loss: 0.0029 - accuracy: 0.9960 - val_loss: 1.2943 - val_accuracy: 0.7849\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 2s 70ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2977 - val_accuracy: 0.7849\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 2s 69ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.7852\n",
            "250\n",
            "Model: \"model_98\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9207\n",
            "fr 0.787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [00:55<01:43, 25.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2639\n",
            "None\n",
            "Epoch 1/150\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 4.1140 - accuracy: 0.5180 - val_loss: 1.1514 - val_accuracy: 0.7568\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.6711 - accuracy: 0.9260 - val_loss: 0.8927 - val_accuracy: 0.8041\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1112 - accuracy: 0.9640 - val_loss: 0.8819 - val_accuracy: 0.8185\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0769 - accuracy: 0.9800 - val_loss: 0.8869 - val_accuracy: 0.8259\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.0301 - accuracy: 0.9880 - val_loss: 0.8751 - val_accuracy: 0.8287\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0131 - accuracy: 0.9940 - val_loss: 0.8713 - val_accuracy: 0.8297\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.8670 - val_accuracy: 0.8315\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: 0.8693 - val_accuracy: 0.8318\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.8736 - val_accuracy: 0.8297\n",
            "Epoch 10/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0125 - accuracy: 0.9920 - val_loss: 0.8697 - val_accuracy: 0.8308\n",
            "Epoch 11/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.8638 - val_accuracy: 0.8329\n",
            "Epoch 12/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.8329\n",
            "Epoch 13/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 0.8661 - val_accuracy: 0.8343\n",
            "Epoch 14/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.8637 - val_accuracy: 0.8367\n",
            "Epoch 15/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.8694 - val_accuracy: 0.8381\n",
            "Epoch 16/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: 0.8787 - val_accuracy: 0.8360\n",
            "Epoch 17/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.8322\n",
            "Epoch 18/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8928 - val_accuracy: 0.8329\n",
            "Epoch 19/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.8913 - val_accuracy: 0.8325\n",
            "500\n",
            "Model: \"model_99\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9341\n",
            "fr 0.8322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [01:56<01:49, 36.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2834\n",
            "None\n",
            "Epoch 1/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 2.5298 - accuracy: 0.5880 - val_loss: 0.8173 - val_accuracy: 0.8301\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.3624 - accuracy: 0.9250 - val_loss: 0.6709 - val_accuracy: 0.8644\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0973 - accuracy: 0.9730 - val_loss: 0.6257 - val_accuracy: 0.8770\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0436 - accuracy: 0.9880 - val_loss: 0.6343 - val_accuracy: 0.8658\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.6097 - val_accuracy: 0.8718\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.6020 - val_accuracy: 0.8749\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.6118 - val_accuracy: 0.8749\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.6160 - val_accuracy: 0.8770\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.5997 - val_accuracy: 0.8837\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.6028 - val_accuracy: 0.8847\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0078 - accuracy: 0.9960 - val_loss: 0.5966 - val_accuracy: 0.8823\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.8844\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5978 - val_accuracy: 0.8812\n",
            "Epoch 14/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8774\n",
            "Epoch 15/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.8812\n",
            "Epoch 16/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5954 - val_accuracy: 0.8837\n",
            "Epoch 17/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8833\n",
            "Epoch 18/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.6033 - val_accuracy: 0.8823\n",
            "Epoch 19/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8840\n",
            "Epoch 20/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.6096 - val_accuracy: 0.8851\n",
            "Epoch 21/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.6150 - val_accuracy: 0.8823\n",
            "1000\n",
            "Model: \"model_100\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9354\n",
            "fr 0.8736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [03:48<01:57, 58.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.3328\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6355 - accuracy: 0.6990 - val_loss: 0.6439 - val_accuracy: 0.8690\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.3040 - accuracy: 0.9400 - val_loss: 0.5025 - val_accuracy: 0.8987\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0992 - accuracy: 0.9790 - val_loss: 0.5119 - val_accuracy: 0.8980\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0540 - accuracy: 0.9875 - val_loss: 0.4932 - val_accuracy: 0.9005\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0649 - accuracy: 0.9850 - val_loss: 0.5736 - val_accuracy: 0.8938\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.5261 - val_accuracy: 0.8963\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.5473 - val_accuracy: 0.8963\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.5404 - val_accuracy: 0.9005\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.5304 - val_accuracy: 0.9026\n",
            "2000\n",
            "Model: \"model_101\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9268\n",
            "fr 0.8911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [05:15<01:07, 67.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2894\n",
            "None\n",
            "Epoch 1/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 1.4326 - accuracy: 0.8018 - val_loss: 0.4494 - val_accuracy: 0.9100\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.2232 - accuracy: 0.9574 - val_loss: 0.4081 - val_accuracy: 0.9198\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.0987 - accuracy: 0.9784 - val_loss: 0.3893 - val_accuracy: 0.9296\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0586 - accuracy: 0.9874 - val_loss: 0.3874 - val_accuracy: 0.9292\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0436 - accuracy: 0.9928 - val_loss: 0.4060 - val_accuracy: 0.9292\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0292 - accuracy: 0.9946 - val_loss: 0.4169 - val_accuracy: 0.9317\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0325 - accuracy: 0.9930 - val_loss: 0.4490 - val_accuracy: 0.9282\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.4351 - val_accuracy: 0.9292\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 0.4832 - val_accuracy: 0.9292\n",
            "5000\n",
            "Model: \"model_102\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 34, 300)      6877800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 32, 75)       67575       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 31, 75)       90075       embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 30, 75)       112575      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_105 (MaxPooling1D (None, 1, 75)        0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_106 (MaxPooling1D (None, 1, 75)        0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_107 (MaxPooling1D (None, 1, 75)        0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 75)        0           max_pooling1d_105[0][0]          \n",
            "                                                                 max_pooling1d_106[0][0]          \n",
            "                                                                 max_pooling1d_107[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,164,975\n",
            "Trainable params: 7,164,975\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9148\n",
            "fr 0.9327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [08:39<00:00, 86.51s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.2834\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>cnn</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6392</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.8322</td>\n",
              "      <td>0.8736</td>\n",
              "      <td>0.8911</td>\n",
              "      <td>0.9327</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>cnn</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2497</td>\n",
              "      <td>0.4519</td>\n",
              "      <td>0.5265</td>\n",
              "      <td>0.5949</td>\n",
              "      <td>0.6723</td>\n",
              "      <td>0.7368</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model          task      metric    0     100  ...    5000 10000 15000 25000 40000\n",
              "28   cnn  slc_de_tf_fr    accuracy  NaN  0.6392  ...  0.9327   NaN   NaN   NaN   NaN\n",
              "29   cnn  slc_de_tf_fr  avg_recall  NaN  0.2497  ...  0.7368   NaN   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS1ZecFuujru",
        "colab_type": "text"
      },
      "source": [
        "CNN FR -> DE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHDpYPA1duk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a9cd9a2-a254-4f6d-ece8-4bf5c1b49a75"
      },
      "source": [
        "dropout_rate= .4\n",
        "lr = .0001\n",
        "#lr= .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "filter_sizes =  [3,4,5]\n",
        "num_filters = 75\n",
        "\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "    maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate)(falt_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_cnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 3)\n",
        "print(de_cnn.summary())\n",
        "\n",
        "#de_cnn.load_weights(path+'/model/de_cnn')\n",
        "\n",
        "hist = de_cnn.fit(x = X_train_pad_fr, y = y_train_enc_fr,\\\n",
        "                validation_data = (X_val_pad_fr, y_val_enc_fr), \\\n",
        "                epochs = 50, batch_size = 64, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_cnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_cnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "de_cnn.save_weights(path+'/model/de_cnn')\n",
        "de_cnn.save(path+'/model/de_cnn.h5')\n",
        "\n",
        "all_tests(de_cnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 32, 75)       67575       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 31, 75)       90075       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 30, 75)       112575      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 75)        0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 1, 75)        0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 1, 75)        0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 75)        0           max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "                                                                 max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,159,575\n",
            "Trainable params: 7,159,575\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 3.7018 - accuracy: 0.1517 - val_loss: 3.5768 - val_accuracy: 0.5364\n",
            "Epoch 2/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 3.2476 - accuracy: 0.4643 - val_loss: 2.8868 - val_accuracy: 0.6748\n",
            "Epoch 3/50\n",
            "268/268 [==============================] - 48s 178ms/step - loss: 2.6736 - accuracy: 0.6556 - val_loss: 2.0545 - val_accuracy: 0.7386\n",
            "Epoch 4/50\n",
            "268/268 [==============================] - 47s 177ms/step - loss: 2.0817 - accuracy: 0.7196 - val_loss: 1.4902 - val_accuracy: 0.7754\n",
            "Epoch 5/50\n",
            "268/268 [==============================] - 48s 178ms/step - loss: 1.6180 - accuracy: 0.7624 - val_loss: 1.1709 - val_accuracy: 0.8115\n",
            "Epoch 6/50\n",
            "268/268 [==============================] - 48s 177ms/step - loss: 1.2948 - accuracy: 0.8047 - val_loss: 0.9254 - val_accuracy: 0.8395\n",
            "Epoch 7/50\n",
            "268/268 [==============================] - 47s 177ms/step - loss: 1.0793 - accuracy: 0.8399 - val_loss: 0.7584 - val_accuracy: 0.8672\n",
            "Epoch 8/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.9038 - accuracy: 0.8647 - val_loss: 0.6453 - val_accuracy: 0.8802\n",
            "Epoch 9/50\n",
            "268/268 [==============================] - 47s 177ms/step - loss: 0.7830 - accuracy: 0.8786 - val_loss: 0.5545 - val_accuracy: 0.8931\n",
            "Epoch 10/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.6792 - accuracy: 0.8907 - val_loss: 0.4926 - val_accuracy: 0.9022\n",
            "Epoch 11/50\n",
            "268/268 [==============================] - 48s 178ms/step - loss: 0.6111 - accuracy: 0.9000 - val_loss: 0.4476 - val_accuracy: 0.9107\n",
            "Epoch 12/50\n",
            "268/268 [==============================] - 48s 179ms/step - loss: 0.5475 - accuracy: 0.9103 - val_loss: 0.4120 - val_accuracy: 0.9215\n",
            "Epoch 13/50\n",
            "268/268 [==============================] - 48s 177ms/step - loss: 0.4833 - accuracy: 0.9189 - val_loss: 0.3818 - val_accuracy: 0.9247\n",
            "Epoch 14/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.4437 - accuracy: 0.9237 - val_loss: 0.3526 - val_accuracy: 0.9292\n",
            "Epoch 15/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.3985 - accuracy: 0.9296 - val_loss: 0.3264 - val_accuracy: 0.9313\n",
            "Epoch 16/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.3628 - accuracy: 0.9357 - val_loss: 0.3079 - val_accuracy: 0.9369\n",
            "Epoch 17/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.3327 - accuracy: 0.9399 - val_loss: 0.2894 - val_accuracy: 0.9401\n",
            "Epoch 18/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.3081 - accuracy: 0.9437 - val_loss: 0.2720 - val_accuracy: 0.9439\n",
            "Epoch 19/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.2777 - accuracy: 0.9482 - val_loss: 0.2617 - val_accuracy: 0.9432\n",
            "Epoch 20/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.2555 - accuracy: 0.9509 - val_loss: 0.2450 - val_accuracy: 0.9478\n",
            "Epoch 21/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.2362 - accuracy: 0.9540 - val_loss: 0.2385 - val_accuracy: 0.9478\n",
            "Epoch 22/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.2233 - accuracy: 0.9561 - val_loss: 0.2267 - val_accuracy: 0.9464\n",
            "Epoch 23/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.2045 - accuracy: 0.9605 - val_loss: 0.2131 - val_accuracy: 0.9516\n",
            "Epoch 24/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.1863 - accuracy: 0.9611 - val_loss: 0.2080 - val_accuracy: 0.9534\n",
            "Epoch 25/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1651 - accuracy: 0.9657 - val_loss: 0.1970 - val_accuracy: 0.9530\n",
            "Epoch 26/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1573 - accuracy: 0.9660 - val_loss: 0.1908 - val_accuracy: 0.9573\n",
            "Epoch 27/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1463 - accuracy: 0.9698 - val_loss: 0.1850 - val_accuracy: 0.9583\n",
            "Epoch 28/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1347 - accuracy: 0.9710 - val_loss: 0.1766 - val_accuracy: 0.9580\n",
            "Epoch 29/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1240 - accuracy: 0.9730 - val_loss: 0.1714 - val_accuracy: 0.9583\n",
            "Epoch 30/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1148 - accuracy: 0.9748 - val_loss: 0.1666 - val_accuracy: 0.9622\n",
            "Epoch 31/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.1047 - accuracy: 0.9770 - val_loss: 0.1607 - val_accuracy: 0.9629\n",
            "Epoch 32/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.1025 - accuracy: 0.9766 - val_loss: 0.1545 - val_accuracy: 0.9632\n",
            "Epoch 33/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.0924 - accuracy: 0.9792 - val_loss: 0.1508 - val_accuracy: 0.9646\n",
            "Epoch 34/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.0864 - accuracy: 0.9804 - val_loss: 0.1453 - val_accuracy: 0.9650\n",
            "Epoch 35/50\n",
            "268/268 [==============================] - 46s 173ms/step - loss: 0.0765 - accuracy: 0.9815 - val_loss: 0.1419 - val_accuracy: 0.9671\n",
            "Epoch 36/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.0730 - accuracy: 0.9827 - val_loss: 0.1388 - val_accuracy: 0.9671\n",
            "Epoch 37/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.0718 - accuracy: 0.9828 - val_loss: 0.1357 - val_accuracy: 0.9695\n",
            "Epoch 38/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.0615 - accuracy: 0.9849 - val_loss: 0.1321 - val_accuracy: 0.9688\n",
            "Epoch 39/50\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 0.0595 - accuracy: 0.9849 - val_loss: 0.1295 - val_accuracy: 0.9720\n",
            "Epoch 40/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.0536 - accuracy: 0.9873 - val_loss: 0.1285 - val_accuracy: 0.9716\n",
            "Epoch 41/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.1270 - val_accuracy: 0.9716\n",
            "Epoch 42/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0507 - accuracy: 0.9873 - val_loss: 0.1214 - val_accuracy: 0.9730\n",
            "Epoch 43/50\n",
            "268/268 [==============================] - 48s 177ms/step - loss: 0.0463 - accuracy: 0.9887 - val_loss: 0.1215 - val_accuracy: 0.9709\n",
            "Epoch 44/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.1210 - val_accuracy: 0.9727\n",
            "Epoch 45/50\n",
            "268/268 [==============================] - 47s 177ms/step - loss: 0.0410 - accuracy: 0.9900 - val_loss: 0.1190 - val_accuracy: 0.9734\n",
            "Epoch 46/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.1174 - val_accuracy: 0.9727\n",
            "Epoch 47/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 0.1163 - val_accuracy: 0.9744\n",
            "Epoch 48/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0334 - accuracy: 0.9911 - val_loss: 0.1137 - val_accuracy: 0.9751\n",
            "Epoch 49/50\n",
            "268/268 [==============================] - 47s 176ms/step - loss: 0.0313 - accuracy: 0.9925 - val_loss: 0.1129 - val_accuracy: 0.9751\n",
            "Epoch 50/50\n",
            "268/268 [==============================] - 47s 175ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.1118 - val_accuracy: 0.9758\n",
            "0.1955\n",
            "0.2597\n",
            "0.9811\n",
            "0.8628\n",
            "\n",
            "de 0.1955\n",
            "fr 0.9811\n",
            "it 0.1904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwdCfJ63uxCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd5e802d-1107-418e-fe54-1997e18c2d1a"
      },
      "source": [
        "y_pred_test = de_cnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_de))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1955\n",
            "0.2597\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       0.26      0.83      0.39        12\n",
            "                                        1112_Flours and other cereals       0.00      0.00      0.00         0\n",
            "                                                           1113_Bread       0.06      0.50      0.11         4\n",
            "                                           1114_Other bakery products       0.36      0.34      0.35       126\n",
            "                                                1115_Pizza and quiche       0.80      0.47      0.59        34\n",
            "                                     1116_Pasta products and couscous       0.11      0.53      0.19        17\n",
            "                                               1117_Breakfast cereals       0.59      0.49      0.54        77\n",
            "                                           1118_Other cereal products       0.12      0.03      0.05       126\n",
            "                                                   1121_Beef and veal       0.11      0.31      0.16        16\n",
            "                                                            1122_Pork       0.00      0.00      0.00         2\n",
            "                                                   1123_Lamb and goat       0.00      0.00      0.00         0\n",
            "                                                         1124_Poultry       0.02      0.25      0.03         4\n",
            "                                                     1125_Other meats       0.00      0.00      0.00         0\n",
            "                                                    1126_Edible offal       0.00      0.00      0.00         1\n",
            "                                    1127_Dried, salted or smoked meat       0.18      0.41      0.25        37\n",
            "                                         1128_Other meat preparations       0.10      0.04      0.06        45\n",
            "                                           1131_Fresh or chilled fish       0.00      0.00      0.00         2\n",
            "                                                     1132_Frozen fish       0.50      1.00      0.67         7\n",
            "                                        1133_Fresh or chilled seafood       0.00      0.00      0.00         0\n",
            "                                                  1134_Frozen seafood       0.25      0.67      0.36         3\n",
            "                        1135_Dried, smoked or salted fish and seafood       0.00      0.00      0.00         0\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.42      0.12      0.18       135\n",
            "                                                1141_Fresh whole milk       0.00      0.00      0.00         3\n",
            "                                              1142_Fresh low fat milk       0.00      0.00      0.00         0\n",
            "                                                  1143_Preserved milk       0.00      0.00      0.00         0\n",
            "                                                         1144_Yoghurt       0.04      1.00      0.07         1\n",
            "                                                 1145_Cheese and curd       0.09      1.00      0.16         3\n",
            "                                             1146_Other milk products       0.02      0.09      0.04        11\n",
            "                                                            1147_Eggs       0.00      0.00      0.00         0\n",
            "                                                          1151_Butter       0.00      0.00      0.00         0\n",
            "                              1152_Margarine and other vegetable fats       0.55      0.67      0.60         9\n",
            "                                                       1153_Olive oil       0.00      0.00      0.00         0\n",
            "                                               1154_Other edible oils       0.00      0.00      0.00         0\n",
            "                                        1155_Other edible animal fats       0.00      0.00      0.00         0\n",
            "                                          1161_Fresh or chilled fruit       0.01      1.00      0.02         1\n",
            "                                                    1162_Frozen fruit       0.00      0.00      0.00         0\n",
            "                                            1163_Dried fruit and nuts       0.00      0.00      0.00         2\n",
            "                        1164_Preserved fruit and fruit-based products       0.00      0.00      0.00         1\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       0.04      0.19      0.07        32\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.00      0.00      0.00         9\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.00      0.00      0.00         1\n",
            "                                                        1174_Potatoes       0.21      0.92      0.34        12\n",
            "                                                          1175_Crisps       0.74      0.81      0.77        21\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00         0\n",
            "                                                           1181_Sugar       0.00      0.00      0.00         0\n",
            "                                      1182_Jams, marmalades and honey       0.02      1.00      0.03         1\n",
            "                                                       1183_Chocolate       0.07      0.50      0.12         8\n",
            "                                          1184_Confectionery products       0.26      0.08      0.12       235\n",
            "                                       1185_Edible ices and ice cream       0.14      0.88      0.25         8\n",
            "                                    1186_Artificial sugar substitutes       0.60      0.03      0.05       107\n",
            "                                              1191_Sauces, condiments       0.29      0.31      0.30        89\n",
            "                                 1192_Salt, spices and culinary herbs       0.02      0.06      0.02        17\n",
            "                                                       1193_Baby food       0.00      0.00      0.00         2\n",
            "                                                1194_Ready-made meals       0.19      0.02      0.04       206\n",
            "                                      1199_Other food products n.e.c.       0.40      0.02      0.05       575\n",
            "                                                          1211_Coffee       0.56      0.24      0.34       130\n",
            "                                                             1212_Tea       0.00      0.00      0.00         0\n",
            "                                    1213_Cocoa and powdered chocolate       0.20      0.25      0.22         4\n",
            "                                        1221_Mineral or spring waters       0.00      0.00      0.00         0\n",
            "                                                     1222_Soft drinks       0.57      0.40      0.47        97\n",
            "                                      1223_Fruit and vegetable juices       0.15      0.20      0.17        44\n",
            "                                            2111_Spirits and liqueurs       0.49      0.10      0.16       334\n",
            "                                           2112_Alcoholic soft drinks       0.00      0.00      0.00        69\n",
            "                                                2121_Wine from grapes       0.45      0.83      0.59        78\n",
            "                                          2122_Wine from other fruits       0.11      1.00      0.20         1\n",
            "                                                 2123_Fortified wines       0.00      0.00      0.00         0\n",
            "                                               2124_Wine-based drinks       0.78      0.13      0.23        53\n",
            "                                                      2131_Lager beer       0.75      0.31      0.43        49\n",
            "                                            2132_Other alcoholic beer       0.00      0.00      0.00         0\n",
            "                                      2133_Low and non-alcoholic beer       0.05      1.00      0.09         1\n",
            "                                               2134_Beer-based drinks       0.00      0.00      0.00       469\n",
            "                                                      2201_Cigarettes       0.00      0.00      0.00         0\n",
            "                                                          2202_Cigars       0.00      0.00      0.00         0\n",
            "                                          2203_Other tobacco products       0.00      0.00      0.00         0\n",
            "                                                        9999_Non-Food       0.23      0.45      0.31       602\n",
            "\n",
            "                                                             accuracy                           0.20      3933\n",
            "                                                            macro avg       0.16      0.26      0.14      3933\n",
            "                                                         weighted avg       0.31      0.20      0.18      3933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YqAwu7Zuxlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b903c0b7-2716-4323-d76c-b304762d2662"
      },
      "source": [
        "\n",
        "y_pred_test = de_cnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_fr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9811\n",
            "0.8628\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       1.00      0.97      0.99        38\n",
            "                                        1112_Flours and other cereals       1.00      1.00      1.00         6\n",
            "                                                           1113_Bread       0.98      1.00      0.99        54\n",
            "                                           1114_Other bakery products       0.91      0.91      0.91        58\n",
            "                                                1115_Pizza and quiche       1.00      0.96      0.98        23\n",
            "                                     1116_Pasta products and couscous       0.98      0.99      0.99       112\n",
            "                                               1117_Breakfast cereals       1.00      1.00      1.00        54\n",
            "                                           1118_Other cereal products       1.00      1.00      1.00         4\n",
            "                                                   1121_Beef and veal       1.00      0.94      0.97        35\n",
            "                                                            1122_Pork       1.00      0.94      0.97        16\n",
            "                                                   1123_Lamb and goat       1.00      1.00      1.00         5\n",
            "                                                         1124_Poultry       0.57      1.00      0.73         4\n",
            "                                                     1125_Other meats       1.00      0.50      0.67         4\n",
            "                                                    1126_Edible offal       1.00      1.00      1.00         3\n",
            "                                    1127_Dried, salted or smoked meat       0.90      1.00      0.95        18\n",
            "                                         1128_Other meat preparations       1.00      0.55      0.71        11\n",
            "                                                     1132_Frozen fish       1.00      1.00      1.00         6\n",
            "                                        1133_Fresh or chilled seafood       1.00      0.75      0.86        12\n",
            "                                                  1134_Frozen seafood       1.00      0.67      0.80         6\n",
            "                        1135_Dried, smoked or salted fish and seafood       1.00      1.00      1.00         7\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.81      1.00      0.90        13\n",
            "                                                1141_Fresh whole milk       1.00      1.00      1.00        19\n",
            "                                              1142_Fresh low fat milk       1.00      1.00      1.00        63\n",
            "                                                  1143_Preserved milk       1.00      1.00      1.00         8\n",
            "                                                         1144_Yoghurt       1.00      1.00      1.00        72\n",
            "                                                 1145_Cheese and curd       1.00      1.00      1.00       337\n",
            "                                             1146_Other milk products       0.94      1.00      0.97        17\n",
            "                                                            1147_Eggs       1.00      1.00      1.00         2\n",
            "                                                          1151_Butter       1.00      1.00      1.00        47\n",
            "                              1152_Margarine and other vegetable fats       1.00      1.00      1.00        23\n",
            "                                                       1153_Olive oil       1.00      1.00      1.00        32\n",
            "                                               1154_Other edible oils       1.00      1.00      1.00        27\n",
            "                                          1161_Fresh or chilled fruit       0.87      1.00      0.93        13\n",
            "                                                    1162_Frozen fruit       1.00      1.00      1.00         2\n",
            "                                            1163_Dried fruit and nuts       0.94      0.88      0.91        17\n",
            "                        1164_Preserved fruit and fruit-based products       1.00      1.00      1.00        18\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       1.00      1.00      1.00         9\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.86      1.00      0.92         6\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.83      1.00      0.91        20\n",
            "                                                        1174_Potatoes       1.00      1.00      1.00         6\n",
            "                                                          1175_Crisps       1.00      0.99      0.99        75\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00         2\n",
            "                                                           1181_Sugar       0.88      1.00      0.93        21\n",
            "                                      1182_Jams, marmalades and honey       0.92      1.00      0.96        23\n",
            "                                                       1183_Chocolate       0.99      0.98      0.98       225\n",
            "                                          1184_Confectionery products       0.92      0.94      0.93        63\n",
            "                                       1185_Edible ices and ice cream       1.00      0.97      0.99        37\n",
            "                                    1186_Artificial sugar substitutes       1.00      0.71      0.83         7\n",
            "                                              1191_Sauces, condiments       0.95      0.95      0.95        21\n",
            "                                 1192_Salt, spices and culinary herbs       1.00      1.00      1.00        23\n",
            "                                                       1193_Baby food       1.00      1.00      1.00        54\n",
            "                                                1194_Ready-made meals       0.90      0.90      0.90        31\n",
            "                                      1199_Other food products n.e.c.       0.95      0.90      0.93        21\n",
            "                                                          1211_Coffee       1.00      1.00      1.00       232\n",
            "                                                             1212_Tea       1.00      1.00      1.00        18\n",
            "                                    1213_Cocoa and powdered chocolate       0.94      1.00      0.97        15\n",
            "                                        1221_Mineral or spring waters       1.00      1.00      1.00        13\n",
            "                                                     1222_Soft drinks       1.00      1.00      1.00        75\n",
            "                                      1223_Fruit and vegetable juices       1.00      1.00      1.00       116\n",
            "                                            2111_Spirits and liqueurs       0.88      1.00      0.93        14\n",
            "                                           2112_Alcoholic soft drinks       1.00      1.00      1.00         2\n",
            "                                                2121_Wine from grapes       1.00      1.00      1.00       310\n",
            "                                          2122_Wine from other fruits       1.00      1.00      1.00         5\n",
            "                                               2124_Wine-based drinks       1.00      0.60      0.75         5\n",
            "                                                      2131_Lager beer       0.80      1.00      0.89         8\n",
            "                                            2132_Other alcoholic beer       1.00      0.70      0.82        20\n",
            "                                      2133_Low and non-alcoholic beer       1.00      1.00      1.00         5\n",
            "                                               2134_Beer-based drinks       0.56      1.00      0.71         5\n",
            "                                                        9999_Non-Food       0.99      1.00      0.99       182\n",
            "\n",
            "                                                             accuracy                           0.98      2855\n",
            "                                                            macro avg       0.95      0.94      0.93      2855\n",
            "                                                         weighted avg       0.98      0.98      0.98      2855\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3PMAChZyH7F",
        "colab_type": "text"
      },
      "source": [
        "## RNN DE -> FR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNopRAoAyLQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "6b6b93bb-7b78-4a73-b0e2-01fdbf21a6ab"
      },
      "source": [
        "dropout_rate= .5\n",
        "\n",
        "lr= .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "lstm_layer = Bidirectional(LSTM(256,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(embedd_seq)\n",
        "drop_layer = Dropout(dropout_rate)(lstm_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_rnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_rnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 3)\n",
        "print(de_rnn.summary())\n",
        "hist = de_rnn.fit(x = X_train_pad_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_pad_de, y_val_enc_de), \\\n",
        "                epochs = 50, batch_size = 64, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_rnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_rnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "de_rnn.save_weights(path+'/model/de_rnn')\n",
        "de_rnn.save(path+'/model/de_rnn.h5')\n",
        "\n",
        "all_tests(de_rnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9667\n",
            "0.8968\n",
            "0.3289\n",
            "0.1706\n",
            "\n",
            "de 0.9667\n",
            "fr 0.3289\n",
            "it 0.2069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRyXYkW50fkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e53534e-5749-4405-e192-e4bd4e46170b"
      },
      "source": [
        "# run transfer\n",
        "task = 'slc_de_tf_fr'\n",
        "model = 'rnn'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(de_rnn,'de_rnn',obs,freeze=False)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 6.0279 - accuracy: 0.0900 - val_loss: 3.9051 - val_accuracy: 0.0967\n",
            "Epoch 2/150\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 4.1166 - accuracy: 0.1500 - val_loss: 3.0723 - val_accuracy: 0.3080\n",
            "Epoch 3/150\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 3.2018 - accuracy: 0.4000 - val_loss: 2.9912 - val_accuracy: 0.3423\n",
            "Epoch 4/150\n",
            "50/50 [==============================] - 6s 126ms/step - loss: 2.5257 - accuracy: 0.5600 - val_loss: 2.7099 - val_accuracy: 0.3686\n",
            "Epoch 5/150\n",
            "50/50 [==============================] - 6s 126ms/step - loss: 1.7607 - accuracy: 0.6600 - val_loss: 2.4348 - val_accuracy: 0.5000\n",
            "Epoch 6/150\n",
            "50/50 [==============================] - 6s 127ms/step - loss: 1.4622 - accuracy: 0.7400 - val_loss: 2.2531 - val_accuracy: 0.5441\n",
            "Epoch 7/150\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.7526 - accuracy: 0.8300 - val_loss: 2.2579 - val_accuracy: 0.5676\n",
            "Epoch 8/150\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.7683 - accuracy: 0.8400 - val_loss: 1.9905 - val_accuracy: 0.6279\n",
            "Epoch 9/150\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.4817 - accuracy: 0.8900 - val_loss: 1.9794 - val_accuracy: 0.6209\n",
            "Epoch 10/150\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.6241 - accuracy: 0.9100 - val_loss: 2.0156 - val_accuracy: 0.6261\n",
            "Epoch 11/150\n",
            "50/50 [==============================] - 6s 123ms/step - loss: 0.3021 - accuracy: 0.9500 - val_loss: 2.0446 - val_accuracy: 0.6377\n",
            "Epoch 12/150\n",
            "50/50 [==============================] - 6s 123ms/step - loss: 0.1969 - accuracy: 0.9600 - val_loss: 2.1146 - val_accuracy: 0.6272\n",
            "Epoch 13/150\n",
            "50/50 [==============================] - 6s 123ms/step - loss: 0.0766 - accuracy: 0.9900 - val_loss: 2.1858 - val_accuracy: 0.6286\n",
            "Epoch 14/150\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 2.2267 - val_accuracy: 0.6198\n",
            "100 2\n",
            "Model: \"model_109\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.6646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [01:31<07:39, 91.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.6116\n",
            "it 0.0825\n",
            "None\n",
            "Epoch 1/150\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 4.3623 - accuracy: 0.1960 - val_loss: 2.2141 - val_accuracy: 0.5375\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 2.8747 - accuracy: 0.5480 - val_loss: 1.9006 - val_accuracy: 0.5193\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 2.1123 - accuracy: 0.6000 - val_loss: 1.5192 - val_accuracy: 0.6233\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 1.3767 - accuracy: 0.7960 - val_loss: 1.3869 - val_accuracy: 0.6857\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 1.0638 - accuracy: 0.8560 - val_loss: 1.4173 - val_accuracy: 0.7123\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.8135 - accuracy: 0.8400 - val_loss: 1.4259 - val_accuracy: 0.7155\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 0.5093 - accuracy: 0.9280 - val_loss: 1.5850 - val_accuracy: 0.6808\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.3183 - accuracy: 0.9160 - val_loss: 1.5326 - val_accuracy: 0.7344\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.2215 - accuracy: 0.9400 - val_loss: 1.4805 - val_accuracy: 0.7425\n",
            "250 2\n",
            "Model: \"model_110\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.7145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [02:56<05:58, 89.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.7405\n",
            "it 0.0495\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 3.4549 - accuracy: 0.3600 - val_loss: 1.8566 - val_accuracy: 0.5985\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 13s 54ms/step - loss: 2.2021 - accuracy: 0.6640 - val_loss: 1.3889 - val_accuracy: 0.7081\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 1.5309 - accuracy: 0.7700 - val_loss: 1.2104 - val_accuracy: 0.7554\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 1.1153 - accuracy: 0.8660 - val_loss: 1.1932 - val_accuracy: 0.7512\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.6475 - accuracy: 0.8920 - val_loss: 1.1470 - val_accuracy: 0.7772\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.6574 - accuracy: 0.8880 - val_loss: 1.0745 - val_accuracy: 0.7936\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 14s 58ms/step - loss: 0.5249 - accuracy: 0.9300 - val_loss: 1.0303 - val_accuracy: 0.8094\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.3723 - accuracy: 0.9440 - val_loss: 1.1212 - val_accuracy: 0.8024\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.1852 - accuracy: 0.9640 - val_loss: 1.1251 - val_accuracy: 0.8101\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 14s 55ms/step - loss: 0.1503 - accuracy: 0.9720 - val_loss: 1.1377 - val_accuracy: 0.8097\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 14s 54ms/step - loss: 0.1035 - accuracy: 0.9780 - val_loss: 1.1937 - val_accuracy: 0.8041\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 0.0803 - accuracy: 0.9800 - val_loss: 1.2615 - val_accuracy: 0.8052\n",
            "500 2\n",
            "Model: \"model_111\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.7239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [05:46<05:40, 113.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.8182\n",
            "it 0.0885\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 3.9501 - accuracy: 0.4310 - val_loss: 1.4763 - val_accuracy: 0.6591\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.2159 - accuracy: 0.7140 - val_loss: 1.0090 - val_accuracy: 0.7708\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 1.7023 - accuracy: 0.7800 - val_loss: 0.9423 - val_accuracy: 0.7463\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 1.1567 - accuracy: 0.8290 - val_loss: 0.8095 - val_accuracy: 0.8136\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.9276 - accuracy: 0.8690 - val_loss: 0.8918 - val_accuracy: 0.7978\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.6877 - accuracy: 0.9050 - val_loss: 0.7836 - val_accuracy: 0.8343\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.5308 - accuracy: 0.9060 - val_loss: 0.8074 - val_accuracy: 0.8290\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.3790 - accuracy: 0.9380 - val_loss: 0.7554 - val_accuracy: 0.8549\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.2559 - accuracy: 0.9610 - val_loss: 0.8330 - val_accuracy: 0.8423\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.2882 - accuracy: 0.9450 - val_loss: 0.8104 - val_accuracy: 0.8504\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.2757 - accuracy: 0.9510 - val_loss: 0.8606 - val_accuracy: 0.8462\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.2677 - accuracy: 0.9530 - val_loss: 0.8499 - val_accuracy: 0.8381\n",
            "Epoch 13/150\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.1336 - accuracy: 0.9710 - val_loss: 0.8482 - val_accuracy: 0.8483\n",
            "1000 4\n",
            "Model: \"model_112\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.7854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [08:24<04:14, 127.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.8515\n",
            "it 0.1154\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 3.2990 - accuracy: 0.5325 - val_loss: 0.9376 - val_accuracy: 0.7877\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 1.8111 - accuracy: 0.7910 - val_loss: 0.7935 - val_accuracy: 0.7912\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 1.1755 - accuracy: 0.8530 - val_loss: 0.6175 - val_accuracy: 0.8584\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.8271 - accuracy: 0.8990 - val_loss: 0.5820 - val_accuracy: 0.8693\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.5975 - accuracy: 0.9265 - val_loss: 0.5766 - val_accuracy: 0.8721\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.3965 - accuracy: 0.9450 - val_loss: 0.6187 - val_accuracy: 0.8704\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.2900 - accuracy: 0.9525 - val_loss: 0.6105 - val_accuracy: 0.8826\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.2768 - accuracy: 0.9615 - val_loss: 0.5719 - val_accuracy: 0.8886\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.1523 - accuracy: 0.9745 - val_loss: 0.5778 - val_accuracy: 0.8896\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.1596 - accuracy: 0.9740 - val_loss: 0.6099 - val_accuracy: 0.8879\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 0.0822 - accuracy: 0.9830 - val_loss: 0.6307 - val_accuracy: 0.8917\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 0.0792 - accuracy: 0.9835 - val_loss: 0.6396 - val_accuracy: 0.8945\n",
            "Epoch 13/150\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0778 - accuracy: 0.9850 - val_loss: 0.7017 - val_accuracy: 0.8791\n",
            "2000 8\n",
            "Model: \"model_113\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [10:45<02:11, 131.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.8876\n",
            "it 0.1124\n",
            "None\n",
            "Epoch 1/150\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 1.9799 - accuracy: 0.7360 - val_loss: 0.5706 - val_accuracy: 0.8721\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.7967 - accuracy: 0.8946 - val_loss: 0.5191 - val_accuracy: 0.8809\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 3s 41ms/step - loss: 0.5443 - accuracy: 0.9152 - val_loss: 0.4323 - val_accuracy: 0.9082\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.3212 - accuracy: 0.9494 - val_loss: 0.4179 - val_accuracy: 0.9124\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.2824 - accuracy: 0.9606 - val_loss: 0.4484 - val_accuracy: 0.9117\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 3s 41ms/step - loss: 0.2267 - accuracy: 0.9602 - val_loss: 0.4391 - val_accuracy: 0.9145\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.1385 - accuracy: 0.9742 - val_loss: 0.4482 - val_accuracy: 0.9215\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 3s 41ms/step - loss: 0.1168 - accuracy: 0.9796 - val_loss: 0.4827 - val_accuracy: 0.9159\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.1750 - accuracy: 0.9670 - val_loss: 0.5023 - val_accuracy: 0.9050\n",
            "5000 64\n",
            "Model: \"model_114\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_68 (Embedding)     (None, 34, 300)           6877800   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,057,011\n",
            "Trainable params: 8,057,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "de 0.9334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [11:19<00:00, 113.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fr 0.9075\n",
            "it 0.2459\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>rnn</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.7405</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.8515</td>\n",
              "      <td>0.8876</td>\n",
              "      <td>0.9075</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>rnn</td>\n",
              "      <td>slc_de_tf_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2743</td>\n",
              "      <td>0.4062</td>\n",
              "      <td>0.497</td>\n",
              "      <td>0.6068</td>\n",
              "      <td>0.6741</td>\n",
              "      <td>0.7132</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model          task      metric    0     100  ...    5000 10000 15000 25000 40000\n",
              "30   rnn  slc_de_tf_fr    accuracy  NaN  0.6116  ...  0.9075   NaN   NaN   NaN   NaN\n",
              "31   rnn  slc_de_tf_fr  avg_recall  NaN  0.2743  ...  0.7132   NaN   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ogCrAO5Jyl",
        "colab_type": "text"
      },
      "source": [
        "# DEFR -> IT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orj8MW-30-qa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c555a9b7-6245-4764-f6d8-6900dc896a80"
      },
      "source": [
        "X_train_pad = np.concatenate((X_train_pad_de,X_train_pad_fr),axis=0) \n",
        "X_val_pad  = np.concatenate((X_val_pad_de,X_val_pad_fr),axis=0) \n",
        "y_train_enc  = np.concatenate((y_train_enc_de,y_train_enc_fr),axis=0) \n",
        "y_val_enc  = np.concatenate((y_val_enc_de,y_val_enc_fr),axis=0)\n",
        "\n",
        "dropout_rate= .4\n",
        "lr = .0001\n",
        "#lr= .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "filter_sizes =  [3,4,5]\n",
        "num_filters = 75\n",
        "\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "lstm_layer = Bidirectional(LSTM(256,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(embedd_seq)\n",
        "drop_layer = Dropout(dropout_rate)(lstm_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_rnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_rnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 3)\n",
        "print(de_rnn.summary())\n",
        "hist = de_rnn.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                validation_data = (X_val_pad, y_val_enc), \\\n",
        "                epochs = 100, batch_size = 256, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_rnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_rnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_rnn.predict(X_pad_it)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_it),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_it)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "\n",
        "de_rnn.save_weights(path+'/model/defr_rnn')\n",
        "de_rnn.save(path+'/model/defr_rnn.h5')\n",
        "\n",
        "all_tests(de_rnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 34)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 34, 300)           6872400   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 75)                38475     \n",
            "=================================================================\n",
            "Total params: 8,051,611\n",
            "Trainable params: 8,051,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 4.2233 - accuracy: 0.0489 - val_loss: 4.0194 - val_accuracy: 0.1918\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 3.8674 - accuracy: 0.1866 - val_loss: 3.0118 - val_accuracy: 0.4366\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 2.9033 - accuracy: 0.4697 - val_loss: 1.6693 - val_accuracy: 0.6748\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 1.9961 - accuracy: 0.6587 - val_loss: 1.0708 - val_accuracy: 0.7949\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 1.4527 - accuracy: 0.7494 - val_loss: 0.8010 - val_accuracy: 0.8356\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 1.1125 - accuracy: 0.8056 - val_loss: 0.6643 - val_accuracy: 0.8528\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.9010 - accuracy: 0.8429 - val_loss: 0.5373 - val_accuracy: 0.8857\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.7307 - accuracy: 0.8714 - val_loss: 0.4321 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.6160 - accuracy: 0.8913 - val_loss: 0.3886 - val_accuracy: 0.9119\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.5146 - accuracy: 0.9087 - val_loss: 0.3369 - val_accuracy: 0.9190\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4427 - accuracy: 0.9211 - val_loss: 0.2907 - val_accuracy: 0.9327\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 9s 59ms/step - loss: 0.3682 - accuracy: 0.9328 - val_loss: 0.2844 - val_accuracy: 0.9355\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.3305 - accuracy: 0.9396 - val_loss: 0.2597 - val_accuracy: 0.9375\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.2929 - accuracy: 0.9459 - val_loss: 0.2537 - val_accuracy: 0.9393\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.2703 - accuracy: 0.9512 - val_loss: 0.2210 - val_accuracy: 0.9505\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.2301 - accuracy: 0.9560 - val_loss: 0.2135 - val_accuracy: 0.9517\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.2062 - accuracy: 0.9615 - val_loss: 0.2043 - val_accuracy: 0.9517\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1918 - accuracy: 0.9642 - val_loss: 0.2098 - val_accuracy: 0.9506\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1792 - accuracy: 0.9671 - val_loss: 0.1870 - val_accuracy: 0.9557\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1643 - accuracy: 0.9682 - val_loss: 0.1905 - val_accuracy: 0.9571\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.1449 - accuracy: 0.9712 - val_loss: 0.1971 - val_accuracy: 0.9546\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 10s 59ms/step - loss: 0.1393 - accuracy: 0.9730 - val_loss: 0.1777 - val_accuracy: 0.9589\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1232 - accuracy: 0.9755 - val_loss: 0.1798 - val_accuracy: 0.9592\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1118 - accuracy: 0.9775 - val_loss: 0.1723 - val_accuracy: 0.9602\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.1162 - accuracy: 0.9767 - val_loss: 0.1743 - val_accuracy: 0.9612\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.1034 - accuracy: 0.9785 - val_loss: 0.1791 - val_accuracy: 0.9602\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.0932 - accuracy: 0.9806 - val_loss: 0.1658 - val_accuracy: 0.9633\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.0840 - accuracy: 0.9825 - val_loss: 0.1713 - val_accuracy: 0.9618\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.0805 - accuracy: 0.9828 - val_loss: 0.1651 - val_accuracy: 0.9618\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.0790 - accuracy: 0.9832 - val_loss: 0.1655 - val_accuracy: 0.9623\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 9s 59ms/step - loss: 0.0780 - accuracy: 0.9837 - val_loss: 0.1708 - val_accuracy: 0.9618\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.0723 - accuracy: 0.9854 - val_loss: 0.1671 - val_accuracy: 0.9638\n",
            "0.9603\n",
            "0.8941\n",
            "0.9755\n",
            "0.8458\n",
            "0.1814\n",
            "0.1693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d521632ea24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mde_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/defr_rnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mall_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_rnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_pad_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: all_tests() missing 1 required positional argument: 'y_it'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdEPf2o25M7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "138a10c9-92e3-41a4-af63-9f8835507b3a"
      },
      "source": [
        "X_train_pad = np.concatenate((X_train_pad_de,X_train_pad_fr),axis=0) \n",
        "X_val_pad  = np.concatenate((X_val_pad_de,X_val_pad_fr),axis=0) \n",
        "y_train_enc  = np.concatenate((y_train_enc_de,y_train_enc_fr),axis=0) \n",
        "y_val_enc  = np.concatenate((y_val_enc_de,y_val_enc_fr),axis=0)\n",
        "\n",
        "dropout_rate= .4\n",
        "lr = .0001\n",
        "#lr= .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "filter_sizes =  [3,4,5]\n",
        "num_filters = 75\n",
        "\n",
        "                  \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "    maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate)(falt_layer)\n",
        "\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_rnn = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_rnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 3)\n",
        "print(de_rnn.summary())\n",
        "hist = de_rnn.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                validation_data = (X_val_pad, y_val_enc), \\\n",
        "                epochs = 100, batch_size = 256, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_test = de_rnn.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_de),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_de)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_rnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "y_pred_test = de_rnn.predict(X_pad_it)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print(round(accuracy_score(y_pred_test, y_it),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_it)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "\n",
        "\n",
        "de_rnn.save_weights(path+'/model/defr_rnn')\n",
        "de_rnn.save(path+'/model/defr_rnn.h5')\n",
        "\n",
        "all_tests(de_rnn,X_test_pad_de,X_test_pad_fr,X_pad_it)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 300)      6872400     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 32, 75)       67575       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 31, 75)       90075       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 30, 75)       112575      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 75)        0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 1, 75)        0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 1, 75)        0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 75)        0           max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "                                                                 max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,159,575\n",
            "Trainable params: 7,159,575\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 4.3034 - accuracy: 0.0364 - val_loss: 4.0515 - val_accuracy: 0.4098\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 4.0426 - accuracy: 0.1774 - val_loss: 3.7819 - val_accuracy: 0.5852\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 3.7980 - accuracy: 0.3299 - val_loss: 3.4266 - val_accuracy: 0.6651\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 3.4892 - accuracy: 0.4994 - val_loss: 2.9644 - val_accuracy: 0.7170\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 3.0965 - accuracy: 0.6122 - val_loss: 2.4144 - val_accuracy: 0.7921\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 2.6545 - accuracy: 0.6886 - val_loss: 1.8754 - val_accuracy: 0.8164\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 2.2227 - accuracy: 0.7436 - val_loss: 1.4729 - val_accuracy: 0.8289\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.8293 - accuracy: 0.7794 - val_loss: 1.1517 - val_accuracy: 0.8491\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 1.5340 - accuracy: 0.8091 - val_loss: 0.9424 - val_accuracy: 0.8661\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.2848 - accuracy: 0.8362 - val_loss: 0.7765 - val_accuracy: 0.8865\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1025 - accuracy: 0.8559 - val_loss: 0.6569 - val_accuracy: 0.8972\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.9734 - accuracy: 0.8680 - val_loss: 0.5702 - val_accuracy: 0.9058\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.8607 - accuracy: 0.8858 - val_loss: 0.5046 - val_accuracy: 0.9128\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.7613 - accuracy: 0.8948 - val_loss: 0.4517 - val_accuracy: 0.9176\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.6789 - accuracy: 0.9027 - val_loss: 0.4093 - val_accuracy: 0.9206\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.6164 - accuracy: 0.9115 - val_loss: 0.3724 - val_accuracy: 0.9252\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.5626 - accuracy: 0.9192 - val_loss: 0.3447 - val_accuracy: 0.9306\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.5156 - accuracy: 0.9237 - val_loss: 0.3201 - val_accuracy: 0.9341\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.4726 - accuracy: 0.9283 - val_loss: 0.3004 - val_accuracy: 0.9372\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.4322 - accuracy: 0.9342 - val_loss: 0.2815 - val_accuracy: 0.9409\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.4039 - accuracy: 0.9387 - val_loss: 0.2640 - val_accuracy: 0.9450\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.3731 - accuracy: 0.9425 - val_loss: 0.2517 - val_accuracy: 0.9464\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.3460 - accuracy: 0.9457 - val_loss: 0.2383 - val_accuracy: 0.9498\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.3216 - accuracy: 0.9483 - val_loss: 0.2259 - val_accuracy: 0.9521\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.2965 - accuracy: 0.9521 - val_loss: 0.2151 - val_accuracy: 0.9520\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.2798 - accuracy: 0.9532 - val_loss: 0.2061 - val_accuracy: 0.9542\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.2590 - accuracy: 0.9572 - val_loss: 0.1976 - val_accuracy: 0.9567\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.2434 - accuracy: 0.9599 - val_loss: 0.1888 - val_accuracy: 0.9571\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.2275 - accuracy: 0.9611 - val_loss: 0.1849 - val_accuracy: 0.9584\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.2141 - accuracy: 0.9630 - val_loss: 0.1775 - val_accuracy: 0.9589\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.2025 - accuracy: 0.9654 - val_loss: 0.1718 - val_accuracy: 0.9610\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1828 - accuracy: 0.9684 - val_loss: 0.1664 - val_accuracy: 0.9614\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.1780 - accuracy: 0.9691 - val_loss: 0.1611 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1678 - accuracy: 0.9697 - val_loss: 0.1573 - val_accuracy: 0.9633\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1609 - accuracy: 0.9701 - val_loss: 0.1528 - val_accuracy: 0.9652\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1477 - accuracy: 0.9729 - val_loss: 0.1487 - val_accuracy: 0.9666\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1411 - accuracy: 0.9742 - val_loss: 0.1443 - val_accuracy: 0.9670\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1333 - accuracy: 0.9752 - val_loss: 0.1396 - val_accuracy: 0.9677\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1243 - accuracy: 0.9766 - val_loss: 0.1381 - val_accuracy: 0.9674\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1228 - accuracy: 0.9771 - val_loss: 0.1342 - val_accuracy: 0.9679\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.1142 - accuracy: 0.9792 - val_loss: 0.1328 - val_accuracy: 0.9691\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.1074 - accuracy: 0.9796 - val_loss: 0.1300 - val_accuracy: 0.9702\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.0980 - accuracy: 0.9811 - val_loss: 0.1266 - val_accuracy: 0.9704\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.0953 - accuracy: 0.9815 - val_loss: 0.1245 - val_accuracy: 0.9704\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.0900 - accuracy: 0.9834 - val_loss: 0.1219 - val_accuracy: 0.9704\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.0857 - accuracy: 0.9826 - val_loss: 0.1196 - val_accuracy: 0.9711\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0816 - accuracy: 0.9839 - val_loss: 0.1180 - val_accuracy: 0.9716\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0775 - accuracy: 0.9847 - val_loss: 0.1178 - val_accuracy: 0.9719\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.0722 - accuracy: 0.9852 - val_loss: 0.1154 - val_accuracy: 0.9723\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0690 - accuracy: 0.9863 - val_loss: 0.1128 - val_accuracy: 0.9726\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0665 - accuracy: 0.9870 - val_loss: 0.1123 - val_accuracy: 0.9733\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0620 - accuracy: 0.9875 - val_loss: 0.1112 - val_accuracy: 0.9738\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.0625 - accuracy: 0.9870 - val_loss: 0.1095 - val_accuracy: 0.9741\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.0587 - accuracy: 0.9880 - val_loss: 0.1085 - val_accuracy: 0.9748\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.0551 - accuracy: 0.9884 - val_loss: 0.1071 - val_accuracy: 0.9747\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.0527 - accuracy: 0.9892 - val_loss: 0.1056 - val_accuracy: 0.9752\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0505 - accuracy: 0.9895 - val_loss: 0.1047 - val_accuracy: 0.9754\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.1033 - val_accuracy: 0.9748\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.0462 - accuracy: 0.9906 - val_loss: 0.1031 - val_accuracy: 0.9754\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.1019 - val_accuracy: 0.9757\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0438 - accuracy: 0.9906 - val_loss: 0.1010 - val_accuracy: 0.9763\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0402 - accuracy: 0.9913 - val_loss: 0.1006 - val_accuracy: 0.9766\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.0395 - accuracy: 0.9910 - val_loss: 0.0995 - val_accuracy: 0.9770\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0356 - accuracy: 0.9921 - val_loss: 0.0994 - val_accuracy: 0.9767\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0356 - accuracy: 0.9927 - val_loss: 0.0986 - val_accuracy: 0.9769\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0323 - accuracy: 0.9931 - val_loss: 0.0980 - val_accuracy: 0.9775\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0347 - accuracy: 0.9923 - val_loss: 0.0975 - val_accuracy: 0.9772\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0318 - accuracy: 0.9934 - val_loss: 0.0967 - val_accuracy: 0.9770\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.0956 - val_accuracy: 0.9782\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0290 - accuracy: 0.9935 - val_loss: 0.0962 - val_accuracy: 0.9779\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.0251 - accuracy: 0.9945 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
            "0.9751\n",
            "0.9345\n",
            "0.9807\n",
            "0.8626\n",
            "0.2459\n",
            "0.2072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3692568bca2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mde_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/defr_rnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mall_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_rnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_pad_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: all_tests() missing 1 required positional argument: 'y_it'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW7zX9PVMrdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36cc9c3f-76f7-4c4f-e07d-27c23d2c272a"
      },
      "source": [
        "y_pred_test = de_rnn.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "print(round(accuracy_score(y_pred_test, y_test_fr),4))\n",
        "print(round(balanced_accuracy_score(y_pred_test, y_test_fr)*len(np.unique(y_pred_test))/no_Classes,4))\n",
        "print(classification_report(y_pred_test, y_test_fr))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9807\n",
            "0.8626\n",
            "                                                                       precision    recall  f1-score   support\n",
            "\n",
            "                                                            1111_Rice       1.00      0.97      0.99        38\n",
            "                                        1112_Flours and other cereals       1.00      1.00      1.00         6\n",
            "                                                           1113_Bread       1.00      1.00      1.00        55\n",
            "                                           1114_Other bakery products       0.91      0.93      0.92        57\n",
            "                                                1115_Pizza and quiche       1.00      0.96      0.98        23\n",
            "                                     1116_Pasta products and couscous       0.99      0.97      0.98       115\n",
            "                                               1117_Breakfast cereals       1.00      0.98      0.99        55\n",
            "                                           1118_Other cereal products       1.00      1.00      1.00         4\n",
            "                                                   1121_Beef and veal       1.00      1.00      1.00        33\n",
            "                                                            1122_Pork       1.00      0.88      0.94        17\n",
            "                                                   1123_Lamb and goat       1.00      1.00      1.00         5\n",
            "                                                         1124_Poultry       0.57      1.00      0.73         4\n",
            "                                                     1125_Other meats       1.00      0.50      0.67         4\n",
            "                                                    1126_Edible offal       1.00      1.00      1.00         3\n",
            "                                    1127_Dried, salted or smoked meat       0.85      1.00      0.92        17\n",
            "                                         1128_Other meat preparations       1.00      0.46      0.63        13\n",
            "                                                     1132_Frozen fish       1.00      1.00      1.00         6\n",
            "                                        1133_Fresh or chilled seafood       1.00      0.82      0.90        11\n",
            "                                                  1134_Frozen seafood       1.00      0.67      0.80         6\n",
            "                        1135_Dried, smoked or salted fish and seafood       1.00      1.00      1.00         7\n",
            "1136_Other preserved or processed fish and seafood-based preparations       0.81      1.00      0.90        13\n",
            "                                                1141_Fresh whole milk       1.00      1.00      1.00        19\n",
            "                                              1142_Fresh low fat milk       1.00      1.00      1.00        63\n",
            "                                                  1143_Preserved milk       1.00      1.00      1.00         8\n",
            "                                                         1144_Yoghurt       1.00      1.00      1.00        72\n",
            "                                                 1145_Cheese and curd       1.00      1.00      1.00       337\n",
            "                                             1146_Other milk products       0.94      1.00      0.97        17\n",
            "                                                            1147_Eggs       1.00      1.00      1.00         2\n",
            "                                                          1151_Butter       1.00      1.00      1.00        47\n",
            "                              1152_Margarine and other vegetable fats       1.00      1.00      1.00        23\n",
            "                                                       1153_Olive oil       1.00      1.00      1.00        32\n",
            "                                               1154_Other edible oils       1.00      0.96      0.98        28\n",
            "                                          1161_Fresh or chilled fruit       0.87      1.00      0.93        13\n",
            "                                                    1162_Frozen fruit       1.00      1.00      1.00         2\n",
            "                                            1163_Dried fruit and nuts       0.94      0.88      0.91        17\n",
            "                        1164_Preserved fruit and fruit-based products       1.00      1.00      1.00        18\n",
            "1171_Fresh or chilled vegetables other than potatoes and other tubers       1.00      1.00      1.00         9\n",
            "          1172_Frozen vegetables other than potatoes and other tubers       0.86      1.00      0.92         6\n",
            "       1173_Dried vegetables, other preserved or processed vegetables       0.88      1.00      0.93        21\n",
            "                                                        1174_Potatoes       1.00      1.00      1.00         6\n",
            "                                                          1175_Crisps       1.00      0.99      0.99        75\n",
            "                   1176_Other tubers and products of tuber vegetables       0.00      0.00      0.00         2\n",
            "                                                           1181_Sugar       0.88      1.00      0.93        21\n",
            "                                      1182_Jams, marmalades and honey       0.92      1.00      0.96        23\n",
            "                                                       1183_Chocolate       0.99      0.98      0.98       226\n",
            "                                          1184_Confectionery products       0.92      0.95      0.94        62\n",
            "                                       1185_Edible ices and ice cream       1.00      0.97      0.99        37\n",
            "                                    1186_Artificial sugar substitutes       1.00      0.71      0.83         7\n",
            "                                              1191_Sauces, condiments       0.90      1.00      0.95        19\n",
            "                                 1192_Salt, spices and culinary herbs       1.00      1.00      1.00        23\n",
            "                                                       1193_Baby food       1.00      1.00      1.00        54\n",
            "                                                1194_Ready-made meals       0.90      0.90      0.90        31\n",
            "                                      1199_Other food products n.e.c.       0.85      0.89      0.87        19\n",
            "                                                          1211_Coffee       1.00      1.00      1.00       232\n",
            "                                                             1212_Tea       1.00      1.00      1.00        18\n",
            "                                    1213_Cocoa and powdered chocolate       0.94      1.00      0.97        15\n",
            "                                        1221_Mineral or spring waters       1.00      1.00      1.00        13\n",
            "                                                     1222_Soft drinks       1.00      1.00      1.00        75\n",
            "                                      1223_Fruit and vegetable juices       1.00      1.00      1.00       116\n",
            "                                            2111_Spirits and liqueurs       0.88      1.00      0.93        14\n",
            "                                           2112_Alcoholic soft drinks       1.00      1.00      1.00         2\n",
            "                                                2121_Wine from grapes       1.00      1.00      1.00       310\n",
            "                                          2122_Wine from other fruits       1.00      1.00      1.00         5\n",
            "                                               2124_Wine-based drinks       1.00      0.60      0.75         5\n",
            "                                                      2131_Lager beer       0.80      1.00      0.89         8\n",
            "                                            2132_Other alcoholic beer       1.00      0.70      0.82        20\n",
            "                                      2133_Low and non-alcoholic beer       1.00      1.00      1.00         5\n",
            "                                               2134_Beer-based drinks       0.56      1.00      0.71         5\n",
            "                                                        9999_Non-Food       0.98      1.00      0.99       181\n",
            "\n",
            "                                                             accuracy                           0.98      2855\n",
            "                                                            macro avg       0.94      0.94      0.93      2855\n",
            "                                                         weighted avg       0.98      0.98      0.98      2855\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWE6wAk4DV25",
        "colab_type": "text"
      },
      "source": [
        "## Pool - CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjMiR-OT5M_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_pool(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,\n",
        "             X_train_emb_fr,y_train_enc_fr,X_val_emb_fr,y_val_enc_fr,X_test_emb_fr,y_test_fr,\n",
        "             X_it,y_enc_it,y_it,\n",
        "             class_weight_dict,no):\n",
        "   \n",
        "    idx_fr = np.random.randint(len(X_train_emb_fr), size=no+50)\n",
        "    idx_de = np.random.randint(len(X_train_emb_de), size=no+50)\n",
        "    idx_it = np.random.randint(len(X_it), size=no)\n",
        "    idx_test_it = [a for a in range(0,len(X_it)) if a not in idx_it]\n",
        "\n",
        "    X_train_emb =  np.concatenate((X_train_emb_de[:100], X_train_emb_fr))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[:100], y_train_enc_fr))\n",
        "    print('before_it',len(X_train_emb), len(X_it[idx_it[50:]]))\n",
        "\n",
        "    for i in range(0,50):\n",
        "        X_train_emb =  np.concatenate((X_train_emb, X_it[idx_it[50:]]))\n",
        "        y_train_enc =  np.concatenate((y_train_enc, y_enc_it[idx_it[50:],:]))\n",
        "\n",
        "    print('after_it',len(X_train_emb), len(X_it[idx_it[50:]]))\n",
        "\n",
        "    X_val_emb =  np.concatenate((X_val_emb_de[:100], X_val_emb_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de[:100], y_val_enc_fr))\n",
        "    X_val_emb =  np.concatenate((X_val_emb,  X_it[idx_it[:50]]))\n",
        "    y_val_enc =  np.concatenate((y_val_enc, y_enc_it[idx_it[:50],:]))\n",
        "    print('after_it',len(X_val_emb), len(X_it[idx_it[:50]]))\n",
        "\n",
        "\n",
        "    dropout_rate= .1\n",
        "    lr = .01\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    pool_layer = GlobalAveragePooling1D()(embedd_seq)   \n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    cnn_defr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    cnn_defr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 2)\n",
        "\n",
        "    \n",
        "    hist = cnn_defr.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "\n",
        "    task_fr = task + '_fr'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_fr)\n",
        "    fill_df_res(y_pred_test,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_de)\n",
        "    fill_df_res(y_pred_test,y_test_de,no,task_de)\n",
        "\n",
        "    task_it = task + '_it'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_it[idx_test_it])\n",
        "    fill_df_res(y_pred_test,y_it.iloc[idx_test_it],no,task_it)\n",
        "\n",
        "    all_tests(cnn_defr,X_test_pad_de,X_test_pad_fr,X_it[idx_test_it],y_it.iloc[idx_test_it])\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTeATmiEDjwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36f086ee-49b0-4688-edd0-0b08fdeb9007"
      },
      "source": [
        "task = 'mlc_defrit'\n",
        "model = 'Avg_pool'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_de'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_it'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500]):\n",
        "     run_ml_pool(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\\\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\\\n",
        "             X_pad_it,y_enc_it,y_it,class_weight_dict_de_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before_it 17224 50\n",
            "after_it 19724 50\n",
            "after_it 3004 50\n",
            "Epoch 1/50\n",
            "78/78 [==============================] - 7s 84ms/step - loss: 1.4657 - accuracy: 0.7921 - val_loss: 0.4069 - val_accuracy: 0.9111\n",
            "Epoch 2/50\n",
            "78/78 [==============================] - 6s 82ms/step - loss: 0.2088 - accuracy: 0.9612 - val_loss: 0.2831 - val_accuracy: 0.9361\n",
            "Epoch 3/50\n",
            "78/78 [==============================] - 6s 82ms/step - loss: 0.0890 - accuracy: 0.9812 - val_loss: 0.2304 - val_accuracy: 0.9467\n",
            "Epoch 4/50\n",
            "78/78 [==============================] - 6s 83ms/step - loss: 0.0490 - accuracy: 0.9887 - val_loss: 0.2098 - val_accuracy: 0.9547\n",
            "Epoch 5/50\n",
            "78/78 [==============================] - 6s 82ms/step - loss: 0.0331 - accuracy: 0.9924 - val_loss: 0.2007 - val_accuracy: 0.9571\n",
            "Epoch 6/50\n",
            "78/78 [==============================] - 6s 83ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.2040 - val_accuracy: 0.9577\n",
            "Epoch 7/50\n",
            "78/78 [==============================] - 6s 82ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: 0.2025 - val_accuracy: 0.9611\n",
            "\n",
            "de 0.6402\n",
            "fr 0.9804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 1/3 [00:47<01:34, 47.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.5456\n",
            "before_it 17224 200\n",
            "after_it 27224 200\n",
            "after_it 3004 50\n",
            "Epoch 1/50\n",
            "107/107 [==============================] - 9s 84ms/step - loss: 1.0899 - accuracy: 0.8048 - val_loss: 0.3654 - val_accuracy: 0.9198\n",
            "Epoch 2/50\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.1285 - accuracy: 0.9741 - val_loss: 0.2355 - val_accuracy: 0.9481\n",
            "Epoch 3/50\n",
            "107/107 [==============================] - 9s 84ms/step - loss: 0.0587 - accuracy: 0.9878 - val_loss: 0.2165 - val_accuracy: 0.9531\n",
            "Epoch 4/50\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 0.1877 - val_accuracy: 0.9607\n",
            "Epoch 5/50\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.1886 - val_accuracy: 0.9611\n",
            "Epoch 6/50\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.1808 - val_accuracy: 0.9650\n",
            "Epoch 7/50\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.1846 - val_accuracy: 0.9630\n",
            "Epoch 8/50\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1847 - val_accuracy: 0.9660\n",
            "\n",
            "de 0.6313\n",
            "fr 0.9807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 2/3 [02:00<00:54, 54.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.6893\n",
            "before_it 17224 450\n",
            "after_it 39724 450\n",
            "after_it 3004 50\n",
            "Epoch 1/50\n",
            "156/156 [==============================] - 12s 80ms/step - loss: 0.7771 - accuracy: 0.8649 - val_loss: 0.3189 - val_accuracy: 0.9314\n",
            "Epoch 2/50\n",
            "156/156 [==============================] - 12s 79ms/step - loss: 0.0755 - accuracy: 0.9856 - val_loss: 0.2279 - val_accuracy: 0.9461\n",
            "Epoch 3/50\n",
            "156/156 [==============================] - 13s 85ms/step - loss: 0.0330 - accuracy: 0.9921 - val_loss: 0.1884 - val_accuracy: 0.9581\n",
            "Epoch 4/50\n",
            "156/156 [==============================] - 12s 79ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1739 - val_accuracy: 0.9637\n",
            "Epoch 5/50\n",
            "156/156 [==============================] - 12s 79ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.1673 - val_accuracy: 0.9664\n",
            "Epoch 6/50\n",
            "156/156 [==============================] - 12s 79ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1752 - val_accuracy: 0.9670\n",
            "Epoch 7/50\n",
            "156/156 [==============================] - 12s 79ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.1741 - val_accuracy: 0.9690\n",
            "\n",
            "de 0.6524\n",
            "fr 0.9793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 3/3 [03:29<00:00, 69.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it 0.7662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [model, task, metric, 0, 100, 250, 500, 1000, 2000, 5000, 10000, 15000, 25000, 40000]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgQaVuqJ3lqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9607158b-6847-4b9a-db2c-303f7c06863e"
      },
      "source": [
        "df_results[df_results['model']=='Avg_pool']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.9807</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6313</td>\n",
              "      <td>0.6524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4002</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Avg_pool</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model           task      metric    0  ... 10000 15000 25000 40000\n",
              "12  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "13  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "14  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "15  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "16  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "17  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "18  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "19  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "20  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "21  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "22  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "23  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "30  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "31  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "32  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "33  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "34  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "35  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "36  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "37  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "38  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "39  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "40  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "41  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "42  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "43  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "44  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "45  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "46  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "47  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "48  Avg_pool  mlc_defrit_fr    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "49  Avg_pool  mlc_defrit_de    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "50  Avg_pool  mlc_defrit_it    accuracy  NaN  ...   NaN   NaN   NaN   NaN\n",
              "51  Avg_pool  mlc_defrit_fr  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "52  Avg_pool  mlc_defrit_de  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "53  Avg_pool  mlc_defrit_it  avg_recall  NaN  ...   NaN   NaN   NaN   NaN\n",
              "\n",
              "[36 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVG4YNgv2BwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "19ebd373-c18e-4d2d-8e60-e5f06ba305c4"
      },
      "source": [
        "df_results[df_results['model']=='CNN']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "      <th>40000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9811</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>0.9818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4617</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.6739</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8695</td>\n",
              "      <td>0.8647</td>\n",
              "      <td>0.8736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2507</td>\n",
              "      <td>0.3049</td>\n",
              "      <td>0.3548</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9811</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>0.9818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4617</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.6739</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_fr</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8695</td>\n",
              "      <td>0.8647</td>\n",
              "      <td>0.8736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_de</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2507</td>\n",
              "      <td>0.3049</td>\n",
              "      <td>0.3548</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CNN</td>\n",
              "      <td>mlc_defrit_it</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model           task      metric    0     100  ... 5000 10000 15000 25000 40000\n",
              "0    CNN  mlc_defrit_fr    accuracy  NaN  0.9811  ...  NaN   NaN   NaN   NaN   NaN\n",
              "1    CNN  mlc_defrit_de    accuracy  NaN  0.4617  ...  NaN   NaN   NaN   NaN   NaN\n",
              "2    CNN  mlc_defrit_it    accuracy  NaN     NaN  ...  NaN   NaN   NaN   NaN   NaN\n",
              "3    CNN  mlc_defrit_fr  avg_recall  NaN  0.8695  ...  NaN   NaN   NaN   NaN   NaN\n",
              "4    CNN  mlc_defrit_de  avg_recall  NaN  0.2507  ...  NaN   NaN   NaN   NaN   NaN\n",
              "5    CNN  mlc_defrit_it  avg_recall  NaN     NaN  ...  NaN   NaN   NaN   NaN   NaN\n",
              "6    CNN  mlc_defrit_fr    accuracy  NaN  0.9811  ...  NaN   NaN   NaN   NaN   NaN\n",
              "7    CNN  mlc_defrit_de    accuracy  NaN  0.4617  ...  NaN   NaN   NaN   NaN   NaN\n",
              "8    CNN  mlc_defrit_it    accuracy  NaN     NaN  ...  NaN   NaN   NaN   NaN   NaN\n",
              "9    CNN  mlc_defrit_fr  avg_recall  NaN  0.8695  ...  NaN   NaN   NaN   NaN   NaN\n",
              "10   CNN  mlc_defrit_de  avg_recall  NaN  0.2507  ...  NaN   NaN   NaN   NaN   NaN\n",
              "11   CNN  mlc_defrit_it  avg_recall  NaN     NaN  ...  NaN   NaN   NaN   NaN   NaN\n",
              "\n",
              "[12 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_nNrfyNRpm",
        "colab_type": "text"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkBjjU35M4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_CNN1D(X_train_emb_de,y_train_enc_de,X_val_emb_de,y_val_enc_de,X_test_emb_de,y_test_de,\n",
        "             X_train_emb_fr,y_train_enc_fr,X_val_emb_fr,y_val_enc_fr,X_test_emb_fr,y_test_fr,\n",
        "             X_it,y_enc_it,y_it,\n",
        "             class_weight_dict,no):\n",
        "   \n",
        "    idx_fr = np.random.randint(len(X_train_emb_fr), size=no+50)\n",
        "    idx_de = np.random.randint(len(X_train_emb_de), size=no+50)\n",
        "    idx_it = np.random.randint(len(X_it), size=no)\n",
        "    idx_test_it = [a for a in range(0,len(X_it)) if a not in idx_it]\n",
        "\n",
        "    X_train_emb =  np.concatenate((X_train_emb_de, X_train_emb_fr))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de, y_train_enc_fr))\n",
        "    print('before_it',len(X_train_emb), len(X_it[idx_it[50:]]))\n",
        "\n",
        "    for i in range(0,50):\n",
        "        X_train_emb =  np.concatenate((X_train_emb, X_it[idx_it[50:]]))\n",
        "        y_train_enc =  np.concatenate((y_train_enc, y_enc_it[idx_it[50:],:]))\n",
        "\n",
        "    print('after_it',len(X_train_emb), len(X_it[idx_it[50:]]))\n",
        "\n",
        "    X_val_emb =  np.concatenate((X_val_emb_de, X_val_emb_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "    X_val_emb =  np.concatenate((X_val_emb,  X_it[idx_it[:50]]))\n",
        "    y_val_enc =  np.concatenate((y_val_enc, y_enc_it[idx_it[:50],:]))\n",
        "    print('after_it',len(X_val_emb), len(X_it[idx_it[:50]]))\n",
        "\n",
        "\n",
        "    dropout_rate= .6\n",
        "    filter_sizes = [1,5]\n",
        "    num_filters = 100\n",
        "    lr = .002\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                          \n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "        maxpool_pool.append(MaxPooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    #dense_layer = Dense(150,activation='tanh')(falt_layer)\n",
        "\n",
        "\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    cnn_defr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    cnn_defr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 1)\n",
        "\n",
        "    \n",
        "    hist = cnn_defr.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_emb, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "\n",
        "    task_fr = task + '_fr'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_fr)\n",
        "    fill_df_res(y_pred_test,y_test_fr,no,task_fr)\n",
        "\n",
        "    task_de = task + '_de'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_test_pad_de)\n",
        "    fill_df_res(y_pred_test,y_test_de,no,task_de)\n",
        "\n",
        "    task_it = task + '_it'\n",
        "    y_pred_test = pred_encode(cnn_defr,X_it[idx_test_it])\n",
        "    fill_df_res(y_pred_test,y_it.iloc[idx_test_it],no,task_it)\n",
        "\n",
        "    all_tests(cnn_defr,X_test_pad_de,X_test_pad_fr,X_it[idx_test_it],y_it.iloc[idx_test_it])\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNVDkz3hDbg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "11d803ed-ce11-4696-ef25-2947f4a5bb29"
      },
      "source": [
        "task = 'mlc_defrit'\n",
        "model = 'CNN'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    task_l = task + '_fr'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_de'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "    task_l = task + '_it'\n",
        "    df_results = df_results.append({'model': model,'task':task_l,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500]):\n",
        "     run_ml_CNN1D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\\\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\\\n",
        "             X_pad_it,y_enc_it,y_it,class_weight_dict_de_fr,obs)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before_it 40721 50\n",
            "after_it 43221 50\n",
            "after_it 6837 50\n",
            "Epoch 1/50\n",
            "169/169 [==============================] - 65s 382ms/step - loss: 2.4967 - accuracy: 0.6118 - val_loss: 0.4106 - val_accuracy: 0.9105\n",
            "Epoch 2/50\n",
            "169/169 [==============================] - 64s 380ms/step - loss: 0.5979 - accuracy: 0.9085 - val_loss: 0.2215 - val_accuracy: 0.9501\n",
            "Epoch 3/50\n",
            "169/169 [==============================] - 65s 384ms/step - loss: 0.3229 - accuracy: 0.9454 - val_loss: 0.1691 - val_accuracy: 0.9615\n",
            "Epoch 4/50\n",
            "169/169 [==============================] - 65s 388ms/step - loss: 0.2172 - accuracy: 0.9615 - val_loss: 0.1522 - val_accuracy: 0.9658\n",
            "Epoch 5/50\n",
            "169/169 [==============================] - 67s 394ms/step - loss: 0.1514 - accuracy: 0.9712 - val_loss: 0.1428 - val_accuracy: 0.9684\n",
            "Epoch 6/50\n",
            "169/169 [==============================] - 64s 380ms/step - loss: 0.1232 - accuracy: 0.9769 - val_loss: 0.1366 - val_accuracy: 0.9725\n",
            "Epoch 7/50\n",
            "169/169 [==============================] - 64s 378ms/step - loss: 0.0949 - accuracy: 0.9803 - val_loss: 0.1332 - val_accuracy: 0.9724\n",
            "Epoch 8/50\n",
            "169/169 [==============================] - 64s 378ms/step - loss: 0.0815 - accuracy: 0.9817 - val_loss: 0.1346 - val_accuracy: 0.9728\n",
            "Epoch 9/50\n",
            "169/169 [==============================] - 65s 383ms/step - loss: 0.0652 - accuracy: 0.9856 - val_loss: 0.1405 - val_accuracy: 0.9715\n",
            "Epoch 10/50\n",
            "169/169 [==============================] - 63s 376ms/step - loss: 0.0630 - accuracy: 0.9855 - val_loss: 0.1437 - val_accuracy: 0.9743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-623b58c86af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m      \u001b[0mrun_ml_CNN1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_de\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mX_train_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_fr\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mX_pad_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_enc_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight_dict_de_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-4b4d923d3a4d>\u001b[0m in \u001b[0;36mrun_ml_CNN1D\u001b[0;34m(X_train_emb_de, y_train_enc_de, X_val_emb_de, y_val_enc_de, X_test_emb_de, y_test_de, X_train_emb_fr, y_train_enc_fr, X_val_emb_fr, y_val_enc_fr, X_test_emb_fr, y_test_fr, X_it, y_enc_it, y_it, class_weight_dict, no)\u001b[0m\n\u001b[1;32m     58\u001b[0m    \u001b[0mtask_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_fr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m    \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_defr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m    \u001b[0mfill_df_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m    \u001b[0mtask_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_de'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fill_df_res() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wa5sPn0qy0gP"
      },
      "source": [
        "# Shop to Shop Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NMQBhs9Ey0gQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d44f7f5a-73be-4697-950d-dc40ec3b2099"
      },
      "source": [
        "df_rewe = df_de[df_de['shop'] == 'shop.rewe.de']\n",
        "df_cap= df_de[df_de['shop'] == 'CAP MARKT']\n",
        "df_rewe2 = df_de[df_de['shop'] == 'REWE']\n",
        "df_rewe3 = df_de[df_de['shop'] == 'ALDI Nord']\n",
        "df_rewe4 = df_de[df_de['shop'] == 'ALDI Süd']\n",
        "df_rewe5 = df_de[df_de['shop'] == 'Treff 3000']\n",
        "df_rewe6 = df_de[df_de['shop'] == 'Spar']\n",
        "\n",
        "df_rewe_united = df_rewe.append(df_cap)#.append(df_rewe2).append(df_rewe3).append(df_rewe4).append(df_rewe5).append(df_rewe6)\n",
        "df_edeka= df_de[df_de['shop'] == 'REWE']\n",
        "df_real = df_de[df_de['shop'] == 'EDEKA Center']\n",
        "\n",
        "len(df_rewe),len(df_edeka),len(df_real)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9124, 2003, 1855)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GLy_5Mumy0gS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "53823d8a-6332-4e78-c640-69c751c56060"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_train_abs(df):\n",
        "    X_train, X_val_test, y_train, y_val_test  = train_test_split(df['text'], df['cc5'], random_state=42, shuffle=True)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val_test , y_val_test, train_size=.5,random_state=42)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train_de_rewe, X_val_de_rewe, X_test_de_rewe, y_train_de_rewe, y_val_de_rewe, y_test_de_rewe = split_train_abs(df_rewe)\n",
        "X_train_de_rewe, X_val_de_rewe2, X_test_de_rewe2, y_train_de_rewe2, y_val_de_rewe2, y_test_de_rewe2 = split_train_abs(df_rewe_united)\n",
        "\n",
        "X_test_tokens_de = tokenizer_all.texts_to_sequences(X_test_de)\n",
        "\n",
        "X_train_pad_de = pad_sequences(X_train_tokens_de,maxlen=seq_len, padding='post')\n",
        "\n",
        "\n",
        "\n",
        "X_train_emb_de_rewe = np.array(list(model_helper.text_to_embed(X_train_de_rewe, ['de' for a in X_train_de_rewe], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_de_rewe = np.array(list(model_helper.text_to_embed(X_val_de_rewe, ['de' for a in X_val_de_rewe], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_de_rewe = np.array(list(model_helper.text_to_embed(X_test_de_rewe, ['de' for a in X_test_de_rewe], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "X_train_emb_de_rewe2 = np.array(list(model_helper.text_to_embed(X_train_de_rewe2, ['de' for a in X_train_de_rewe2], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_de_rewe2 = np.array(list(model_helper.text_to_embed(X_val_de_rewe2, ['de' for a in X_val_de_rewe2], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_de_rewe2 = np.array(list(model_helper.text_to_embed(X_test_de_rewe2, ['de' for a in X_test_de_rewe2], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "################################################################\n",
        "\n",
        "X_emb_edeka = np.array(list(model_helper.text_to_embed(df_edeka['text'], df_edeka['lang'], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_emb_real = np.array(list(model_helper.text_to_embed(df_real['text'], df_real['lang'], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "y_train_enc_de_rewe = encode_label(y_train_de_rewe)\n",
        "y_val_enc_de_rewe = encode_label(y_val_de_rewe)\n",
        "y_test_enc_de_rewe = encode_label(y_test_de_rewe)\n",
        "\n",
        "y_train_enc_de_rewe2 = encode_label(y_train_de_rewe2)\n",
        "y_val_enc_de_rewe2 = encode_label(y_val_de_rewe2)\n",
        "y_test_enc_de_rewe2 = encode_label(y_test_de_rewe2)\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "y_enc_edeka = encode_label(df_edeka['cc5'])\n",
        "y_enc_real = encode_label(df_real['cc5'])\n",
        "\n",
        "class_weight_dict_de = get_weigth_dict(y_train_de_rewe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-46ef0fbba434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_train_de_rewe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_de_rewe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_de_rewe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_de_rewe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_de_rewe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_de_rewe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rewe_united\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train_emb_de_rewe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_de_rewe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'de'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train_de_rewe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_val_emb_de_rewe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_de_rewe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'de'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_val_de_rewe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_test_emb_de_rewe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_de_rewe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'de'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test_de_rewe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_git_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'seq_len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "trsGNyILy0gX",
        "colab": {}
      },
      "source": [
        "dropout_rate=.2\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "input_layer = Input(shape = (seq_len,embedding_dim,), name='text_input')\n",
        "\n",
        "filter_sizes = [2,3,5]\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(100, kernel_size=filter_sizes[i], kernel_initializer='he_normal', activation='relu')(input_layer)\n",
        "    maxpool_pool.append(AveragePooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de',kernel_regularizer=l1_l2(l1=5e-6, l2=5e-9))(drop_layer) \n",
        "\n",
        "de_rewe = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "de_rewe.summary()\n",
        "\n",
        "de_rewe.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = de_rewe.fit(x = X_train_emb_de_rewe, y = y_train_enc_de_rewe,\\\n",
        "                validation_data = (X_val_emb_de_rewe, y_val_enc_de_rewe), \\\n",
        "                epochs = 50, batch_size = 32, shuffle = True,verbose =0, \\\n",
        "                class_weight = class_weight_dict_de, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J9GzK38Sy0gc",
        "colab": {}
      },
      "source": [
        "dropout_rate=.2\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "input_layer = Input(shape = (seq_len,embedding_dim,), name='text_input')\n",
        "\n",
        "filter_sizes = [2,3,5]\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(100, kernel_size=filter_sizes[i], kernel_initializer='he_normal', activation='relu')(input_layer)\n",
        "    maxpool_pool.append(AveragePooling1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de',kernel_regularizer=l1_l2(l1=5e-6, l2=5e-9))(drop_layer) \n",
        "\n",
        "de_rewe2 = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "de_rewe2.summary()\n",
        "\n",
        "de_rewe2.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = de_rewe.fit(x = X_train_emb_de_rewe2, y = y_train_enc_de_rewe2,\\\n",
        "                validation_data = (X_val_emb_de_rewe2, y_val_enc_de_rewe2), \\\n",
        "                epochs = 50, batch_size = 32, shuffle = True,verbose =0, \\\n",
        "                class_weight = class_weight_dict_de, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "07D24BDOy0gi",
        "colab": {}
      },
      "source": [
        "def test_xy(X,y,string,model):\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    print('accuracy %s'% string,accuracy_score(pred,y))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(pred, y))\n",
        "\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_rewe)\n",
        "test_xy(X_emb_edeka,df_edeka['cc5'],'edeka',de_rewe)\n",
        "test_xy(X_emb_real,df_real['cc5'],'real',de_rewe)\n",
        "\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_rewe2)\n",
        "test_xy(X_emb_edeka,df_edeka['cc5'],'edeka',de_rewe2)\n",
        "test_xy(X_emb_real,df_real['cc5'],'real',de_rewe2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARo4GJ-By2AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWNADmapy7tQ"
      },
      "source": [
        "# Multilingual Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKXHyTHQy7tR"
      },
      "source": [
        "load embedings  \n",
        "we only load a \"slim\" version of the embeddings, which are a subset of the vocab (less than 5%) the time loading the embeddings decreases from 15 min to 7 sec and colab is capable of loading more than two languages (embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CePvYnY0y7tR"
      },
      "source": [
        "### Co2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jhjuwFDTy7tS",
        "colab": {}
      },
      "source": [
        "#!pip install experiment-impact-tracker\n",
        "#!mkdir logs\n",
        "#from experiment_impact_tracker.compute_tracker import ImpactTracker\n",
        "#tracker = ImpactTracker('logs')\n",
        "#tracker.launch_impact_monitor()\n",
        "#info = tracker.get_latest_info_and_check_for_errors()\n",
        "#!ls logs/impacttracker\n",
        "#!cat logs/impacttracker/impact_tracker_log.log\n",
        "#!wget 'https://raw.githubusercontent.com/ELehmann91/Thesis_Multilingual_Transferlearning/master/data/model.json'\n",
        "!create-compute-appendix logs/ --site_spec model.json --output_dir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b5lnF_yny7tV",
        "colab": {}
      },
      "source": [
        "task = 'slc_de_zstf'\n",
        "model = 'LogReg'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "    \n",
        "\n",
        "tf_idf_log_reg(X_train_de,y_train_de,X_test_fr,y_test_fr,15000)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TovqT12iy7tY"
      },
      "source": [
        "## CNN 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uIaOwG8Ay7tZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b6809de-f541-4b4c-bc3d-68ba82182a18"
      },
      "source": [
        "dropout_rate= 0.5\n",
        "filter_sizes = [2,3,5]\n",
        "num_filters = 80\n",
        "lr = .01\n",
        "opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                      \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "    maxpool_pool.append(AvgPool1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "#dense_layer = Dense(150,activation='relu')(falt_layer)\n",
        "\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_cnn1d = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_cnn1d.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "print(X_train_pad_de.shape, y_train_enc_de.shape)\n",
        "print(de_cnn1d.summary())\n",
        "hist = de_cnn1d.fit(x = X_train_pad_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_pad_de, y_val_enc_de), \\\n",
        "                epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict_de,  \\\n",
        "                callbacks = [early_stopping])\n",
        "#verbose =0,\n",
        "\n",
        "\n",
        "all_tests(de_cnn1d,X_test_pad_de,X_test_pad_fr,X_pad_it)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23597, 31) (23597, 75)\n",
            "Model: \"model_181\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_149 (Embedding)       (None, 31, 300)      6590700     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_341 (Conv1D)             (None, 31, 80)       24080       embedding_149[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_342 (Conv1D)             (None, 30, 80)       48080       embedding_149[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_343 (Conv1D)             (None, 27, 80)       120080      embedding_149[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_199 (AverageP (None, 1, 80)        0           conv1d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_200 (AverageP (None, 1, 80)        0           conv1d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_201 (AverageP (None, 1, 80)        0           conv1d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 3, 80)        0           average_pooling1d_199[0][0]      \n",
            "                                                                 average_pooling1d_200[0][0]      \n",
            "                                                                 average_pooling1d_201[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 240)          0           concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 240)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           18075       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,801,015\n",
            "Trainable params: 210,315\n",
            "Non-trainable params: 6,590,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 3.0839 - accuracy: 0.3618 - val_loss: 1.2644 - val_accuracy: 0.6997\n",
            "Epoch 2/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 1.5222 - accuracy: 0.6712 - val_loss: 0.7171 - val_accuracy: 0.8523\n",
            "Epoch 3/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 1.1158 - accuracy: 0.7598 - val_loss: 0.5327 - val_accuracy: 0.8848\n",
            "Epoch 4/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.8561 - accuracy: 0.8095 - val_loss: 0.4648 - val_accuracy: 0.8945\n",
            "Epoch 5/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.7106 - accuracy: 0.8445 - val_loss: 0.4125 - val_accuracy: 0.9016\n",
            "Epoch 6/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.6287 - accuracy: 0.8605 - val_loss: 0.3487 - val_accuracy: 0.9174\n",
            "Epoch 7/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.5552 - accuracy: 0.8750 - val_loss: 0.3261 - val_accuracy: 0.9296\n",
            "Epoch 8/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.4837 - accuracy: 0.8911 - val_loss: 0.3016 - val_accuracy: 0.9354\n",
            "Epoch 9/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.4325 - accuracy: 0.9026 - val_loss: 0.2887 - val_accuracy: 0.9385\n",
            "Epoch 10/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.3946 - accuracy: 0.9091 - val_loss: 0.2574 - val_accuracy: 0.9443\n",
            "Epoch 11/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.3749 - accuracy: 0.9156 - val_loss: 0.2603 - val_accuracy: 0.9446\n",
            "Epoch 12/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.3383 - accuracy: 0.9222 - val_loss: 0.2458 - val_accuracy: 0.9491\n",
            "Epoch 13/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3341 - accuracy: 0.9236 - val_loss: 0.2527 - val_accuracy: 0.9451\n",
            "Epoch 14/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.3274 - accuracy: 0.9285 - val_loss: 0.2361 - val_accuracy: 0.9514\n",
            "Epoch 15/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2882 - accuracy: 0.9308 - val_loss: 0.2425 - val_accuracy: 0.9497\n",
            "Epoch 16/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2801 - accuracy: 0.9319 - val_loss: 0.2234 - val_accuracy: 0.9522\n",
            "Epoch 17/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2587 - accuracy: 0.9364 - val_loss: 0.2173 - val_accuracy: 0.9537\n",
            "Epoch 18/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2455 - accuracy: 0.9422 - val_loss: 0.2260 - val_accuracy: 0.9519\n",
            "Epoch 19/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2415 - accuracy: 0.9425 - val_loss: 0.2181 - val_accuracy: 0.9550\n",
            "Epoch 20/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2221 - accuracy: 0.9476 - val_loss: 0.2108 - val_accuracy: 0.9580\n",
            "Epoch 21/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2096 - accuracy: 0.9495 - val_loss: 0.2131 - val_accuracy: 0.9560\n",
            "Epoch 22/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9537 - val_loss: 0.2059 - val_accuracy: 0.9603\n",
            "Epoch 23/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1866 - accuracy: 0.9539 - val_loss: 0.2009 - val_accuracy: 0.9588\n",
            "Epoch 24/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.2034 - accuracy: 0.9528 - val_loss: 0.2034 - val_accuracy: 0.9570\n",
            "Epoch 25/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1753 - accuracy: 0.9553 - val_loss: 0.1939 - val_accuracy: 0.9598\n",
            "Epoch 26/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1645 - accuracy: 0.9572 - val_loss: 0.1975 - val_accuracy: 0.9619\n",
            "Epoch 27/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1583 - accuracy: 0.9614 - val_loss: 0.1864 - val_accuracy: 0.9636\n",
            "Epoch 28/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9627 - val_loss: 0.1943 - val_accuracy: 0.9611\n",
            "Epoch 29/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1514 - accuracy: 0.9627 - val_loss: 0.1892 - val_accuracy: 0.9641\n",
            "Epoch 30/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1466 - accuracy: 0.9629 - val_loss: 0.1907 - val_accuracy: 0.9649\n",
            "Epoch 31/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1360 - accuracy: 0.9639 - val_loss: 0.1827 - val_accuracy: 0.9644\n",
            "Epoch 32/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1676 - accuracy: 0.9611 - val_loss: 0.1894 - val_accuracy: 0.9621\n",
            "Epoch 33/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1257 - accuracy: 0.9658 - val_loss: 0.1938 - val_accuracy: 0.9652\n",
            "Epoch 34/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9660 - val_loss: 0.1873 - val_accuracy: 0.9667\n",
            "Epoch 35/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1231 - accuracy: 0.9682 - val_loss: 0.1860 - val_accuracy: 0.9659\n",
            "Epoch 36/150\n",
            "369/369 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9689 - val_loss: 0.1829 - val_accuracy: 0.9647\n",
            "\n",
            "de 0.9667\n",
            "fr 0.476\n",
            "it 0.1325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q53KzPGYy7te"
      },
      "source": [
        "### deeper prediction analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E5-qUDCDy7te"
      },
      "source": [
        "Prediction / Certainty Treshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VxZ1Ipxxy7tf",
        "colab": {}
      },
      "source": [
        "def test_xy(X,y,string,model,z,ret=False):\n",
        "    obs = len(X)\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    y_pred_max = y_pred.max(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    df_pred = pd.DataFrame(zip(X,pred,y,y_pred_max),columns=['embed','pred','y','y_pred_max'])\n",
        "    df_pred = df_pred[df_pred['y_pred_max']>z]\n",
        "    print('accuracy %s'% string,accuracy_score(df_pred['pred'],df_pred['y']))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(df_pred['pred'],df_pred['y']))\n",
        "    print(len(df_pred),'of',len(X),int(len(df_pred)/len(X)*100),'%',len(df_pred.pred.unique()))\n",
        "    if ret:\n",
        "        return df_pred\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_avg_pool,.65)\n",
        "test_xy(X_traprint(classification_report(y,pred))in_emb_fr,y_train_fr,'french',de_avg_pool,.8)\n",
        "    #return pred, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WORVBMqxy7th",
        "colab": {}
      },
      "source": [
        "print(classification_report(y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lIBOEeI7y7tl"
      },
      "source": [
        "Accuracy for higher hirachies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtoA7Wb6y7tl",
        "colab": {}
      },
      "source": [
        "with open('coicop_5_4.txt') as json_file:#\n",
        "    coicop_5_4 = json.load(json_file)\n",
        "\n",
        "with open('coicop_5_3.txt') as json_file:#\n",
        "    coicop_5_3 = json.load(json_file)\n",
        "\n",
        "y_pred = de_avg_pool.predict([X_test_emb_fr])\n",
        "y_pred_arg = y_pred.argmax(axis=1)\n",
        "pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pr_lab3 = [coicop_5_3[cc5] for cc5 in pred]\n",
        "y_pr_lab4 = [coicop_5_4[cc5] for cc5 in pred]\n",
        "y_lab3 = [coicop_5_3[cc5] for cc5 in y_test_fr]\n",
        "y_lab4 = [coicop_5_4[cc5] for cc5 in y_test_fr]\n",
        "print('accuracy %s'% accuracy_score(y_pr_lab3,y_lab3))\n",
        "print('b_accuracy %s'%  balanced_accuracy_score(y_pr_lab3, y_lab3))\n",
        "print('accuracy %s'% accuracy_score(y_pr_lab4,y_lab4))\n",
        "print('b_accuracy %s'%  balanced_accuracy_score(y_pr_lab4, y_lab4))\n",
        "#print(classification_report(y_lab4,y_pr_lab4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LrkYrn7jy7tn",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "y_pred = de_avg_pool.predict([X_test_emb_fr])\n",
        "y_pred_arg = y_pred.argmax(axis=1)\n",
        "pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pr_lab4 = [coicop_5_4[cc5] for cc5 in pred]\n",
        "y_lab4 = [coicop_5_4[cc5] for cc5 in y_test_fr]\n",
        "\n",
        "label = pd.Series(y_lab4).unique()\n",
        "label.sort()\n",
        "cm = confusion_matrix(y_lab4,y_pr_lab4,labels=label)#, normalize='true')\n",
        "\n",
        "df_cm = pd.DataFrame(cm, label,label)\n",
        "plt.figure(figsize=(15,15))\n",
        "sn.set(font_scale=.7) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 9}) # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UiF-WJGty7tp"
      },
      "source": [
        "### Transferlearning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lUev1vesy7tr",
        "colab": {}
      },
      "source": [
        "#test_xy(X_test_emb_de,y_test_de,'german',model_new)\n",
        "#test_xy(X_test_emb_fr,y_test_fr,'french',model_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDsFNictQZDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24ba15de-dd60-46d3-8f19-9e3b4580fea1"
      },
      "source": [
        "dropout_rate= 0.2\n",
        "filter_sizes =  [3,4,5]\n",
        "num_filters = 75\n",
        "lr = .001\n",
        "opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "                      \n",
        "input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "embedd_seq = Embedding(vocab_size_all, embedding_dim, weights = [embedding_matrix_all], input_length = seq_len, trainable = False, mask_zero=False)(input_layer)\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv1D(num_filters, kernel_size=filter_sizes[i],  activation='relu')(embedd_seq) #kernel_initializer='he_normal',\n",
        "    maxpool_pool.append(AvgPool1D(pool_size = seq_len-filter_sizes[i]+1)(conv))\n",
        "\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)  \n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "#dense_layer = Dense(150,activation='relu')(falt_layer)\n",
        "\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_cnn1d_tf = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "de_cnn1d_tf.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "print(X_train_pad_de.shape, y_train_enc_de.shape)\n",
        "print(de_cnn1d_tf.summary())\n",
        "hist = de_cnn1d_tf.fit(x = X_train_pad_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_pad_de, y_val_enc_de), \\\n",
        "                epochs = 150, batch_size = 64, shuffle = True, class_weight = class_weight_dict_de,  \\\n",
        "                callbacks = [early_stopping])\n",
        "#verbose =0,\n",
        "\n",
        "de_cnn1d_tf.save_weights('de_cnn1d_tf')\n",
        "all_tests(de_cnn1d_tf,X_test_pad_de,X_test_pad_fr,X_pad_it)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23597, 31) (23597, 75)\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 287,175\n",
            "Non-trainable params: 6,863,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 3.9581 - accuracy: 0.1750 - val_loss: 3.3371 - val_accuracy: 0.1719\n",
            "Epoch 2/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 3.0057 - accuracy: 0.4492 - val_loss: 2.1579 - val_accuracy: 0.5512\n",
            "Epoch 3/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 2.3082 - accuracy: 0.5553 - val_loss: 1.6630 - val_accuracy: 0.6621\n",
            "Epoch 4/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.8892 - accuracy: 0.6210 - val_loss: 1.3208 - val_accuracy: 0.6997\n",
            "Epoch 5/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.6125 - accuracy: 0.6660 - val_loss: 1.1484 - val_accuracy: 0.7549\n",
            "Epoch 6/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.4236 - accuracy: 0.7053 - val_loss: 0.9845 - val_accuracy: 0.7757\n",
            "Epoch 7/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.2865 - accuracy: 0.7264 - val_loss: 0.9138 - val_accuracy: 0.7854\n",
            "Epoch 8/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.1748 - accuracy: 0.7581 - val_loss: 0.8468 - val_accuracy: 0.7951\n",
            "Epoch 9/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.0830 - accuracy: 0.7708 - val_loss: 0.7662 - val_accuracy: 0.8167\n",
            "Epoch 10/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 1.0113 - accuracy: 0.7843 - val_loss: 0.6919 - val_accuracy: 0.8365\n",
            "Epoch 11/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.9463 - accuracy: 0.8004 - val_loss: 0.6643 - val_accuracy: 0.8332\n",
            "Epoch 12/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.8866 - accuracy: 0.8132 - val_loss: 0.6627 - val_accuracy: 0.8243\n",
            "Epoch 13/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.8372 - accuracy: 0.8204 - val_loss: 0.5842 - val_accuracy: 0.8652\n",
            "Epoch 14/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.7935 - accuracy: 0.8307 - val_loss: 0.5714 - val_accuracy: 0.8622\n",
            "Epoch 15/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.7476 - accuracy: 0.8421 - val_loss: 0.5250 - val_accuracy: 0.8698\n",
            "Epoch 16/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.7021 - accuracy: 0.8515 - val_loss: 0.6395 - val_accuracy: 0.8556\n",
            "Epoch 17/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.6747 - accuracy: 0.8523 - val_loss: 0.4693 - val_accuracy: 0.8899\n",
            "Epoch 18/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.6438 - accuracy: 0.8602 - val_loss: 0.4581 - val_accuracy: 0.8912\n",
            "Epoch 19/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.6189 - accuracy: 0.8635 - val_loss: 0.5102 - val_accuracy: 0.8660\n",
            "Epoch 20/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.5938 - accuracy: 0.8704 - val_loss: 0.4480 - val_accuracy: 0.8891\n",
            "Epoch 21/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.5641 - accuracy: 0.8762 - val_loss: 0.4092 - val_accuracy: 0.9044\n",
            "Epoch 22/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.5451 - accuracy: 0.8791 - val_loss: 0.3935 - val_accuracy: 0.9085\n",
            "Epoch 23/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.5212 - accuracy: 0.8855 - val_loss: 0.3870 - val_accuracy: 0.9153\n",
            "Epoch 24/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.5016 - accuracy: 0.8888 - val_loss: 0.4013 - val_accuracy: 0.9105\n",
            "Epoch 25/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4858 - accuracy: 0.8925 - val_loss: 0.3825 - val_accuracy: 0.9120\n",
            "Epoch 26/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4605 - accuracy: 0.8983 - val_loss: 0.3463 - val_accuracy: 0.9186\n",
            "Epoch 27/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4516 - accuracy: 0.9005 - val_loss: 0.3554 - val_accuracy: 0.9085\n",
            "Epoch 28/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4409 - accuracy: 0.9017 - val_loss: 0.3203 - val_accuracy: 0.9273\n",
            "Epoch 29/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4219 - accuracy: 0.9062 - val_loss: 0.3353 - val_accuracy: 0.9230\n",
            "Epoch 30/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4068 - accuracy: 0.9071 - val_loss: 0.3257 - val_accuracy: 0.9255\n",
            "Epoch 31/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.4039 - accuracy: 0.9096 - val_loss: 0.3084 - val_accuracy: 0.9316\n",
            "Epoch 32/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3874 - accuracy: 0.9122 - val_loss: 0.3249 - val_accuracy: 0.9176\n",
            "Epoch 33/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3707 - accuracy: 0.9170 - val_loss: 0.3239 - val_accuracy: 0.9227\n",
            "Epoch 34/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3691 - accuracy: 0.9172 - val_loss: 0.3064 - val_accuracy: 0.9288\n",
            "Epoch 35/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3543 - accuracy: 0.9219 - val_loss: 0.3130 - val_accuracy: 0.9181\n",
            "Epoch 36/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3459 - accuracy: 0.9208 - val_loss: 0.2835 - val_accuracy: 0.9359\n",
            "Epoch 37/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3345 - accuracy: 0.9225 - val_loss: 0.2630 - val_accuracy: 0.9420\n",
            "Epoch 38/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9283 - val_loss: 0.2679 - val_accuracy: 0.9420\n",
            "Epoch 39/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3141 - accuracy: 0.9323 - val_loss: 0.2863 - val_accuracy: 0.9316\n",
            "Epoch 40/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.3101 - accuracy: 0.9292 - val_loss: 0.2803 - val_accuracy: 0.9362\n",
            "Epoch 41/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2964 - accuracy: 0.9343 - val_loss: 0.2636 - val_accuracy: 0.9420\n",
            "Epoch 42/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2910 - accuracy: 0.9327 - val_loss: 0.2527 - val_accuracy: 0.9448\n",
            "Epoch 43/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2894 - accuracy: 0.9316 - val_loss: 0.2476 - val_accuracy: 0.9458\n",
            "Epoch 44/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2765 - accuracy: 0.9378 - val_loss: 0.2747 - val_accuracy: 0.9364\n",
            "Epoch 45/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2761 - accuracy: 0.9368 - val_loss: 0.2593 - val_accuracy: 0.9430\n",
            "Epoch 46/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2646 - accuracy: 0.9401 - val_loss: 0.2388 - val_accuracy: 0.9464\n",
            "Epoch 47/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2605 - accuracy: 0.9403 - val_loss: 0.2377 - val_accuracy: 0.9464\n",
            "Epoch 48/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2524 - accuracy: 0.9404 - val_loss: 0.2386 - val_accuracy: 0.9484\n",
            "Epoch 49/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2480 - accuracy: 0.9427 - val_loss: 0.2371 - val_accuracy: 0.9469\n",
            "Epoch 50/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2405 - accuracy: 0.9447 - val_loss: 0.2261 - val_accuracy: 0.9522\n",
            "Epoch 51/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2437 - accuracy: 0.9425 - val_loss: 0.2294 - val_accuracy: 0.9502\n",
            "Epoch 52/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2325 - accuracy: 0.9464 - val_loss: 0.2319 - val_accuracy: 0.9456\n",
            "Epoch 53/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2306 - accuracy: 0.9457 - val_loss: 0.2348 - val_accuracy: 0.9476\n",
            "Epoch 54/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2299 - accuracy: 0.9456 - val_loss: 0.2181 - val_accuracy: 0.9537\n",
            "Epoch 55/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2182 - accuracy: 0.9494 - val_loss: 0.2246 - val_accuracy: 0.9517\n",
            "Epoch 56/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2126 - accuracy: 0.9517 - val_loss: 0.2076 - val_accuracy: 0.9563\n",
            "Epoch 57/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2103 - accuracy: 0.9513 - val_loss: 0.2111 - val_accuracy: 0.9525\n",
            "Epoch 58/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2028 - accuracy: 0.9526 - val_loss: 0.2127 - val_accuracy: 0.9560\n",
            "Epoch 59/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.2011 - accuracy: 0.9510 - val_loss: 0.2054 - val_accuracy: 0.9580\n",
            "Epoch 60/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.1988 - accuracy: 0.9513 - val_loss: 0.2412 - val_accuracy: 0.9446\n",
            "Epoch 61/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.1947 - accuracy: 0.9533 - val_loss: 0.2106 - val_accuracy: 0.9555\n",
            "Epoch 62/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.1902 - accuracy: 0.9532 - val_loss: 0.2070 - val_accuracy: 0.9540\n",
            "Epoch 63/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.1852 - accuracy: 0.9555 - val_loss: 0.2169 - val_accuracy: 0.9542\n",
            "Epoch 64/150\n",
            "369/369 [==============================] - 2s 5ms/step - loss: 0.1892 - accuracy: 0.9537 - val_loss: 0.2148 - val_accuracy: 0.9494\n",
            "\n",
            "de 0.9433\n",
            "fr 0.4319\n",
            "it 0.2747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMyW2XuEy7tv",
        "colab": {}
      },
      "source": [
        "def transfer_cnn(few_shot,freeze,lr):\n",
        "\n",
        "    de_cnn1d_tf.load_weights('de_cnn1d_tf')\n",
        "\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "    inp = de_cnn1d_tf.input\n",
        "    out = de_cnn1d_tf.output #get_layer('output_de').output\n",
        "\n",
        "    # create a new network between inp and out\n",
        "    de_cnn1d_transfer = Model(inp, out)    \n",
        "\n",
        "    de_cnn1d_transfer.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    #freeze\n",
        "    for l , layer in enumerate(de_cnn1d_transfer.layers[:-2]):\n",
        "        de_cnn1d_transfer.layers[l].trainable = (freeze==False)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_pad_fr), size=few_shot)\n",
        "\n",
        "    de_cnn1d_transfer.fit(x = X_train_pad_fr[idx,:], y = y_train_enc_fr[idx,:],\\\n",
        "                    validation_data = (X_val_pad_fr, y_val_enc_fr), \\\n",
        "                    epochs = 150, batch_size = 8, shuffle = True, \\\n",
        "                    class_weight = class_weight_dict_fr, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    print(few_shot)\n",
        "    print(de_cnn1d_transfer.summary())\n",
        "    #all_tests(de_cnn1d_transfer,X_test_pad_de,X_test_pad_fr,X_pad_it)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test_fr = de_cnn1d_transfer.predict(X_test_pad_fr)\n",
        "    y_pred_arg_fr = y_pred_test_fr.argmax(axis=1)\n",
        "    y_pred_test_fr = [encoder.classes_[y] for y in y_pred_arg_fr]\n",
        "    \n",
        "    df_results[str(few_shot)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='accuracy')] = round(accuracy_score(y_pred_test_fr, y_test_fr),4)\n",
        "    df_results[str(few_shot)][(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']=='avg_recall')] = round(balanced_accuracy_score(y_pred_test_fr, y_test_fr),4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqyzbxv3m0D6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42c618bb-baff-418b-f906-6793eed258b4"
      },
      "source": [
        " task = 'slc_de_tf'\n",
        "model = 'CNN1D_fix_.01'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "    lr = 0.005\n",
        "    if obs == 250:\n",
        "        lr= 0.001\n",
        "    transfer_cnn(obs,True,lr = lr)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 2.6714 - accuracy: 0.4500 - val_loss: 2.4154 - val_accuracy: 0.5256\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 2.3912 - accuracy: 0.4700 - val_loss: 2.4270 - val_accuracy: 0.5270\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 1.7641 - accuracy: 0.6000 - val_loss: 2.6358 - val_accuracy: 0.5032\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 1.6347 - accuracy: 0.5400 - val_loss: 2.7638 - val_accuracy: 0.4832\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 1.2613 - accuracy: 0.5500 - val_loss: 2.7867 - val_accuracy: 0.4807\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 1.0437 - accuracy: 0.5100 - val_loss: 2.8402 - val_accuracy: 0.4793\n",
            "100\n",
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:06<00:33,  6.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 6.5920 - accuracy: 0.3960 - val_loss: 2.5877 - val_accuracy: 0.4720\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 5.7692 - accuracy: 0.4360 - val_loss: 2.4581 - val_accuracy: 0.4909\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 4.9981 - accuracy: 0.4600 - val_loss: 2.3972 - val_accuracy: 0.4975\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 4.7921 - accuracy: 0.4600 - val_loss: 2.3844 - val_accuracy: 0.4923\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 4.2497 - accuracy: 0.4920 - val_loss: 2.4122 - val_accuracy: 0.4870\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 4.1188 - accuracy: 0.4520 - val_loss: 2.4232 - val_accuracy: 0.4919\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 3.8024 - accuracy: 0.4640 - val_loss: 2.4169 - val_accuracy: 0.4919\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 3.4693 - accuracy: 0.5000 - val_loss: 2.3916 - val_accuracy: 0.4982\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 3.5925 - accuracy: 0.4680 - val_loss: 2.4171 - val_accuracy: 0.4958\n",
            "250\n",
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [00:16<00:30,  7.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 5.1537 - accuracy: 0.4860 - val_loss: 2.5486 - val_accuracy: 0.4818\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 3.5433 - accuracy: 0.4220 - val_loss: 2.4836 - val_accuracy: 0.4713\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 3.1324 - accuracy: 0.4400 - val_loss: 2.5341 - val_accuracy: 0.4695\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 2.6125 - accuracy: 0.4980 - val_loss: 2.4884 - val_accuracy: 0.4877\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 2.4520 - accuracy: 0.4880 - val_loss: 2.5332 - val_accuracy: 0.5000\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 2.0594 - accuracy: 0.5500 - val_loss: 2.2692 - val_accuracy: 0.5473\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 2.0707 - accuracy: 0.5320 - val_loss: 2.5137 - val_accuracy: 0.4772\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.5529 - accuracy: 0.5480 - val_loss: 2.3039 - val_accuracy: 0.5399\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.6487 - accuracy: 0.5540 - val_loss: 2.2968 - val_accuracy: 0.5473\n",
            "Epoch 10/150\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 1.6151 - accuracy: 0.5940 - val_loss: 2.3753 - val_accuracy: 0.5413\n",
            "Epoch 11/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.4788 - accuracy: 0.6540 - val_loss: 2.1288 - val_accuracy: 0.5865\n",
            "Epoch 12/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.1390 - accuracy: 0.6560 - val_loss: 2.0633 - val_accuracy: 0.6226\n",
            "Epoch 13/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.9816 - accuracy: 0.7100 - val_loss: 2.0432 - val_accuracy: 0.6237\n",
            "Epoch 14/150\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 1.1724 - accuracy: 0.7000 - val_loss: 2.0346 - val_accuracy: 0.6303\n",
            "Epoch 15/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.9025 - accuracy: 0.6820 - val_loss: 1.9769 - val_accuracy: 0.6412\n",
            "Epoch 16/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.8358 - accuracy: 0.7500 - val_loss: 2.0007 - val_accuracy: 0.6531\n",
            "Epoch 17/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.0304 - accuracy: 0.7320 - val_loss: 1.9446 - val_accuracy: 0.6517\n",
            "Epoch 18/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.8574 - accuracy: 0.7440 - val_loss: 1.9289 - val_accuracy: 0.6601\n",
            "Epoch 19/150\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.7037 - accuracy: 0.7640 - val_loss: 1.8881 - val_accuracy: 0.6622\n",
            "Epoch 20/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6176 - accuracy: 0.7860 - val_loss: 1.8201 - val_accuracy: 0.6966\n",
            "Epoch 21/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.7304 - accuracy: 0.7820 - val_loss: 1.8509 - val_accuracy: 0.6875\n",
            "Epoch 22/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6869 - accuracy: 0.7980 - val_loss: 1.8888 - val_accuracy: 0.6752\n",
            "Epoch 23/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6795 - accuracy: 0.7720 - val_loss: 1.9801 - val_accuracy: 0.6542\n",
            "Epoch 24/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5979 - accuracy: 0.7960 - val_loss: 1.9094 - val_accuracy: 0.6773\n",
            "Epoch 25/150\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5963 - accuracy: 0.8060 - val_loss: 1.8498 - val_accuracy: 0.6868\n",
            "500\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [00:45<00:42, 14.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 4.8021 - accuracy: 0.4290 - val_loss: 2.2129 - val_accuracy: 0.5088\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 3.5116 - accuracy: 0.4280 - val_loss: 2.1956 - val_accuracy: 0.5049\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 2.8330 - accuracy: 0.4860 - val_loss: 2.0048 - val_accuracy: 0.5347\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 2.4677 - accuracy: 0.5180 - val_loss: 1.8969 - val_accuracy: 0.5743\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 2.1515 - accuracy: 0.5530 - val_loss: 1.9423 - val_accuracy: 0.5477\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.8956 - accuracy: 0.5760 - val_loss: 1.7234 - val_accuracy: 0.6195\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.7162 - accuracy: 0.6230 - val_loss: 1.7265 - val_accuracy: 0.6135\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.6003 - accuracy: 0.6240 - val_loss: 1.5040 - val_accuracy: 0.6703\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.3419 - accuracy: 0.6790 - val_loss: 1.4112 - val_accuracy: 0.6938\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.3345 - accuracy: 0.6690 - val_loss: 1.6275 - val_accuracy: 0.6374\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.3186 - accuracy: 0.6640 - val_loss: 1.5520 - val_accuracy: 0.6699\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.1027 - accuracy: 0.6820 - val_loss: 1.4738 - val_accuracy: 0.6969\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.9094 - accuracy: 0.7090 - val_loss: 1.3031 - val_accuracy: 0.7358\n",
            "Epoch 14/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.8542 - accuracy: 0.7380 - val_loss: 1.3032 - val_accuracy: 0.7425\n",
            "Epoch 15/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.8419 - accuracy: 0.7380 - val_loss: 1.3327 - val_accuracy: 0.7306\n",
            "Epoch 16/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.9378 - accuracy: 0.7180 - val_loss: 1.4114 - val_accuracy: 0.7221\n",
            "Epoch 17/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.7564 - accuracy: 0.7760 - val_loss: 1.2612 - val_accuracy: 0.7610\n",
            "Epoch 18/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6727 - accuracy: 0.7950 - val_loss: 1.3204 - val_accuracy: 0.7488\n",
            "Epoch 19/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6327 - accuracy: 0.8010 - val_loss: 1.3054 - val_accuracy: 0.7491\n",
            "Epoch 20/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6940 - accuracy: 0.7830 - val_loss: 1.2739 - val_accuracy: 0.7663\n",
            "Epoch 21/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6585 - accuracy: 0.7980 - val_loss: 1.3668 - val_accuracy: 0.7565\n",
            "Epoch 22/150\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6217 - accuracy: 0.8040 - val_loss: 1.3322 - val_accuracy: 0.7467\n",
            "1000\n",
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [01:13<00:36, 18.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 4.6150 - accuracy: 0.4270 - val_loss: 2.3648 - val_accuracy: 0.4608\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 3.0701 - accuracy: 0.4795 - val_loss: 1.7762 - val_accuracy: 0.5960\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 2.5103 - accuracy: 0.5410 - val_loss: 1.5318 - val_accuracy: 0.6454\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 2.2431 - accuracy: 0.5735 - val_loss: 1.5418 - val_accuracy: 0.6444\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 1.7572 - accuracy: 0.6425 - val_loss: 1.2609 - val_accuracy: 0.6955\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 1.5226 - accuracy: 0.6585 - val_loss: 1.3051 - val_accuracy: 0.7099\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.5962 - accuracy: 0.6800 - val_loss: 1.2521 - val_accuracy: 0.7274\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.3974 - accuracy: 0.6985 - val_loss: 1.2217 - val_accuracy: 0.7214\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 1.3100 - accuracy: 0.7175 - val_loss: 1.0643 - val_accuracy: 0.7617\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 1.1972 - accuracy: 0.7415 - val_loss: 1.1034 - val_accuracy: 0.7579\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.9850 - accuracy: 0.7560 - val_loss: 0.9978 - val_accuracy: 0.7761\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.9589 - accuracy: 0.7665 - val_loss: 0.9867 - val_accuracy: 0.7768\n",
            "Epoch 13/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.7938 - accuracy: 0.7955 - val_loss: 0.9641 - val_accuracy: 0.7831\n",
            "Epoch 14/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.8569 - accuracy: 0.7750 - val_loss: 0.9013 - val_accuracy: 0.8090\n",
            "Epoch 15/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.7868 - accuracy: 0.8035 - val_loss: 0.9492 - val_accuracy: 0.7821\n",
            "Epoch 16/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.7259 - accuracy: 0.8015 - val_loss: 0.9017 - val_accuracy: 0.7989\n",
            "Epoch 17/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.7657 - accuracy: 0.8005 - val_loss: 1.0908 - val_accuracy: 0.7649\n",
            "Epoch 18/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.8025 - accuracy: 0.8180 - val_loss: 0.9473 - val_accuracy: 0.7940\n",
            "Epoch 19/150\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.7162 - accuracy: 0.8210 - val_loss: 0.9193 - val_accuracy: 0.7992\n",
            "2000\n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [01:44<00:21, 21.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 4.1502 - accuracy: 0.4574 - val_loss: 1.6864 - val_accuracy: 0.6160\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 2.7312 - accuracy: 0.5774 - val_loss: 1.2822 - val_accuracy: 0.7025\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 2.1580 - accuracy: 0.6512 - val_loss: 1.0068 - val_accuracy: 0.7596\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.8242 - accuracy: 0.6980 - val_loss: 1.3509 - val_accuracy: 0.6829\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.6880 - accuracy: 0.7202 - val_loss: 1.0903 - val_accuracy: 0.7446\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.3843 - accuracy: 0.7498 - val_loss: 0.8157 - val_accuracy: 0.8122\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.3115 - accuracy: 0.7626 - val_loss: 0.7758 - val_accuracy: 0.8231\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.2443 - accuracy: 0.7700 - val_loss: 0.9216 - val_accuracy: 0.7768\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 1.1992 - accuracy: 0.7784 - val_loss: 0.7756 - val_accuracy: 0.8178\n",
            "Epoch 10/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 1.1948 - accuracy: 0.7954 - val_loss: 0.7833 - val_accuracy: 0.8206\n",
            "Epoch 11/150\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9740 - accuracy: 0.8108 - val_loss: 0.7735 - val_accuracy: 0.8210\n",
            "Epoch 12/150\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0276 - accuracy: 0.7984 - val_loss: 0.7021 - val_accuracy: 0.8430\n",
            "Epoch 13/150\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9408 - accuracy: 0.8152 - val_loss: 0.7621 - val_accuracy: 0.8297\n",
            "Epoch 14/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.9139 - accuracy: 0.8264 - val_loss: 0.6912 - val_accuracy: 0.8546\n",
            "Epoch 15/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.8645 - accuracy: 0.8304 - val_loss: 0.6999 - val_accuracy: 0.8381\n",
            "Epoch 16/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.8548 - accuracy: 0.8182 - val_loss: 0.7013 - val_accuracy: 0.8455\n",
            "Epoch 17/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.8341 - accuracy: 0.8284 - val_loss: 0.6860 - val_accuracy: 0.8549\n",
            "Epoch 18/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.8650 - accuracy: 0.8304 - val_loss: 0.7057 - val_accuracy: 0.8479\n",
            "Epoch 19/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.8536 - accuracy: 0.8346 - val_loss: 0.7221 - val_accuracy: 0.8378\n",
            "Epoch 20/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.7283 - accuracy: 0.8392 - val_loss: 0.6802 - val_accuracy: 0.8486\n",
            "Epoch 21/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.7516 - accuracy: 0.8378 - val_loss: 0.6184 - val_accuracy: 0.8630\n",
            "Epoch 22/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.7637 - accuracy: 0.8514 - val_loss: 0.6059 - val_accuracy: 0.8672\n",
            "Epoch 23/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.6200 - accuracy: 0.8538 - val_loss: 0.6146 - val_accuracy: 0.8756\n",
            "Epoch 24/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.7107 - accuracy: 0.8506 - val_loss: 0.6563 - val_accuracy: 0.8665\n",
            "Epoch 25/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.6649 - accuracy: 0.8534 - val_loss: 0.6278 - val_accuracy: 0.8616\n",
            "Epoch 26/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.6413 - accuracy: 0.8526 - val_loss: 0.6497 - val_accuracy: 0.8553\n",
            "Epoch 27/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.6460 - accuracy: 0.8578 - val_loss: 0.6123 - val_accuracy: 0.8721\n",
            "5000\n",
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 16,950\n",
            "Non-trainable params: 7,133,325\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [02:52<00:00, 28.83s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN1D_fix_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4669</td>\n",
              "      <td>0.4869</td>\n",
              "      <td>0.6816</td>\n",
              "      <td>0.7345</td>\n",
              "      <td>0.786</td>\n",
              "      <td>0.8539</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN1D_fix_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.3443</td>\n",
              "      <td>0.5162</td>\n",
              "      <td>0.5914</td>\n",
              "      <td>0.6234</td>\n",
              "      <td>0.6859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model       task      metric    0  ...    5000 10000 15000 25000\n",
              "0  CNN1D_fix_.01  slc_de_tf    accuracy  NaN  ...  0.8539   NaN   NaN   NaN\n",
              "1  CNN1D_fix_.01  slc_de_tf  avg_recall  NaN  ...  0.6859   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijlEqGPUQeOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86e04bc6-c0ac-4625-8306-4aba141cf115"
      },
      "source": [
        " task = 'slc_de_tf'\n",
        "model = 'CNN1D_free_.1'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(obs,False,lr = .005)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 17.9975 - accuracy: 0.2500 - val_loss: 15.0320 - val_accuracy: 0.1167\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 6.2389 - accuracy: 0.2000 - val_loss: 14.7982 - val_accuracy: 0.1994\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 4.5080 - accuracy: 0.3300 - val_loss: 12.5780 - val_accuracy: 0.2652\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 4.1227 - accuracy: 0.4100 - val_loss: 12.8113 - val_accuracy: 0.3844\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 2.8470 - accuracy: 0.5200 - val_loss: 11.6409 - val_accuracy: 0.4688\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 1.5651 - accuracy: 0.5900 - val_loss: 13.1818 - val_accuracy: 0.3248\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 2.7285 - accuracy: 0.5700 - val_loss: 13.0076 - val_accuracy: 0.3788\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 4.2880 - accuracy: 0.5600 - val_loss: 15.2527 - val_accuracy: 0.4026\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 3.4092 - accuracy: 0.7100 - val_loss: 12.0503 - val_accuracy: 0.4832\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 3.2118 - accuracy: 0.7300 - val_loss: 14.2130 - val_accuracy: 0.3139\n",
            "100\n",
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:10<00:52, 10.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "32/32 [==============================] - 2s 70ms/step - loss: 63.0606 - accuracy: 0.2600 - val_loss: 15.1024 - val_accuracy: 0.4439\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 67ms/step - loss: 72.8970 - accuracy: 0.4280 - val_loss: 18.0800 - val_accuracy: 0.4166\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 67ms/step - loss: 19.8576 - accuracy: 0.4680 - val_loss: 19.5164 - val_accuracy: 0.4583\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 18.4561 - accuracy: 0.5160 - val_loss: 21.2128 - val_accuracy: 0.4951\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 28.8829 - accuracy: 0.5760 - val_loss: 34.5703 - val_accuracy: 0.5119\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 7.0341 - accuracy: 0.6200 - val_loss: 27.7876 - val_accuracy: 0.5298\n",
            "250\n",
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [00:24<00:46, 11.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 42.3914 - accuracy: 0.2820 - val_loss: 11.4876 - val_accuracy: 0.2484\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 21.7327 - accuracy: 0.3520 - val_loss: 17.6020 - val_accuracy: 0.3879\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 18.9507 - accuracy: 0.4560 - val_loss: 18.6102 - val_accuracy: 0.4107\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 14.5819 - accuracy: 0.5040 - val_loss: 15.8782 - val_accuracy: 0.4552\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 5.5965 - accuracy: 0.5240 - val_loss: 19.0468 - val_accuracy: 0.4390\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 7.3302 - accuracy: 0.5040 - val_loss: 22.5580 - val_accuracy: 0.4425\n",
            "500\n",
            "Model: \"model_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [00:45<00:43, 14.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 6s 47ms/step - loss: 24.1611 - accuracy: 0.3960 - val_loss: 17.1788 - val_accuracy: 0.3865\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 47.5280 - accuracy: 0.4600 - val_loss: 19.0997 - val_accuracy: 0.4695\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 13.6334 - accuracy: 0.4900 - val_loss: 11.5108 - val_accuracy: 0.4807\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 7.3668 - accuracy: 0.4900 - val_loss: 11.5973 - val_accuracy: 0.4895\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 4.2510 - accuracy: 0.5450 - val_loss: 13.6845 - val_accuracy: 0.5270\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 6.3108 - accuracy: 0.5700 - val_loss: 12.1329 - val_accuracy: 0.5505\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 6s 46ms/step - loss: 4.8592 - accuracy: 0.5780 - val_loss: 12.0654 - val_accuracy: 0.5343\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 6s 47ms/step - loss: 3.9222 - accuracy: 0.5660 - val_loss: 11.5885 - val_accuracy: 0.5357\n",
            "1000\n",
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [01:33<00:48, 24.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 38.0875 - accuracy: 0.3485 - val_loss: 19.5050 - val_accuracy: 0.4278\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 45.1961 - accuracy: 0.3885 - val_loss: 12.4101 - val_accuracy: 0.4355\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 12.4108 - accuracy: 0.4395 - val_loss: 19.8568 - val_accuracy: 0.4769\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 4.9684 - accuracy: 0.5040 - val_loss: 15.0448 - val_accuracy: 0.5340\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 4.3043 - accuracy: 0.5235 - val_loss: 14.1339 - val_accuracy: 0.5298\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 3.7557 - accuracy: 0.5365 - val_loss: 14.6175 - val_accuracy: 0.5431\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 3.5983 - accuracy: 0.5080 - val_loss: 14.9225 - val_accuracy: 0.4716\n",
            "2000\n",
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [02:49<00:39, 39.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 32.9158 - accuracy: 0.2708 - val_loss: 11.0829 - val_accuracy: 0.2901\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 19.2911 - accuracy: 0.2650 - val_loss: 8.8031 - val_accuracy: 0.2831\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 6.0474 - accuracy: 0.2922 - val_loss: 6.3110 - val_accuracy: 0.2922\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 5.9694 - accuracy: 0.2770 - val_loss: 6.0842 - val_accuracy: 0.3220\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 5.1733 - accuracy: 0.3296 - val_loss: 6.9963 - val_accuracy: 0.3203\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.7432 - accuracy: 0.3506 - val_loss: 6.5957 - val_accuracy: 0.4033\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.7515 - accuracy: 0.3768 - val_loss: 6.0939 - val_accuracy: 0.4299\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.6347 - accuracy: 0.3950 - val_loss: 5.8886 - val_accuracy: 0.4460\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.6402 - accuracy: 0.4234 - val_loss: 5.5829 - val_accuracy: 0.4692\n",
            "Epoch 10/150\n",
            "625/625 [==============================] - 26s 41ms/step - loss: 3.6871 - accuracy: 0.4340 - val_loss: 5.4594 - val_accuracy: 0.4751\n",
            "Epoch 11/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.6668 - accuracy: 0.4406 - val_loss: 5.5954 - val_accuracy: 0.4744\n",
            "Epoch 12/150\n",
            "625/625 [==============================] - 25s 41ms/step - loss: 3.4975 - accuracy: 0.4510 - val_loss: 5.5167 - val_accuracy: 0.4940\n",
            "Epoch 13/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.6418 - accuracy: 0.4622 - val_loss: 5.6479 - val_accuracy: 0.4996\n",
            "Epoch 14/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.5549 - accuracy: 0.4650 - val_loss: 5.5653 - val_accuracy: 0.4972\n",
            "Epoch 15/150\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 3.5091 - accuracy: 0.4686 - val_loss: 5.8095 - val_accuracy: 0.4867\n",
            "5000\n",
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 31, 300)      6863100     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 29, 75)       67575       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 28, 75)       90075       embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 27, 75)       112575      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 75)        0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 1, 75)        0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 1, 75)        0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 3, 75)        0           average_pooling1d_3[0][0]        \n",
            "                                                                 average_pooling1d_4[0][0]        \n",
            "                                                                 average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 7,150,275\n",
            "Trainable params: 7,150,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [09:08<00:00, 91.34s/it] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN1D_free_.1</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.317</td>\n",
              "      <td>0.5093</td>\n",
              "      <td>0.4441</td>\n",
              "      <td>0.5163</td>\n",
              "      <td>0.4557</td>\n",
              "      <td>0.4834</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN1D_free_.1</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4821</td>\n",
              "      <td>0.2921</td>\n",
              "      <td>0.4508</td>\n",
              "      <td>0.3702</td>\n",
              "      <td>0.3744</td>\n",
              "      <td>0.4308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model       task      metric    0  ...    5000 10000 15000 25000\n",
              "2  CNN1D_free_.1  slc_de_tf    accuracy  NaN  ...  0.4834   NaN   NaN   NaN\n",
              "3  CNN1D_free_.1  slc_de_tf  avg_recall  NaN  ...  0.4308   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k6mDH4kXy7tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63ec25bb-887a-4a23-85aa-6382e52f4710"
      },
      "source": [
        " task = 'slc_de_tf'\n",
        "model = 'CNN1D_free_.01'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(obs,False,lr = .01)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 33.5067 - accuracy: 0.2600 - val_loss: 19.4199 - val_accuracy: 0.4334\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 6.4874 - accuracy: 0.6200 - val_loss: 16.9841 - val_accuracy: 0.5007\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 1.2603 - accuracy: 0.8400 - val_loss: 16.3206 - val_accuracy: 0.5399\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.5557 - accuracy: 0.9100 - val_loss: 16.1716 - val_accuracy: 0.5557\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0723 - accuracy: 0.9700 - val_loss: 16.0269 - val_accuracy: 0.5676\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.1024 - accuracy: 0.9900 - val_loss: 16.0012 - val_accuracy: 0.5704\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0550 - accuracy: 0.9900 - val_loss: 16.0578 - val_accuracy: 0.5680\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 16.1189 - val_accuracy: 0.5704\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0604 - accuracy: 0.9700 - val_loss: 16.0405 - val_accuracy: 0.5746\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 5.3222e-04 - accuracy: 1.0000 - val_loss: 15.9614 - val_accuracy: 0.5785\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 4.8058e-05 - accuracy: 1.0000 - val_loss: 15.9496 - val_accuracy: 0.5795\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.3704 - accuracy: 0.9900 - val_loss: 15.9061 - val_accuracy: 0.5771\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 15.9969 - val_accuracy: 0.5750\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 16.0253 - val_accuracy: 0.5739\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0067 - accuracy: 0.9900 - val_loss: 16.0061 - val_accuracy: 0.5729\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 2.3787e-04 - accuracy: 1.0000 - val_loss: 16.0039 - val_accuracy: 0.5739\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0096 - accuracy: 0.9800 - val_loss: 16.0431 - val_accuracy: 0.5792\n",
            "100\n",
            "Model: \"model_248\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [00:24<02:01, 24.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 30.9843 - accuracy: 0.4200 - val_loss: 13.9306 - val_accuracy: 0.5277\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 6.0297 - accuracy: 0.8040 - val_loss: 11.1020 - val_accuracy: 0.6237\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.3034 - accuracy: 0.9360 - val_loss: 10.7671 - val_accuracy: 0.6468\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1261 - accuracy: 0.9640 - val_loss: 10.6679 - val_accuracy: 0.6587\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 10.5155 - val_accuracy: 0.6647\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1611 - accuracy: 0.9680 - val_loss: 10.4977 - val_accuracy: 0.6629\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0676 - accuracy: 0.9880 - val_loss: 10.5276 - val_accuracy: 0.6633\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0131 - accuracy: 0.9920 - val_loss: 10.4135 - val_accuracy: 0.6650\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0482 - accuracy: 0.9880 - val_loss: 10.4130 - val_accuracy: 0.6594\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0881 - accuracy: 0.9840 - val_loss: 10.3369 - val_accuracy: 0.6647\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0627 - accuracy: 0.9960 - val_loss: 10.5134 - val_accuracy: 0.6685\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2411 - accuracy: 0.9920 - val_loss: 11.0994 - val_accuracy: 0.6608\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 10.8312 - val_accuracy: 0.6647\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5098 - accuracy: 0.9920 - val_loss: 10.6384 - val_accuracy: 0.6766\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0099 - accuracy: 0.9920 - val_loss: 10.6808 - val_accuracy: 0.6804\n",
            "250\n",
            "Model: \"model_249\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [00:55<01:45, 26.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 20.6388 - accuracy: 0.4960 - val_loss: 9.4991 - val_accuracy: 0.6356\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 1.4868 - accuracy: 0.8480 - val_loss: 8.1648 - val_accuracy: 0.6804\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.4035 - accuracy: 0.9320 - val_loss: 7.9093 - val_accuracy: 0.6976\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1125 - accuracy: 0.9620 - val_loss: 7.7402 - val_accuracy: 0.7088\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1009 - accuracy: 0.9880 - val_loss: 7.9069 - val_accuracy: 0.7078\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0733 - accuracy: 0.9800 - val_loss: 7.8234 - val_accuracy: 0.7137\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1461 - accuracy: 0.9840 - val_loss: 7.9493 - val_accuracy: 0.7260\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.0830 - accuracy: 0.9960 - val_loss: 7.9795 - val_accuracy: 0.7270\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.0571 - accuracy: 0.9880 - val_loss: 8.1746 - val_accuracy: 0.7228\n",
            "500\n",
            "Model: \"model_250\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [01:25<01:22, 27.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 6s 44ms/step - loss: 25.7273 - accuracy: 0.5510 - val_loss: 5.7382 - val_accuracy: 0.6875\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 2.3455 - accuracy: 0.8540 - val_loss: 4.5960 - val_accuracy: 0.7565\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.4392 - accuracy: 0.9450 - val_loss: 4.3624 - val_accuracy: 0.7765\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1418 - accuracy: 0.9630 - val_loss: 4.7173 - val_accuracy: 0.7807\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.2121 - accuracy: 0.9850 - val_loss: 4.5923 - val_accuracy: 0.7845\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1680 - accuracy: 0.9750 - val_loss: 4.8998 - val_accuracy: 0.7870\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 4.8325 - val_accuracy: 0.7954\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0974 - accuracy: 0.9860 - val_loss: 4.8802 - val_accuracy: 0.7978\n",
            "1000\n",
            "Model: \"model_251\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [02:08<01:04, 32.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 20.5453 - accuracy: 0.6255 - val_loss: 3.6497 - val_accuracy: 0.7961\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6502 - accuracy: 0.8860 - val_loss: 2.9030 - val_accuracy: 0.8189\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.8636 - accuracy: 0.9335 - val_loss: 2.7038 - val_accuracy: 0.8469\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.5282 - accuracy: 0.9690 - val_loss: 2.8766 - val_accuracy: 0.8591\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.3056 - accuracy: 0.9700 - val_loss: 2.8993 - val_accuracy: 0.8542\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.2789 - accuracy: 0.9765 - val_loss: 3.0182 - val_accuracy: 0.8560\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.1684 - accuracy: 0.9870 - val_loss: 3.2781 - val_accuracy: 0.8641\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.1321 - accuracy: 0.9840 - val_loss: 3.2499 - val_accuracy: 0.8641\n",
            "2000\n",
            "Model: \"model_252\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [03:26<00:45, 45.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 11.8328 - accuracy: 0.7396 - val_loss: 2.1699 - val_accuracy: 0.8718\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 1.4605 - accuracy: 0.9230 - val_loss: 1.8635 - val_accuracy: 0.8973\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.5634 - accuracy: 0.9506 - val_loss: 2.1407 - val_accuracy: 0.8963\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.3694 - accuracy: 0.9652 - val_loss: 2.3973 - val_accuracy: 0.8977\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.2353 - accuracy: 0.9750 - val_loss: 2.4295 - val_accuracy: 0.9145\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 23s 37ms/step - loss: 0.2856 - accuracy: 0.9770 - val_loss: 2.7956 - val_accuracy: 0.9103\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.2600 - accuracy: 0.9788 - val_loss: 2.8132 - val_accuracy: 0.9110\n",
            "5000\n",
            "Model: \"model_253\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [06:06<00:00, 61.17s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN1D_free_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5653</td>\n",
              "      <td>0.6606</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.8469</td>\n",
              "      <td>0.8939</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN1D_free_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2673</td>\n",
              "      <td>0.3676</td>\n",
              "      <td>0.4479</td>\n",
              "      <td>0.5756</td>\n",
              "      <td>0.6409</td>\n",
              "      <td>0.7303</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model       task      metric    0  ...    5000 10000 15000 25000\n",
              "2  CNN1D_free_.01  slc_de_tf    accuracy  NaN  ...  0.8939   NaN   NaN   NaN\n",
              "3  CNN1D_free_.01  slc_de_tf  avg_recall  NaN  ...  0.7303   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJs_rbuUm-MC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42c38d5c-d5f1-4ade-c513-0b40a1f7ae1a"
      },
      "source": [
        " task = 'slc_de_tf'\n",
        "model = 'CNN1D_free_.001'\n",
        "metrics = ['accuracy','avg_recall']\n",
        "\n",
        "for m in metrics:\n",
        "    if len(df_results[(df_results['model']==model) & (df_results['task']==task)& (df_results['metric']==m)])==0:\n",
        "        df_results = df_results.append({'model': model,'task':task,'metric':m}, ignore_index=True)\n",
        "\n",
        "for obs in tqdm([100,250,500,1000,2000,5000]):\n",
        "     transfer_cnn(obs,False,lr = .001)\n",
        "\n",
        "df_results[(df_results['model']==model) & (df_results['task']==task)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 72.7377 - accuracy: 0.3300 - val_loss: 24.0922 - val_accuracy: 0.3644\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 60.9595 - accuracy: 0.3200 - val_loss: 23.1753 - val_accuracy: 0.3707\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 52.7246 - accuracy: 0.3300 - val_loss: 22.3902 - val_accuracy: 0.3791\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 44.0750 - accuracy: 0.3700 - val_loss: 21.6803 - val_accuracy: 0.3840\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 31.0680 - accuracy: 0.4000 - val_loss: 21.0199 - val_accuracy: 0.3935\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 29.8502 - accuracy: 0.4300 - val_loss: 20.4812 - val_accuracy: 0.3980\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 22.1960 - accuracy: 0.4200 - val_loss: 19.9716 - val_accuracy: 0.4008\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 17.9765 - accuracy: 0.4400 - val_loss: 19.5207 - val_accuracy: 0.4064\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 13.0810 - accuracy: 0.4800 - val_loss: 19.1289 - val_accuracy: 0.4107\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 11.2524 - accuracy: 0.5300 - val_loss: 18.7689 - val_accuracy: 0.4149\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 10.8453 - accuracy: 0.5900 - val_loss: 18.4547 - val_accuracy: 0.4166\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 6.3896 - accuracy: 0.6200 - val_loss: 18.1909 - val_accuracy: 0.4205\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 3.6788 - accuracy: 0.6700 - val_loss: 17.9460 - val_accuracy: 0.4254\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 4.1280 - accuracy: 0.6700 - val_loss: 17.7249 - val_accuracy: 0.4299\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 4.5429 - accuracy: 0.6500 - val_loss: 17.5196 - val_accuracy: 0.4341\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 2.3683 - accuracy: 0.7600 - val_loss: 17.3252 - val_accuracy: 0.4380\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 2.1061 - accuracy: 0.7400 - val_loss: 17.1660 - val_accuracy: 0.4425\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 3.4345 - accuracy: 0.7300 - val_loss: 16.9692 - val_accuracy: 0.4457\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 1.2259 - accuracy: 0.8500 - val_loss: 16.8442 - val_accuracy: 0.4516\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 1.2177 - accuracy: 0.7900 - val_loss: 16.7551 - val_accuracy: 0.4555\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 1.3091 - accuracy: 0.8700 - val_loss: 16.6606 - val_accuracy: 0.4573\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.9710 - accuracy: 0.8400 - val_loss: 16.5793 - val_accuracy: 0.4587\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 1.2783 - accuracy: 0.8100 - val_loss: 16.4778 - val_accuracy: 0.4643\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 1.1644 - accuracy: 0.8100 - val_loss: 16.3886 - val_accuracy: 0.4660\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.3876 - accuracy: 0.8800 - val_loss: 16.3135 - val_accuracy: 0.4674\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.5613 - accuracy: 0.8800 - val_loss: 16.2636 - val_accuracy: 0.4692\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.1812 - accuracy: 0.9400 - val_loss: 16.2337 - val_accuracy: 0.4692\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.3632 - accuracy: 0.8900 - val_loss: 16.1800 - val_accuracy: 0.4730\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.3729 - accuracy: 0.8900 - val_loss: 16.1272 - val_accuracy: 0.4783\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1060 - accuracy: 0.9400 - val_loss: 16.0681 - val_accuracy: 0.4790\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.2695 - accuracy: 0.8900 - val_loss: 15.9917 - val_accuracy: 0.4825\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.3263 - accuracy: 0.9300 - val_loss: 15.9511 - val_accuracy: 0.4835\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0797 - accuracy: 0.9600 - val_loss: 15.9334 - val_accuracy: 0.4867\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.1476 - accuracy: 0.9700 - val_loss: 15.9270 - val_accuracy: 0.4867\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.7292 - accuracy: 0.9100 - val_loss: 15.9113 - val_accuracy: 0.4867\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1217 - accuracy: 0.9400 - val_loss: 15.8763 - val_accuracy: 0.4902\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.8290 - accuracy: 0.9500 - val_loss: 15.8386 - val_accuracy: 0.4902\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.1076 - accuracy: 0.9500 - val_loss: 15.8008 - val_accuracy: 0.4933\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0565 - accuracy: 0.9700 - val_loss: 15.7767 - val_accuracy: 0.4940\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0376 - accuracy: 0.9800 - val_loss: 15.7678 - val_accuracy: 0.4947\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.1432 - accuracy: 0.9300 - val_loss: 15.7592 - val_accuracy: 0.4965\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.1460 - accuracy: 0.9600 - val_loss: 15.7493 - val_accuracy: 0.4989\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0420 - accuracy: 0.9700 - val_loss: 15.7394 - val_accuracy: 0.5011\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0273 - accuracy: 0.9800 - val_loss: 15.7298 - val_accuracy: 0.5011\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0188 - accuracy: 0.9700 - val_loss: 15.7166 - val_accuracy: 0.5021\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0215 - accuracy: 0.9700 - val_loss: 15.7039 - val_accuracy: 0.5018\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0201 - accuracy: 0.9800 - val_loss: 15.6936 - val_accuracy: 0.5018\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.4190 - accuracy: 0.9500 - val_loss: 15.6771 - val_accuracy: 0.5014\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0074 - accuracy: 0.9900 - val_loss: 15.6667 - val_accuracy: 0.5014\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0291 - accuracy: 0.9700 - val_loss: 15.6537 - val_accuracy: 0.5025\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 15.6461 - val_accuracy: 0.5025\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0532 - accuracy: 0.9600 - val_loss: 15.6332 - val_accuracy: 0.5032\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.6424 - accuracy: 0.9700 - val_loss: 15.6109 - val_accuracy: 0.5060\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0720 - accuracy: 0.9600 - val_loss: 15.5911 - val_accuracy: 0.5063\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0708 - accuracy: 0.9600 - val_loss: 15.5759 - val_accuracy: 0.5053\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0653 - accuracy: 0.9700 - val_loss: 15.5507 - val_accuracy: 0.5081\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1175 - accuracy: 0.9900 - val_loss: 15.5342 - val_accuracy: 0.5074\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0326 - accuracy: 0.9700 - val_loss: 15.5308 - val_accuracy: 0.5067\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0076 - accuracy: 0.9900 - val_loss: 15.5244 - val_accuracy: 0.5088\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0117 - accuracy: 0.9900 - val_loss: 15.5163 - val_accuracy: 0.5091\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0433 - accuracy: 0.9700 - val_loss: 15.5200 - val_accuracy: 0.5091\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0576 - accuracy: 0.9700 - val_loss: 15.4955 - val_accuracy: 0.5112\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0213 - accuracy: 0.9900 - val_loss: 15.4808 - val_accuracy: 0.5130\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0410 - accuracy: 0.9700 - val_loss: 15.4795 - val_accuracy: 0.5119\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 15.4860 - val_accuracy: 0.5116\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 15.4860 - val_accuracy: 0.5112\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.6525 - accuracy: 0.9800 - val_loss: 15.4667 - val_accuracy: 0.5109\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0056 - accuracy: 0.9900 - val_loss: 15.4364 - val_accuracy: 0.5116\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0074 - accuracy: 0.9900 - val_loss: 15.4273 - val_accuracy: 0.5112\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0137 - accuracy: 0.9900 - val_loss: 15.4112 - val_accuracy: 0.5126\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 15.4024 - val_accuracy: 0.5123\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1128 - accuracy: 0.9700 - val_loss: 15.4122 - val_accuracy: 0.5109\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0181 - accuracy: 0.9800 - val_loss: 15.4037 - val_accuracy: 0.5116\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 2.9473e-04 - accuracy: 1.0000 - val_loss: 15.3988 - val_accuracy: 0.5116\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.4674 - accuracy: 0.9800 - val_loss: 15.3566 - val_accuracy: 0.5151\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 15.3379 - val_accuracy: 0.5147\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0183 - accuracy: 0.9900 - val_loss: 15.3305 - val_accuracy: 0.5151\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 15.3303 - val_accuracy: 0.5147\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 15.3311 - val_accuracy: 0.5151\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0513 - accuracy: 0.9900 - val_loss: 15.3252 - val_accuracy: 0.5151\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0719 - accuracy: 0.9800 - val_loss: 15.3053 - val_accuracy: 0.5154\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0098 - accuracy: 0.9900 - val_loss: 15.2944 - val_accuracy: 0.5144\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0179 - accuracy: 0.9900 - val_loss: 15.2892 - val_accuracy: 0.5144\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0109 - accuracy: 0.9900 - val_loss: 15.2833 - val_accuracy: 0.5158\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 3.1733e-04 - accuracy: 1.0000 - val_loss: 15.2804 - val_accuracy: 0.5161\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0505 - accuracy: 0.9800 - val_loss: 15.2742 - val_accuracy: 0.5168\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 15.2718 - val_accuracy: 0.5172\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0669 - accuracy: 0.9900 - val_loss: 15.2660 - val_accuracy: 0.5179\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 3.3899e-04 - accuracy: 1.0000 - val_loss: 15.2623 - val_accuracy: 0.5179\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 15.2602 - val_accuracy: 0.5182\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 1.5144e-04 - accuracy: 1.0000 - val_loss: 15.2594 - val_accuracy: 0.5186\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 15.2589 - val_accuracy: 0.5186\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 15.2430 - val_accuracy: 0.5186\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0149 - accuracy: 0.9900 - val_loss: 15.2354 - val_accuracy: 0.5189\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 15.2411 - val_accuracy: 0.5196\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0724 - accuracy: 0.9900 - val_loss: 15.2344 - val_accuracy: 0.5203\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 15.2244 - val_accuracy: 0.5207\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 5.1248e-04 - accuracy: 1.0000 - val_loss: 15.2162 - val_accuracy: 0.5221\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0071 - accuracy: 0.9900 - val_loss: 15.2061 - val_accuracy: 0.5224\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0075 - accuracy: 0.9900 - val_loss: 15.1878 - val_accuracy: 0.5224\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 15.1778 - val_accuracy: 0.5231\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 15.1718 - val_accuracy: 0.5231\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 15.1679 - val_accuracy: 0.5235\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0053 - accuracy: 0.9900 - val_loss: 15.1533 - val_accuracy: 0.5238\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 1.1330e-04 - accuracy: 1.0000 - val_loss: 15.1475 - val_accuracy: 0.5238\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 15.1451 - val_accuracy: 0.5238\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 5.4284e-04 - accuracy: 1.0000 - val_loss: 15.1436 - val_accuracy: 0.5238\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 15.1352 - val_accuracy: 0.5249\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0121 - accuracy: 0.9900 - val_loss: 15.1233 - val_accuracy: 0.5249\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 15.1163 - val_accuracy: 0.5249\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 8.0419e-04 - accuracy: 1.0000 - val_loss: 15.1118 - val_accuracy: 0.5249\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 15.1084 - val_accuracy: 0.5245\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 15.1056 - val_accuracy: 0.5252\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 1.0264e-04 - accuracy: 1.0000 - val_loss: 15.1042 - val_accuracy: 0.5259\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 2.0798e-04 - accuracy: 1.0000 - val_loss: 15.1037 - val_accuracy: 0.5259\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.0042 - accuracy: 0.9900 - val_loss: 15.0963 - val_accuracy: 0.5263\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 15.0864 - val_accuracy: 0.5263\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0200 - accuracy: 0.9900 - val_loss: 15.0791 - val_accuracy: 0.5263\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0562 - accuracy: 0.9900 - val_loss: 15.0837 - val_accuracy: 0.5266\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 1.6855e-04 - accuracy: 1.0000 - val_loss: 15.1001 - val_accuracy: 0.5266\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 15.1001 - val_accuracy: 0.5256\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 15.0988 - val_accuracy: 0.5259\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 4.9732e-04 - accuracy: 1.0000 - val_loss: 15.0980 - val_accuracy: 0.5259\n",
            "100\n",
            "Model: \"model_254\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [02:48<14:01, 168.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 39.6539 - accuracy: 0.3320 - val_loss: 22.9583 - val_accuracy: 0.3735\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 29.5172 - accuracy: 0.3760 - val_loss: 21.2120 - val_accuracy: 0.3882\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 22.7916 - accuracy: 0.4120 - val_loss: 19.7011 - val_accuracy: 0.4001\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 18.3346 - accuracy: 0.4800 - val_loss: 18.5753 - val_accuracy: 0.4156\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 11.7863 - accuracy: 0.5600 - val_loss: 17.6988 - val_accuracy: 0.4233\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 11.1582 - accuracy: 0.5640 - val_loss: 16.8931 - val_accuracy: 0.4310\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 7.1356 - accuracy: 0.6280 - val_loss: 16.1623 - val_accuracy: 0.4492\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 6.9790 - accuracy: 0.6480 - val_loss: 15.5396 - val_accuracy: 0.4597\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 3.7872 - accuracy: 0.7240 - val_loss: 15.0238 - val_accuracy: 0.4737\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 2.2821 - accuracy: 0.7560 - val_loss: 14.6632 - val_accuracy: 0.4877\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.6296 - accuracy: 0.8160 - val_loss: 14.3758 - val_accuracy: 0.4923\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.4011 - accuracy: 0.8440 - val_loss: 14.1649 - val_accuracy: 0.4968\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.4774 - accuracy: 0.8240 - val_loss: 13.9298 - val_accuracy: 0.5042\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.6450 - accuracy: 0.8440 - val_loss: 13.6245 - val_accuracy: 0.5168\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.8041 - accuracy: 0.8440 - val_loss: 13.4438 - val_accuracy: 0.5224\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.6753 - accuracy: 0.8800 - val_loss: 13.2879 - val_accuracy: 0.5263\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.6306 - accuracy: 0.8960 - val_loss: 13.1666 - val_accuracy: 0.5294\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.8039 - accuracy: 0.8960 - val_loss: 13.0377 - val_accuracy: 0.5329\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.4624 - accuracy: 0.8960 - val_loss: 12.9390 - val_accuracy: 0.5357\n",
            "Epoch 20/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.0054 - accuracy: 0.9120 - val_loss: 12.8363 - val_accuracy: 0.5406\n",
            "Epoch 21/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3777 - accuracy: 0.9400 - val_loss: 12.7149 - val_accuracy: 0.5459\n",
            "Epoch 22/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1625 - accuracy: 0.9440 - val_loss: 12.6514 - val_accuracy: 0.5466\n",
            "Epoch 23/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1965 - accuracy: 0.9480 - val_loss: 12.5758 - val_accuracy: 0.5529\n",
            "Epoch 24/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1488 - accuracy: 0.9600 - val_loss: 12.5325 - val_accuracy: 0.5540\n",
            "Epoch 25/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5825 - accuracy: 0.9480 - val_loss: 12.4664 - val_accuracy: 0.5589\n",
            "Epoch 26/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2339 - accuracy: 0.9440 - val_loss: 12.4003 - val_accuracy: 0.5606\n",
            "Epoch 27/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1482 - accuracy: 0.9520 - val_loss: 12.3487 - val_accuracy: 0.5624\n",
            "Epoch 28/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.3046 - accuracy: 0.9480 - val_loss: 12.2486 - val_accuracy: 0.5645\n",
            "Epoch 29/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.2434 - accuracy: 0.9560 - val_loss: 12.1898 - val_accuracy: 0.5694\n",
            "Epoch 30/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2636 - accuracy: 0.9280 - val_loss: 12.1850 - val_accuracy: 0.5697\n",
            "Epoch 31/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0507 - accuracy: 0.9760 - val_loss: 12.1595 - val_accuracy: 0.5690\n",
            "Epoch 32/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1486 - accuracy: 0.9600 - val_loss: 12.1261 - val_accuracy: 0.5708\n",
            "Epoch 33/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0453 - accuracy: 0.9720 - val_loss: 12.1051 - val_accuracy: 0.5750\n",
            "Epoch 34/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.4606 - accuracy: 0.9680 - val_loss: 12.0622 - val_accuracy: 0.5750\n",
            "Epoch 35/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0171 - accuracy: 0.9880 - val_loss: 12.0544 - val_accuracy: 0.5743\n",
            "Epoch 36/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 12.0484 - val_accuracy: 0.5739\n",
            "Epoch 37/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0715 - accuracy: 0.9720 - val_loss: 12.0264 - val_accuracy: 0.5750\n",
            "Epoch 38/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0478 - accuracy: 0.9800 - val_loss: 12.0009 - val_accuracy: 0.5767\n",
            "Epoch 39/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 11.9904 - val_accuracy: 0.5771\n",
            "Epoch 40/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0804 - accuracy: 0.9800 - val_loss: 11.9268 - val_accuracy: 0.5799\n",
            "Epoch 41/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1400 - accuracy: 0.9560 - val_loss: 11.8949 - val_accuracy: 0.5820\n",
            "Epoch 42/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0266 - accuracy: 0.9880 - val_loss: 11.8737 - val_accuracy: 0.5841\n",
            "Epoch 43/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0462 - accuracy: 0.9760 - val_loss: 11.8493 - val_accuracy: 0.5841\n",
            "Epoch 44/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0372 - accuracy: 0.9840 - val_loss: 11.7986 - val_accuracy: 0.5855\n",
            "Epoch 45/150\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 11.8072 - val_accuracy: 0.5834\n",
            "Epoch 46/150\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 11.8118 - val_accuracy: 0.5837\n",
            "Epoch 47/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 11.8040 - val_accuracy: 0.5862\n",
            "Epoch 48/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 11.7991 - val_accuracy: 0.5869\n",
            "Epoch 49/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0260 - accuracy: 0.9800 - val_loss: 11.7770 - val_accuracy: 0.5872\n",
            "Epoch 50/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0146 - accuracy: 0.9880 - val_loss: 11.7752 - val_accuracy: 0.5879\n",
            "Epoch 51/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0124 - accuracy: 0.9920 - val_loss: 11.7622 - val_accuracy: 0.5890\n",
            "Epoch 52/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0160 - accuracy: 0.9920 - val_loss: 11.7789 - val_accuracy: 0.5879\n",
            "Epoch 53/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 11.7881 - val_accuracy: 0.5876\n",
            "Epoch 54/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 11.7743 - val_accuracy: 0.5886\n",
            "Epoch 55/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0185 - accuracy: 0.9920 - val_loss: 11.7572 - val_accuracy: 0.5900\n",
            "Epoch 56/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0128 - accuracy: 0.9880 - val_loss: 11.7580 - val_accuracy: 0.5897\n",
            "Epoch 57/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 11.7491 - val_accuracy: 0.5897\n",
            "Epoch 58/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0042 - accuracy: 0.9920 - val_loss: 11.7391 - val_accuracy: 0.5897\n",
            "Epoch 59/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0874 - accuracy: 0.9840 - val_loss: 11.6455 - val_accuracy: 0.5893\n",
            "Epoch 60/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 11.6228 - val_accuracy: 0.5890\n",
            "Epoch 61/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0320 - accuracy: 0.9720 - val_loss: 11.6055 - val_accuracy: 0.5929\n",
            "Epoch 62/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0593 - accuracy: 0.9920 - val_loss: 11.6342 - val_accuracy: 0.5929\n",
            "Epoch 63/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0628 - accuracy: 0.9920 - val_loss: 11.6514 - val_accuracy: 0.5936\n",
            "Epoch 64/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0758 - accuracy: 0.9880 - val_loss: 11.6049 - val_accuracy: 0.5943\n",
            "Epoch 65/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0024 - accuracy: 0.9960 - val_loss: 11.5773 - val_accuracy: 0.5953\n",
            "Epoch 66/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0037 - accuracy: 0.9960 - val_loss: 11.5693 - val_accuracy: 0.5953\n",
            "Epoch 67/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2465 - accuracy: 0.9880 - val_loss: 11.5372 - val_accuracy: 0.5957\n",
            "Epoch 68/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0167 - accuracy: 0.9920 - val_loss: 11.4985 - val_accuracy: 0.5974\n",
            "Epoch 69/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0026 - accuracy: 0.9960 - val_loss: 11.4872 - val_accuracy: 0.5985\n",
            "Epoch 70/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0198 - accuracy: 0.9920 - val_loss: 11.4794 - val_accuracy: 0.5981\n",
            "Epoch 71/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0115 - accuracy: 0.9920 - val_loss: 11.4537 - val_accuracy: 0.6002\n",
            "Epoch 72/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0221 - accuracy: 0.9960 - val_loss: 11.4351 - val_accuracy: 0.6013\n",
            "Epoch 73/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0173 - accuracy: 0.9920 - val_loss: 11.4272 - val_accuracy: 0.6016\n",
            "Epoch 74/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0194 - accuracy: 0.9880 - val_loss: 11.4205 - val_accuracy: 0.6044\n",
            "Epoch 75/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 11.4190 - val_accuracy: 0.6041\n",
            "Epoch 76/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 11.4172 - val_accuracy: 0.6044\n",
            "Epoch 77/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0024 - accuracy: 0.9920 - val_loss: 11.4175 - val_accuracy: 0.6044\n",
            "Epoch 78/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 11.4156 - val_accuracy: 0.6044\n",
            "Epoch 79/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0147 - accuracy: 0.9920 - val_loss: 11.4080 - val_accuracy: 0.6051\n",
            "Epoch 80/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0115 - accuracy: 0.9920 - val_loss: 11.3957 - val_accuracy: 0.6048\n",
            "Epoch 81/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0340 - accuracy: 0.9840 - val_loss: 11.3810 - val_accuracy: 0.6051\n",
            "Epoch 82/150\n",
            "32/32 [==============================] - 2s 69ms/step - loss: 0.0060 - accuracy: 0.9960 - val_loss: 11.3729 - val_accuracy: 0.6076\n",
            "Epoch 83/150\n",
            "32/32 [==============================] - 2s 68ms/step - loss: 0.0029 - accuracy: 0.9960 - val_loss: 11.3646 - val_accuracy: 0.6093\n",
            "Epoch 84/150\n",
            "32/32 [==============================] - 2s 68ms/step - loss: 0.0179 - accuracy: 0.9920 - val_loss: 11.3208 - val_accuracy: 0.6093\n",
            "Epoch 85/150\n",
            "32/32 [==============================] - 2s 68ms/step - loss: 0.0526 - accuracy: 0.9960 - val_loss: 11.2400 - val_accuracy: 0.6069\n",
            "Epoch 86/150\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 2.5992e-04 - accuracy: 1.0000 - val_loss: 11.2292 - val_accuracy: 0.6058\n",
            "Epoch 87/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0079 - accuracy: 0.9960 - val_loss: 11.2196 - val_accuracy: 0.6079\n",
            "Epoch 88/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 11.1992 - val_accuracy: 0.6083\n",
            "Epoch 89/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 11.1923 - val_accuracy: 0.6093\n",
            "Epoch 90/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0626 - accuracy: 0.9920 - val_loss: 11.1669 - val_accuracy: 0.6086\n",
            "Epoch 91/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0085 - accuracy: 0.9920 - val_loss: 11.1529 - val_accuracy: 0.6100\n",
            "Epoch 92/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 11.1472 - val_accuracy: 0.6097\n",
            "Epoch 93/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0074 - accuracy: 0.9960 - val_loss: 11.1263 - val_accuracy: 0.6114\n",
            "Epoch 94/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0191 - accuracy: 0.9920 - val_loss: 11.1138 - val_accuracy: 0.6132\n",
            "Epoch 95/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 8.6754e-04 - accuracy: 0.9960 - val_loss: 11.1103 - val_accuracy: 0.6132\n",
            "Epoch 96/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 11.0958 - val_accuracy: 0.6142\n",
            "Epoch 97/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 2.0801e-04 - accuracy: 1.0000 - val_loss: 11.0925 - val_accuracy: 0.6146\n",
            "Epoch 98/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0035 - accuracy: 0.9920 - val_loss: 11.0786 - val_accuracy: 0.6149\n",
            "Epoch 99/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 4.8197e-04 - accuracy: 1.0000 - val_loss: 11.0695 - val_accuracy: 0.6160\n",
            "Epoch 100/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 2.7043e-04 - accuracy: 1.0000 - val_loss: 11.0688 - val_accuracy: 0.6163\n",
            "Epoch 101/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 11.0581 - val_accuracy: 0.6174\n",
            "Epoch 102/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0162 - accuracy: 0.9920 - val_loss: 11.0276 - val_accuracy: 0.6198\n",
            "Epoch 103/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 4.8175e-04 - accuracy: 1.0000 - val_loss: 11.0256 - val_accuracy: 0.6209\n",
            "Epoch 104/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 10.9843 - val_accuracy: 0.6219\n",
            "Epoch 105/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 10.9787 - val_accuracy: 0.6226\n",
            "Epoch 106/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 10.9645 - val_accuracy: 0.6226\n",
            "Epoch 107/150\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 10.9649 - val_accuracy: 0.6240\n",
            "Epoch 108/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 10.9575 - val_accuracy: 0.6251\n",
            "Epoch 109/150\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 10.9554 - val_accuracy: 0.6251\n",
            "Epoch 110/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 4.6773e-05 - accuracy: 1.0000 - val_loss: 10.9561 - val_accuracy: 0.6240\n",
            "Epoch 111/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 10.9472 - val_accuracy: 0.6265\n",
            "Epoch 112/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 10.9517 - val_accuracy: 0.6268\n",
            "Epoch 113/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 4.0236e-04 - accuracy: 1.0000 - val_loss: 10.9679 - val_accuracy: 0.6268\n",
            "Epoch 114/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 2.6946e-04 - accuracy: 1.0000 - val_loss: 10.9676 - val_accuracy: 0.6268\n",
            "Epoch 115/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0419 - accuracy: 0.9960 - val_loss: 10.9587 - val_accuracy: 0.6268\n",
            "Epoch 116/150\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1280 - accuracy: 0.9920 - val_loss: 10.9954 - val_accuracy: 0.6258\n",
            "250\n",
            "Model: \"model_255\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [06:45<12:35, 188.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 41.8431 - accuracy: 0.3340 - val_loss: 21.0100 - val_accuracy: 0.3812\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 31.2287 - accuracy: 0.4080 - val_loss: 18.0848 - val_accuracy: 0.4047\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 21.5164 - accuracy: 0.4380 - val_loss: 15.6196 - val_accuracy: 0.4362\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 13.6950 - accuracy: 0.4980 - val_loss: 13.8370 - val_accuracy: 0.4706\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 8.8326 - accuracy: 0.6040 - val_loss: 12.4687 - val_accuracy: 0.4919\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 5.8391 - accuracy: 0.6460 - val_loss: 11.4001 - val_accuracy: 0.5238\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 3.9837 - accuracy: 0.7020 - val_loss: 10.4924 - val_accuracy: 0.5554\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 2.7468 - accuracy: 0.7600 - val_loss: 9.9549 - val_accuracy: 0.5774\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 1.5684 - accuracy: 0.8020 - val_loss: 9.6009 - val_accuracy: 0.5971\n",
            "Epoch 10/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 1.0380 - accuracy: 0.8440 - val_loss: 9.3216 - val_accuracy: 0.6079\n",
            "Epoch 11/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 1.0918 - accuracy: 0.8660 - val_loss: 9.0889 - val_accuracy: 0.6184\n",
            "Epoch 12/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.4744 - accuracy: 0.8980 - val_loss: 8.9152 - val_accuracy: 0.6258\n",
            "Epoch 13/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.4848 - accuracy: 0.9040 - val_loss: 8.7580 - val_accuracy: 0.6359\n",
            "Epoch 14/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.4683 - accuracy: 0.9040 - val_loss: 8.5991 - val_accuracy: 0.6475\n",
            "Epoch 15/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2954 - accuracy: 0.9220 - val_loss: 8.5189 - val_accuracy: 0.6524\n",
            "Epoch 16/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.3316 - accuracy: 0.9380 - val_loss: 8.3882 - val_accuracy: 0.6559\n",
            "Epoch 17/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2748 - accuracy: 0.9340 - val_loss: 8.2988 - val_accuracy: 0.6615\n",
            "Epoch 18/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2763 - accuracy: 0.9300 - val_loss: 8.2052 - val_accuracy: 0.6654\n",
            "Epoch 19/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2043 - accuracy: 0.9600 - val_loss: 8.1904 - val_accuracy: 0.6678\n",
            "Epoch 20/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1598 - accuracy: 0.9620 - val_loss: 8.1259 - val_accuracy: 0.6727\n",
            "Epoch 21/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1027 - accuracy: 0.9740 - val_loss: 8.1011 - val_accuracy: 0.6752\n",
            "Epoch 22/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1738 - accuracy: 0.9620 - val_loss: 8.0322 - val_accuracy: 0.6755\n",
            "Epoch 23/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0618 - accuracy: 0.9700 - val_loss: 7.9834 - val_accuracy: 0.6766\n",
            "Epoch 24/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.3979 - accuracy: 0.9620 - val_loss: 7.9372 - val_accuracy: 0.6787\n",
            "Epoch 25/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0603 - accuracy: 0.9740 - val_loss: 7.9256 - val_accuracy: 0.6808\n",
            "Epoch 26/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1090 - accuracy: 0.9780 - val_loss: 7.8791 - val_accuracy: 0.6850\n",
            "Epoch 27/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0249 - accuracy: 0.9840 - val_loss: 7.8650 - val_accuracy: 0.6861\n",
            "Epoch 28/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0314 - accuracy: 0.9860 - val_loss: 7.8317 - val_accuracy: 0.6871\n",
            "Epoch 29/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0715 - accuracy: 0.9820 - val_loss: 7.8055 - val_accuracy: 0.6896\n",
            "Epoch 30/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0414 - accuracy: 0.9780 - val_loss: 7.7802 - val_accuracy: 0.6924\n",
            "Epoch 31/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0247 - accuracy: 0.9800 - val_loss: 7.7877 - val_accuracy: 0.6913\n",
            "Epoch 32/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0805 - accuracy: 0.9840 - val_loss: 7.7912 - val_accuracy: 0.6924\n",
            "Epoch 33/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0398 - accuracy: 0.9840 - val_loss: 7.7409 - val_accuracy: 0.6938\n",
            "Epoch 34/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0331 - accuracy: 0.9880 - val_loss: 7.7278 - val_accuracy: 0.6938\n",
            "Epoch 35/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 7.6853 - val_accuracy: 0.6955\n",
            "Epoch 36/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 7.6740 - val_accuracy: 0.6959\n",
            "Epoch 37/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0216 - accuracy: 0.9900 - val_loss: 7.6697 - val_accuracy: 0.6973\n",
            "Epoch 38/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0420 - accuracy: 0.9880 - val_loss: 7.6507 - val_accuracy: 0.6980\n",
            "Epoch 39/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 7.6357 - val_accuracy: 0.7008\n",
            "Epoch 40/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 7.6317 - val_accuracy: 0.7011\n",
            "Epoch 41/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0872 - accuracy: 0.9920 - val_loss: 7.6078 - val_accuracy: 0.7025\n",
            "Epoch 42/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0100 - accuracy: 0.9920 - val_loss: 7.5674 - val_accuracy: 0.7029\n",
            "Epoch 43/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 7.5533 - val_accuracy: 0.7032\n",
            "Epoch 44/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 7.5321 - val_accuracy: 0.7039\n",
            "Epoch 45/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0121 - accuracy: 0.9860 - val_loss: 7.5177 - val_accuracy: 0.7036\n",
            "Epoch 46/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 7.5093 - val_accuracy: 0.7060\n",
            "Epoch 47/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0502 - accuracy: 0.9920 - val_loss: 7.5012 - val_accuracy: 0.7064\n",
            "Epoch 48/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0197 - accuracy: 0.9900 - val_loss: 7.4978 - val_accuracy: 0.7057\n",
            "Epoch 49/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0056 - accuracy: 0.9960 - val_loss: 7.4899 - val_accuracy: 0.7064\n",
            "Epoch 50/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0087 - accuracy: 0.9960 - val_loss: 7.4840 - val_accuracy: 0.7071\n",
            "Epoch 51/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.0451 - accuracy: 0.9940 - val_loss: 7.4760 - val_accuracy: 0.7064\n",
            "Epoch 52/150\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.0782 - accuracy: 0.9960 - val_loss: 7.5013 - val_accuracy: 0.7071\n",
            "Epoch 53/150\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 7.4839 - val_accuracy: 0.7081\n",
            "Epoch 54/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0047 - accuracy: 0.9960 - val_loss: 7.4819 - val_accuracy: 0.7092\n",
            "Epoch 55/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0340 - accuracy: 0.9960 - val_loss: 7.4936 - val_accuracy: 0.7109\n",
            "Epoch 56/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 7.5528 - val_accuracy: 0.7088\n",
            "500\n",
            "Model: \"model_256\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [09:39<09:13, 184.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 40.3533 - accuracy: 0.3810 - val_loss: 17.9217 - val_accuracy: 0.4089\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 25.2519 - accuracy: 0.4440 - val_loss: 13.6692 - val_accuracy: 0.4580\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 14.1909 - accuracy: 0.5450 - val_loss: 10.9380 - val_accuracy: 0.5203\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 8.4844 - accuracy: 0.6370 - val_loss: 9.3567 - val_accuracy: 0.5687\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 4.6031 - accuracy: 0.7280 - val_loss: 8.2123 - val_accuracy: 0.6086\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 2.9868 - accuracy: 0.7710 - val_loss: 7.5293 - val_accuracy: 0.6370\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 1.7615 - accuracy: 0.8350 - val_loss: 7.0679 - val_accuracy: 0.6510\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 1.3283 - accuracy: 0.8470 - val_loss: 6.8262 - val_accuracy: 0.6703\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.6562 - accuracy: 0.8910 - val_loss: 6.6461 - val_accuracy: 0.6833\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.6514 - accuracy: 0.9030 - val_loss: 6.4448 - val_accuracy: 0.6941\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.5634 - accuracy: 0.9230 - val_loss: 6.2682 - val_accuracy: 0.7053\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.4151 - accuracy: 0.9220 - val_loss: 6.0942 - val_accuracy: 0.7116\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 6s 44ms/step - loss: 0.2564 - accuracy: 0.9470 - val_loss: 5.9866 - val_accuracy: 0.7176\n",
            "Epoch 14/150\n",
            "125/125 [==============================] - 5s 44ms/step - loss: 0.4523 - accuracy: 0.9520 - val_loss: 5.9193 - val_accuracy: 0.7214\n",
            "Epoch 15/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1643 - accuracy: 0.9630 - val_loss: 5.8418 - val_accuracy: 0.7292\n",
            "Epoch 16/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1371 - accuracy: 0.9640 - val_loss: 5.7636 - val_accuracy: 0.7302\n",
            "Epoch 17/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1998 - accuracy: 0.9700 - val_loss: 5.7432 - val_accuracy: 0.7295\n",
            "Epoch 18/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0852 - accuracy: 0.9760 - val_loss: 5.7138 - val_accuracy: 0.7320\n",
            "Epoch 19/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1182 - accuracy: 0.9710 - val_loss: 5.6663 - val_accuracy: 0.7386\n",
            "Epoch 20/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 5.6298 - val_accuracy: 0.7386\n",
            "Epoch 21/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0489 - accuracy: 0.9760 - val_loss: 5.6072 - val_accuracy: 0.7411\n",
            "Epoch 22/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0539 - accuracy: 0.9780 - val_loss: 5.5893 - val_accuracy: 0.7442\n",
            "Epoch 23/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0590 - accuracy: 0.9850 - val_loss: 5.5671 - val_accuracy: 0.7446\n",
            "Epoch 24/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0872 - accuracy: 0.9810 - val_loss: 5.5230 - val_accuracy: 0.7463\n",
            "Epoch 25/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 5.4868 - val_accuracy: 0.7509\n",
            "Epoch 26/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0532 - accuracy: 0.9880 - val_loss: 5.4694 - val_accuracy: 0.7519\n",
            "Epoch 27/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 5.4760 - val_accuracy: 0.7488\n",
            "Epoch 28/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0634 - accuracy: 0.9840 - val_loss: 5.4465 - val_accuracy: 0.7540\n",
            "Epoch 29/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0515 - accuracy: 0.9900 - val_loss: 5.4102 - val_accuracy: 0.7558\n",
            "Epoch 30/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 5.3631 - val_accuracy: 0.7537\n",
            "Epoch 31/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0148 - accuracy: 0.9930 - val_loss: 5.3147 - val_accuracy: 0.7558\n",
            "Epoch 32/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 5.2970 - val_accuracy: 0.7561\n",
            "Epoch 33/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 5.2871 - val_accuracy: 0.7582\n",
            "Epoch 34/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 5.2732 - val_accuracy: 0.7596\n",
            "Epoch 35/150\n",
            "125/125 [==============================] - 5s 41ms/step - loss: 0.1012 - accuracy: 0.9920 - val_loss: 5.3137 - val_accuracy: 0.7579\n",
            "Epoch 36/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 5.3027 - val_accuracy: 0.7540\n",
            "Epoch 37/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0177 - accuracy: 0.9900 - val_loss: 5.2818 - val_accuracy: 0.7572\n",
            "Epoch 38/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0568 - accuracy: 0.9960 - val_loss: 5.3128 - val_accuracy: 0.7554\n",
            "Epoch 39/150\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 5.4210 - val_accuracy: 0.7547\n",
            "1000\n",
            "Model: \"model_257\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [13:06<06:22, 191.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 41.9551 - accuracy: 0.3900 - val_loss: 13.2659 - val_accuracy: 0.4674\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 18.5222 - accuracy: 0.5445 - val_loss: 8.1255 - val_accuracy: 0.5760\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 8.9264 - accuracy: 0.6630 - val_loss: 5.9779 - val_accuracy: 0.6706\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.7368 - accuracy: 0.7670 - val_loss: 4.9826 - val_accuracy: 0.7204\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.5291 - accuracy: 0.8340 - val_loss: 4.4183 - val_accuracy: 0.7474\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 1.2988 - accuracy: 0.8655 - val_loss: 4.0711 - val_accuracy: 0.7694\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.9668 - accuracy: 0.8890 - val_loss: 3.8387 - val_accuracy: 0.7828\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.5932 - accuracy: 0.9130 - val_loss: 3.6674 - val_accuracy: 0.7950\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.4558 - accuracy: 0.9295 - val_loss: 3.5333 - val_accuracy: 0.8041\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.4310 - accuracy: 0.9485 - val_loss: 3.4328 - val_accuracy: 0.8104\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.2103 - accuracy: 0.9610 - val_loss: 3.4052 - val_accuracy: 0.8146\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.5348 - accuracy: 0.9595 - val_loss: 3.3492 - val_accuracy: 0.8227\n",
            "Epoch 13/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.2620 - accuracy: 0.9600 - val_loss: 3.3694 - val_accuracy: 0.8206\n",
            "Epoch 14/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.2024 - accuracy: 0.9670 - val_loss: 3.2704 - val_accuracy: 0.8255\n",
            "Epoch 15/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.1371 - accuracy: 0.9785 - val_loss: 3.2628 - val_accuracy: 0.8245\n",
            "Epoch 16/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 3.2603 - val_accuracy: 0.8259\n",
            "Epoch 17/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.2710 - accuracy: 0.9780 - val_loss: 3.2590 - val_accuracy: 0.8308\n",
            "Epoch 18/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.1103 - accuracy: 0.9770 - val_loss: 3.2382 - val_accuracy: 0.8325\n",
            "Epoch 19/150\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.1237 - accuracy: 0.9805 - val_loss: 3.2063 - val_accuracy: 0.8329\n",
            "Epoch 20/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 3.1583 - val_accuracy: 0.8346\n",
            "Epoch 21/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0636 - accuracy: 0.9865 - val_loss: 3.2067 - val_accuracy: 0.8367\n",
            "Epoch 22/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0434 - accuracy: 0.9915 - val_loss: 3.1997 - val_accuracy: 0.8395\n",
            "Epoch 23/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0154 - accuracy: 0.9910 - val_loss: 3.1651 - val_accuracy: 0.8409\n",
            "Epoch 24/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0240 - accuracy: 0.9905 - val_loss: 3.1592 - val_accuracy: 0.8423\n",
            "Epoch 25/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 3.1444 - val_accuracy: 0.8462\n",
            "Epoch 26/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0438 - accuracy: 0.9905 - val_loss: 3.1158 - val_accuracy: 0.8479\n",
            "Epoch 27/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 3.1067 - val_accuracy: 0.8486\n",
            "Epoch 28/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 3.0871 - val_accuracy: 0.8521\n",
            "Epoch 29/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 3.0902 - val_accuracy: 0.8521\n",
            "Epoch 30/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 3.1027 - val_accuracy: 0.8507\n",
            "Epoch 31/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0335 - accuracy: 0.9930 - val_loss: 3.0765 - val_accuracy: 0.8486\n",
            "Epoch 32/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 3.1160 - val_accuracy: 0.8465\n",
            "Epoch 33/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0345 - accuracy: 0.9930 - val_loss: 3.1227 - val_accuracy: 0.8500\n",
            "Epoch 34/150\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 3.1283 - val_accuracy: 0.8521\n",
            "Epoch 35/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 3.1172 - val_accuracy: 0.8532\n",
            "Epoch 36/150\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0162 - accuracy: 0.9965 - val_loss: 3.0881 - val_accuracy: 0.8546\n",
            "2000\n",
            "Model: \"model_258\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [18:46<03:56, 236.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 28.7153 - accuracy: 0.4686 - val_loss: 6.2617 - val_accuracy: 0.6258\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 6.8705 - accuracy: 0.7102 - val_loss: 3.2581 - val_accuracy: 0.7835\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 2.4139 - accuracy: 0.8226 - val_loss: 2.4861 - val_accuracy: 0.8290\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 1.0984 - accuracy: 0.8948 - val_loss: 2.1545 - val_accuracy: 0.8553\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.6231 - accuracy: 0.9192 - val_loss: 1.9535 - val_accuracy: 0.8672\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 23s 37ms/step - loss: 0.3798 - accuracy: 0.9390 - val_loss: 1.8088 - val_accuracy: 0.8777\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.3152 - accuracy: 0.9544 - val_loss: 1.7791 - val_accuracy: 0.8809\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1600 - accuracy: 0.9632 - val_loss: 1.7485 - val_accuracy: 0.8872\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1282 - accuracy: 0.9728 - val_loss: 1.7573 - val_accuracy: 0.8886\n",
            "Epoch 10/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.1097 - accuracy: 0.9768 - val_loss: 1.6882 - val_accuracy: 0.8896\n",
            "Epoch 11/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1011 - accuracy: 0.9792 - val_loss: 1.6421 - val_accuracy: 0.8977\n",
            "Epoch 12/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1031 - accuracy: 0.9846 - val_loss: 1.6250 - val_accuracy: 0.9047\n",
            "Epoch 13/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0834 - accuracy: 0.9856 - val_loss: 1.6072 - val_accuracy: 0.9061\n",
            "Epoch 14/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.0512 - accuracy: 0.9862 - val_loss: 1.5597 - val_accuracy: 0.9093\n",
            "Epoch 15/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.0539 - accuracy: 0.9882 - val_loss: 1.5787 - val_accuracy: 0.9075\n",
            "Epoch 16/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 1.5882 - val_accuracy: 0.9089\n",
            "Epoch 17/150\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.0471 - accuracy: 0.9916 - val_loss: 1.6256 - val_accuracy: 0.9085\n",
            "Epoch 18/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.0584 - accuracy: 0.9916 - val_loss: 1.5842 - val_accuracy: 0.9075\n",
            "Epoch 19/150\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.6014 - val_accuracy: 0.9089\n",
            "5000\n",
            "Model: \"model_259\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 31, 300)      6802500     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 31, 75)       22575       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 30, 75)       45075       embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 27, 75)       112575      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_67 (AveragePo (None, 1, 75)        0           conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_68 (AveragePo (None, 1, 75)        0           conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_69 (AveragePo (None, 1, 75)        0           conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 3, 75)        0           average_pooling1d_67[0][0]       \n",
            "                                                                 average_pooling1d_68[0][0]       \n",
            "                                                                 average_pooling1d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 75)           16950       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 6,999,675\n",
            "Trainable params: 6,999,675\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [25:50<00:00, 258.50s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN1D_free_.001</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.6911</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.8364</td>\n",
              "      <td>0.8963</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN1D_free_.001</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2208</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.4004</td>\n",
              "      <td>0.5132</td>\n",
              "      <td>0.6282</td>\n",
              "      <td>0.7385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             model       task      metric    0  ...    5000 10000 15000 25000\n",
              "4  CNN1D_free_.001  slc_de_tf    accuracy  NaN  ...  0.8963   NaN   NaN   NaN\n",
              "5  CNN1D_free_.001  slc_de_tf  avg_recall  NaN  ...  0.7385   NaN   NaN   NaN\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lDHRD0HFqcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "77751234-9365-4b6b-c17a-67d62033066f"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>100</th>\n",
              "      <th>250</th>\n",
              "      <th>500</th>\n",
              "      <th>1000</th>\n",
              "      <th>2000</th>\n",
              "      <th>5000</th>\n",
              "      <th>10000</th>\n",
              "      <th>15000</th>\n",
              "      <th>25000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN1D_free_.1</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5629</td>\n",
              "      <td>0.6553</td>\n",
              "      <td>0.6834</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.7401</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN1D_free_.1</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5234</td>\n",
              "      <td>0.5155</td>\n",
              "      <td>0.5551</td>\n",
              "      <td>0.5742</td>\n",
              "      <td>0.5663</td>\n",
              "      <td>0.6032</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN1D_free_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5653</td>\n",
              "      <td>0.6606</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.8469</td>\n",
              "      <td>0.8939</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN1D_free_.01</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2673</td>\n",
              "      <td>0.3676</td>\n",
              "      <td>0.4479</td>\n",
              "      <td>0.5756</td>\n",
              "      <td>0.6409</td>\n",
              "      <td>0.7303</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN1D_free_.001</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.6911</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.8364</td>\n",
              "      <td>0.8963</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN1D_free_.001</td>\n",
              "      <td>slc_de_tf</td>\n",
              "      <td>avg_recall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2208</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.4004</td>\n",
              "      <td>0.5132</td>\n",
              "      <td>0.6282</td>\n",
              "      <td>0.7385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             model       task      metric    0  ...    5000 10000 15000 25000\n",
              "0    CNN1D_free_.1  slc_de_tf    accuracy  NaN  ...  0.7401   NaN   NaN   NaN\n",
              "1    CNN1D_free_.1  slc_de_tf  avg_recall  NaN  ...  0.6032   NaN   NaN   NaN\n",
              "2   CNN1D_free_.01  slc_de_tf    accuracy  NaN  ...  0.8939   NaN   NaN   NaN\n",
              "3   CNN1D_free_.01  slc_de_tf  avg_recall  NaN  ...  0.7303   NaN   NaN   NaN\n",
              "4  CNN1D_free_.001  slc_de_tf    accuracy  NaN  ...  0.8963   NaN   NaN   NaN\n",
              "5  CNN1D_free_.001  slc_de_tf  avg_recall  NaN  ...  0.7385   NaN   NaN   NaN\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    }
  ]
}